{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import statistics\n",
    "import pickle\n",
    "import torch\n",
    "from collections import Counter\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import submodlib\n",
    "from submodlib.helper import create_kernel\n",
    "from submodlib.functions.facilityLocationMutualInformation import FacilityLocationMutualInformationFunction\n",
    "from submodlib.functions.facilityLocationVariantMutualInformation import FacilityLocationVariantMutualInformationFunction\n",
    "from submodlib.functions.graphCutMutualInformation import GraphCutMutualInformationFunction\n",
    "from submodlib.functions.logDeterminantMutualInformation import LogDeterminantMutualInformationFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _color_map(dirs):\n",
    "    # color = [\"yellowgreen\", \"darkorange\", \"lightcoral\", \"yellow\", \"cyan\", \"royalblue\", 'fuchsia', 'lawngreen', 'black', 'red', '#D3D3D3']\n",
    "    #color = [\"yellowgreen\", \"darkorange\", \"lightcoral\", \"yellow\", \"cyan\", \"royalblue\", 'fuchsia', 'lawngreen', 'black', 'red']\n",
    "    color = [\"midnightblue\", \"darkgreen\", 'lime', 'pink', 'red', 'yellow', 'black', 'cyan', 'lawngreen', 'darkorange', 'yellowgreen']\n",
    "    color_map = {}\n",
    "    for _dir, color in zip(dirs+['query_set', 'selected_set', 'test_set'], color):\n",
    "        color_map[_dir] = color\n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_PCA(X, y, _dirs, pca_result, extra_result, label_map, _ax, color_map):\n",
    "    feat_cols = ['dim'+str(i) for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(X, columns=feat_cols)\n",
    "    df['y'] = y\n",
    "    label_map = dict(enumerate(_dirs))\n",
    "    df['label'] = df['y'].apply(lambda i: label_map[i])\n",
    "    df['pca-one'] = np.concatenate([pca_result[:,0], extra_result[:, 0]], axis=0)\n",
    "    df['pca-two'] = np.concatenate([pca_result[:,1], extra_result[:, 1]], axis=0)\n",
    "    g = sns.scatterplot(\n",
    "        x=\"pca-one\", y=\"pca-two\",\n",
    "        hue=\"label\",\n",
    "        palette=color_map,\n",
    "        data=df,\n",
    "        legend=\"full\",\n",
    "        alpha=0.6,\n",
    "        ax = _ax\n",
    "    )\n",
    "    g.legend(loc='center right', bbox_to_anchor=(0.05, 0.9))\n",
    "\n",
    "def _plot_TSNE(X, y, _dirs, _ax, color_map, markers):\n",
    "    feat_cols = ['dim'+str(i) for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(X, columns=feat_cols)\n",
    "    df['y'] = y\n",
    "\n",
    "    label_map = dict(enumerate(_dirs))\n",
    "    df['label'] = df['y'].apply(lambda i: label_map[i])\n",
    "\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "    tsne_results = tsne.fit_transform(df[feat_cols].values)\n",
    "\n",
    "    df['tsne-2d-one'] = tsne_results[:,0]\n",
    "    df['tsne-2d-two'] = tsne_results[:,1]\n",
    "\n",
    "    g = sns.scatterplot(\n",
    "        x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "        hue=\"label\",\n",
    "        palette=color_map,\n",
    "        data=df,\n",
    "        legend=\"full\",\n",
    "        alpha=0.6,\n",
    "        markers=markers,\n",
    "        ax = _ax\n",
    "    )\n",
    "    g.legend(loc='center right', bbox_to_anchor=(0.05, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_TSNE(dirs, run_dir, ground_features, ground_features_Y, query_features, test_features, selected_indices, selected_gains, fxn):\n",
    "    n = len(dirs)\n",
    "    selected_features = ground_features[selected_indices]\n",
    "    color_map = _color_map(dirs)\n",
    "    fig = plt.figure(figsize=(30,30))\n",
    "\n",
    "    # _ax = fig.add_subplot(3,2,1)\n",
    "    _ax = fig.add_subplot(2,2,1)\n",
    "    X = np.concatenate([ground_features, query_features, selected_features], axis=0)\n",
    "    y = np.concatenate([ground_features_Y, np.zeros((len(query_features), 1))+n, np.zeros((len(selected_features), 1))+n+1], axis=0)\n",
    "    _plot_TSNE(X, y, dirs+['query_set', 'selected_set'], _ax, color_map, [',']*len(dirs)+['.', '*'])\n",
    "\n",
    "    #    _ax = fig.add_subplot(3,2,3)\n",
    "    #    X = np.concatenate([ground_features], axis=0)\n",
    "    #    y = np.concatenate([ground_features_Y], axis=0)\n",
    "    #    _plot_TSNE(X, y, dirs, _ax, color_map, [',']*len(dirs))\n",
    "    #\n",
    "    #    _ax = fig.add_subplot(3,2,5)    \n",
    "    #    X = np.concatenate([ground_features, test_features], axis=0)\n",
    "    #    y = np.concatenate([ground_features_Y, np.zeros((len(test_features), 1))+n], axis=0)\n",
    "    #    _plot_TSNE(X, y, dirs+['test_set'], _ax, color_map, [',']*len(dirs)+['1'])\n",
    "\n",
    "    #    _ax = fig.add_subplot(3,2,6)    \n",
    "    _ax = fig.add_subplot(2,2,3)    \n",
    "    X = np.concatenate([ground_features, test_features, query_features, selected_features], axis=0)\n",
    "    y = np.concatenate([ground_features_Y, np.zeros((len(test_features), 1))+n, np.zeros((len(query_features), 1))+n+1, np.zeros((len(selected_features), 1))+n+2], axis=0)\n",
    "    _plot_TSNE(X, y, dirs+['test_set', 'query_set', 'selected_set'], _ax, color_map, [',']*len(dirs)+['.', '1', '*'])\n",
    "\n",
    "    #    _ax = fig.add_subplot(3,2,2)    \n",
    "    _ax = fig.add_subplot(2,2,2)    \n",
    "    _ax.bar(range(len(selected_features)), selected_gains, color ='maroon', width = 0.4)\n",
    "    _ax.set_xlabel('samples')\n",
    "    _ax.set_ylabel('gains')\n",
    "\n",
    "    fig.suptitle(fxn, fontsize = 34, fontweight ='bold')\n",
    "    plt.savefig(run_dir+'/plots/TSNE_visualization.png')\n",
    "\n",
    "def plot_PCA(dirs, run_dir, ground_features, ground_features_Y, query_features, test_features, selected_indices, selected_gains, fxn):\n",
    "    n = len(dirs)\n",
    "    selected_features = ground_features[selected_indices]\n",
    "    color_map = _color_map(dirs)\n",
    "    fig = plt.figure(figsize=(30,30))\n",
    "    pca = PCA(n_components=3)\n",
    "\n",
    "    _ax = fig.add_subplot(3,2,3)\n",
    "    X = np.concatenate([ground_features], axis=0)\n",
    "    y = np.concatenate([ground_features_Y], axis=0)\n",
    "\n",
    "    feat_cols = ['dim'+str(i) for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(X, columns=feat_cols)\n",
    "    df['y'] = y\n",
    "    label_map = dict(enumerate(dirs))\n",
    "    df['label'] = df['y'].apply(lambda i: label_map[i])\n",
    "\n",
    "    pca_result = pca.fit_transform(df[feat_cols].values)\n",
    "    df['pca-one'] = pca_result[:,0]\n",
    "    df['pca-two'] = pca_result[:,1] \n",
    "    df['pca-three'] = pca_result[:,2]\n",
    "\n",
    "    _ax = fig.add_subplot(3,2,3)\n",
    "    g = sns.scatterplot(\n",
    "        x=\"pca-one\", y=\"pca-two\",\n",
    "        hue=\"label\",\n",
    "        palette=color_map,\n",
    "        data=df,\n",
    "        legend=\"full\",\n",
    "        alpha=0.6,\n",
    "        ax = _ax\n",
    "    )\n",
    "    g.legend(loc='center right', bbox_to_anchor=(0.05, 0.9))\n",
    "\n",
    "    query_select_transform = pca.transform(np.concatenate([query_features, selected_features], axis=0))\n",
    "    test_transform = pca.transform(test_features)\n",
    "    query_select_test_transform = pca.transform(np.concatenate([test_features, query_features, selected_features], axis=0))\n",
    "\n",
    "    X = np.concatenate([ground_features, query_features, selected_features], axis=0)\n",
    "    y = np.concatenate([ground_features_Y, np.zeros((len(query_features), 1))+n, np.zeros((len(selected_features), 1))+n+1], axis=0)\n",
    "    _ax = fig.add_subplot(3,2,1)\n",
    "    _plot_PCA(X, y, dirs+['query_set', 'selected_set'], pca_result, query_select_transform, label_map, _ax, color_map)\n",
    "\n",
    "    _ax = fig.add_subplot(3,2,5)\n",
    "    X = np.concatenate([ground_features, test_features], axis=0)\n",
    "    y = np.concatenate([ground_features_Y, np.zeros((len(test_features), 1))+n], axis=0)    \n",
    "    _plot_PCA(X, y, dirs+['test_set'], pca_result, test_transform, label_map, _ax, color_map)\n",
    "\n",
    "    _ax = fig.add_subplot(3,2,6)\n",
    "    X = np.concatenate([ground_features, test_features, query_features, selected_features], axis=0)\n",
    "    y = np.concatenate([ground_features_Y, np.zeros((len(test_features), 1))+n, np.zeros((len(query_features), 1))+n+1, np.zeros((len(selected_features), 1))+n+2], axis=0)\n",
    "    _plot_PCA(X, y, dirs+['test_set', 'query_set', 'selected_set'], pca_result, query_select_test_transform, label_map, _ax, color_map)\n",
    "\n",
    "    _ax = fig.add_subplot(3,2,2)    \n",
    "    _ax.bar(range(len(selected_features)), selected_gains, color ='maroon', width = 0.4)\n",
    "    _ax.set_xlabel('samples')\n",
    "    _ax.set_ylabel('gains')\n",
    "\n",
    "    fig.suptitle(fxn, fontsize = 14, fontweight ='bold')\n",
    "    plt.savefig(run_dir+'/plots/PCA_visualization.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(dirs, run_dir, ground_features, ground_features_Y, query_features, test_features, selected_indices, selected_gains, fxn):\n",
    "    plot_TSNE(dirs, run_dir, ground_features, ground_features_Y, query_features, test_features, selected_indices, selected_gains, fxn)\n",
    "    plot_PCA(dirs, run_dir, ground_features, ground_features_Y, query_features, test_features, selected_indices, selected_gains, fxn)\n",
    "\n",
    "    #    X = np.concatenate([ground_features, query_features, ground_features[selected_indices]], axis=0)\n",
    "    #    y = np.concatenate([ground_features_Y, np.zeros((len(query_features), 1)) + len(dirs), np.zeros((len(selected_indices), 1)) + len(dirs) + 1], axis=0)\n",
    "    #    print(X.shape, ground_features.shape, query_features.shape, len(selected_indices))\n",
    "    #    print(y.shape, ground_features_Y.shape)\n",
    "    #    \n",
    "    #    feat_cols = ['dim'+str(i) for i in range(X.shape[1])]\n",
    "    #    df = pd.DataFrame(X, columns=feat_cols)\n",
    "    #    df['y'] = y\n",
    "    #    \n",
    "    #    label_map = dict(enumerate(dirs + ['query_set', 'selected_set']))\n",
    "    #    df['label'] = df['y'].apply(lambda i: label_map[i])\n",
    "    #    \n",
    "    #    tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "    #    tsne_results = tsne.fit_transform(df[feat_cols].values)\n",
    "    #    \n",
    "    #    df['tsne-2d-one'] = tsne_results[:,0]\n",
    "    #    df['tsne-2d-two'] = tsne_results[:,1]\n",
    "    #\n",
    "    #    color_map = _color_map(dirs)\n",
    "    #    fig = plt.figure(figsize=(20,10))\n",
    "    #    \n",
    "    #    ax = fig.add_subplot(1,2,1)\n",
    "    #    g = sns.scatterplot(\n",
    "    #        x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    #        hue=\"label\",\n",
    "    #        palette=color_map,\n",
    "    #        data=df,\n",
    "    #        legend=\"full\",\n",
    "    #        alpha=0.6, \n",
    "    #        ax = ax\n",
    "    #    )\n",
    "    #    g.legend(loc='center right', bbox_to_anchor=(0.05, 0.9))\n",
    "    #    \n",
    "    #    ax = fig.add_subplot(1,2,2)\n",
    "    #    ax.bar(range(len(selected_indices)), selected_gains, color ='maroon', width = 0.4)\n",
    "    #    ax.set_xlabel('samples')\n",
    "    #    ax.set_ylabel('gains')\n",
    "    #    \n",
    "    #    fig.suptitle(fxn, fontsize = 14, fontweight ='bold')\n",
    "    #    plt.savefig(run_dir+'/plots/visualization.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subset(dirs, base_dir, query_dir, ground_list, ground_features, ground_features_Y, query_list, query_features, test_features, greedyList, budget_size, target_size, speaker, fxn, similarity, etaValue, feature_type):\n",
    "    list_total_selection, list_total_count, list_total_duration = [], [], []\n",
    "    list_speaker_sample_count, list_speaker_sample_duration = [], []\n",
    "    output_dir = os.path.join(base_dir, query_dir, f'TSS_output/all/budget_{budget_size}/target_{target_size}/{fxn}/eta_{etaValue}/{similarity}/{feature_type}')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for i in [1, 2, 3]:\n",
    "        run = f'run_{i}'\n",
    "        run_dir = os.path.join(output_dir, run)\n",
    "        for folder in ['train', 'output', 'plots']:\n",
    "            os.makedirs(os.path.join(run_dir, folder), exist_ok=True)\n",
    "            \n",
    "        all_indices = [j[0] for j in greedyList]\n",
    "        all_gains = [j[1] for j in greedyList]\n",
    "        total_duration, index = 0, 0\n",
    "        while total_duration + ground_list[all_indices[index]]['duration'] <= 492:\n",
    "            total_duration += ground_list[all_indices[index]]['duration']\n",
    "            index += 1\n",
    "\n",
    "        list_total_count.append(index)\n",
    "        list_total_duration.append(total_duration)\n",
    "        selected_indices = all_indices[:index]\n",
    "        selected_gains = all_gains[:index]\n",
    "        selected_list = [ground_list[j] for j in selected_indices]\n",
    "        train_list = selected_list + query_list\n",
    "        \n",
    "        speaker_sample_count, speaker_sample_duration = 0, 0\n",
    "        for item in selected_list:\n",
    "            if item['audio_filepath'].split('/')[-4] == speaker:\n",
    "                speaker_sample_count += 1\n",
    "                speaker_sample_duration += item['duration']\n",
    "        list_speaker_sample_count.append(speaker_sample_count)\n",
    "        list_speaker_sample_duration.append(speaker_sample_duration)\n",
    "        list_total_selection.append(Counter([item['audio_filepath'].split('/')[-4] for item in selected_list]))\n",
    "        \n",
    "        with open(base_dir + query_dir + f'train/error_model/{budget_size}/seed_{i}/train.json', 'w') as f:\n",
    "            for line in train_list:\n",
    "                f.write('{}\\n'.format(json.dumps(line)))\n",
    "        with open(f'{run_dir}/train/train.json', 'w') as f:\n",
    "            for line in train_list:\n",
    "                f.write('{}\\n'.format(json.dumps(line)))\n",
    "        plots(dirs, run_dir, ground_features, ground_features_Y, query_features, test_features, selected_indices, selected_gains, fxn)\n",
    "    print('\\n subset computed .... \\n')\n",
    "    stats = 'total selection : ' + ' '.join(map(str, list_total_count)) + ' -> {0:.2f}\\n'.format(statistics.mean(list_total_count))\n",
    "    stats += 'total selection duration: ' + ' '.join(map(str, list_total_duration)) + ' -> {0:.2f}\\n'.format(statistics.mean(list_total_duration))\n",
    "    stats += 'speaker selection: ' + ' '.join(map(str, list_speaker_sample_count)) + ' -> {0:.2f}\\n'.format(statistics.mean(list_speaker_sample_count))\n",
    "    stats += 'speaker duration: ' + ' '.join(map(str, list_speaker_sample_duration)) + ' -> {0:.2f}\\n'.format(statistics.mean(list_speaker_sample_duration))\n",
    "    stats += '\\nall selections: ' + str(list_total_selection)\n",
    "    \n",
    "    with open(output_dir + '/stats.txt', 'w') as f:\n",
    "        f.write(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_greedyList(ground_kernel, query_kernel, query_query_kernel, fxn, budget_size, etaValue):\n",
    "    print(f'\\ncreating {fxn} object\\n')\n",
    "    if fxn == 'FL1MI':\n",
    "        obj1 = FacilityLocationMutualInformationFunction(n=len(ground_kernel), num_queries=query_kernel.shape[1],\n",
    "                                                         query_sijs=query_kernel, data_sijs=ground_kernel, \n",
    "                                                         magnificationEta=etaValue)\n",
    "    elif fxn == 'FL2MI':\n",
    "        obj1 = FacilityLocationVariantMutualInformationFunction(n=len(ground_kernel), num_queries=query_kernel.shape[1],\n",
    "                                                         query_sijs=query_kernel, queryDiversityEta=etaValue)\n",
    "    elif fxn == 'GCMI':\n",
    "        obj1 = GraphCutMutualInformationFunction(n=len(ground_kernel), num_queries=query_kernel.shape[1],\n",
    "                                                         query_sijs=query_kernel)\n",
    "    elif fxn == 'LogDMI':\n",
    "        obj1 = LogDeterminantMutualInformationFunction(n=len(ground_kernel), num_queries=query_kernel.shape[1], lambdaVal=1,\n",
    "                                                         query_sijs=query_kernel, data_sijs=ground_kernel, \n",
    "                                                         query_query_sijs=query_query_kernel, magnificationEta=etaValue)\n",
    "    else:\n",
    "        print('\\n\\n\\n............... ERROR not a valid FUNCTION ............\\n\\n\\n')\n",
    "        exit()\n",
    "    print(f'\\n{fxn} object created\\n')\n",
    "    print('\\ngenerating greedyList...\\n') \n",
    "    greedyList = obj1.maximize(budget=3*budget_size, optimizer='LazyGreedy', stopIfZeroGain=False, stopIfNegativeGain=False, epsilon=0.1, verbose=False)\n",
    "    print('\\n.... greedyList generated ... \\n')\n",
    "    return greedyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(file_dir, feature_type):\n",
    "    features = []\n",
    "    with open(file_dir.replace('.json', f'_{feature_type}.file'), 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                features.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                break\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    print(features.shape)\n",
    "    return features\n",
    "\n",
    "def preprocess(base_dir, target_size, budget_size, speaker, similarity, feature_type):\n",
    "#     dirs = ['THV', 'YKWK', 'ERMS', 'BWC', 'ASI', 'YDCK', 'TNI', 'YBAA', 'TXHC', 'ZHAA', 'MBMPS', 'RRBI', 'NCC', 'HJK', 'HKK', 'TLV', 'ABA', 'SVBI', 'EBVS', 'HQTV', 'NJS', 'SKA', 'PNV']\n",
    "    dirs = [ f.name for f in os.scandir('/home/mayank/MTP/begin_again/Error-Driven-ASR-Personalization/CMU_expts/speaker_with/') if f.is_dir() ]\n",
    "    dirs.remove('.ipynb_checkpoints')\n",
    "    query_dir = f'{speaker}/manifests/' \n",
    "    query_file_path = base_dir + query_dir + 'seed.json'\n",
    "\n",
    "    query_list = [json.loads(line.strip()) for line in open(query_file_path)]\n",
    "    query_features = load_features(query_file_path, feature_type)\n",
    "    query_list, query_features = query_list[:target_size], query_features[:target_size]\n",
    "\n",
    "    ground_list, ground_list_Y, ground_features = [], [], []\n",
    "    for i, _dir in enumerate(dirs):\n",
    "        selection_file_path = base_dir + _dir + '/manifests/selection.json'\n",
    "        selection_file_list = [json.loads(line.strip()) for line in open(selection_file_path)]\n",
    "        ground_list.extend(selection_file_list[:])\n",
    "        ground_features.append(load_features(selection_file_path, feature_type))\n",
    "        ground_list_Y.extend([i]*len(selection_file_list))   \n",
    "    ground_features = np.concatenate(ground_features, axis=0)\n",
    "    ground_features_Y = np.asarray(ground_list_Y).reshape(-1, 1) \n",
    "\n",
    "    ### test file\n",
    "    test_file_path = base_dir + query_dir + 'test.json'\n",
    "    test_list = [json.loads(line.strip()) for line in open(test_file_path)]\n",
    "    test_features = load_features(test_file_path, feature_type)\n",
    "\n",
    "    print(len(ground_list), ground_features.shape)\n",
    "    print(len(query_list), query_features.shape)\n",
    "    print(len(test_list), test_features.shape)\n",
    "\n",
    "    print('creating kernels ....')\n",
    "    t1 = time.time()\n",
    "    ground_kernel = create_kernel(ground_features, metric=similarity, mode='dense')\n",
    "    query_kernel = create_kernel(query_features, metric=similarity, mode='dense', X_rep=ground_features)\n",
    "    query_query_kernel = create_kernel(query_features, metric=similarity, mode='dense', X_rep=query_features)\n",
    "    t2 = time.time()\n",
    "    print('kernel creation done ....', t2-t1)\n",
    "\n",
    "    print('ground_kernel: ', ground_kernel.shape)\n",
    "    print('query_kernel: ', query_kernel.shape)\n",
    "    print('query_query_kernel: ', query_query_kernel.shape)\n",
    "\n",
    "    return dirs, query_dir, ground_list, ground_features, ground_features_Y, ground_kernel, query_list, query_features, query_kernel, query_query_kernel, test_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description ='TSS input')\n",
    "# parser.add_argument('--budget', type = int,  help ='budget')\n",
    "# parser.add_argument('--target', type = int,  help ='target')\n",
    "# parser.add_argument('--eta', type = float,  help ='eta value')\n",
    "# parser.add_argument('--similarity', type = str,  help ='similarity metric')\n",
    "# parser.add_argument('--fxn', type = str,  help ='function')\n",
    "# parser.add_argument('--speaker', type = str,  help ='query set')\n",
    "# parser.add_argument('--feature_type', type = str,  help ='which feature space')\n",
    "# args = parser.parse_args()\n",
    "# budget_size = args.budget\n",
    "# target_size = args.target\n",
    "# etaValue = args.eta\n",
    "# similarity = args.similarity\n",
    "# fxn = args.fxn\n",
    "# speaker = args.speaker\n",
    "# feature_type = args.feature_type\n",
    "budget_size = 100\n",
    "target_size = 50\n",
    "etaValue = 1.2\n",
    "similarity = 'cosine'\n",
    "fxn = 'FL1MI'\n",
    "speaker = 'ABA'\n",
    "feature_type = 'MFCC'\n",
    "base_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs, query_dir, ground_list, ground_features, ground_features_Y, ground_kernel, query_list, query_features, query_kernel, query_query_kernel, test_features = preprocess(base_dir, target_size, budget_size, speaker, similarity, feature_type)\n",
    "greedyList = generate_greedyList(ground_kernel, query_kernel, query_query_kernel, fxn, budget_size, etaValue)\n",
    "compute_subset(dirs, base_dir, query_dir, ground_list, ground_features, ground_features_Y, query_list, query_features, test_features, greedyList, budget_size, target_size, speaker, fxn, similarity, etaValue, feature_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
