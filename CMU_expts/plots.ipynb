{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "# from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [ f.name for f in os.scandir('/home/mayank/MTP/begin_again/Error-Driven-ASR-Personalization/CMU_expts/accent-without/') if f.is_dir() ]\n",
    "dirs.remove('.ipynb_checkpoints')\n",
    "print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs = ['SKA', 'MBMPS', 'THV']\n",
    "\n",
    "# dirs = ['ABA', 'ASI', 'BWC', 'EBVS', 'ERMS', 'HJK', 'HKK', 'HQTV', 'NCC', 'NJS', 'PNV', \n",
    "#         'RRBI', 'SVBI', 'TLV', 'TNI', 'TXHC', 'YBAA', 'YDCK', 'YKWK', 'ZHAA']\n",
    "accent_map = {\"ABA\":\"arabic\",\"SKA\":\"arabic\",\"YBAA\":\"arabic\",\"ZHAA\":\"arabic\",\n",
    "              \"BWC\":\"chinese\",\"LXC\":\"chinese\",\"NCC\":\"chinese\",\"TXHC\":\"chinese\",\n",
    "              \"ASI\":\"hindi\",\"RRBI\":\"hindi\",\"SVBI\":\"hindi\",\"TNI\":\"hindi\",\n",
    "              \"HJK\":\"korean\",\"HKK\":\"korean\",\"YDCK\":\"korean\",\"YKWK\":\"korean\",\n",
    "              \"EBVS\":\"spanish\",\"ERMS\":\"spanish\",\"MBMPS\":\"spanish\",\"NJS\":\"spanish\",\n",
    "              \"HQTV\":\"vietnamese\",\"PNV\":\"vietnamese\",\"THV\":\"vietnamese\",\"TLV\":\"vietnamese\"\n",
    "              }\n",
    "accent_base_dir = '/home/mayank/MTP/begin_again/Error-Driven-ASR-Personalization/CMU_expts/accent-without/'\n",
    "base_dir = '/home/mayank/MTP/begin_again/Error-Driven-ASR-Personalization/CMU_expts/accent-without/'\n",
    "accent_dirs = list(set(map(accent_map.get, dirs)))\n",
    "print(accent_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "\n",
    "def load_features(file_dir, feature):\n",
    "    features = []\n",
    "    with open(file_dir.replace('.json', '_'+feature+'.file'), 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                features.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                break\n",
    "    print(features[-1].shape)\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    return features\n",
    "\n",
    "\n",
    "dirs = ['hindi', 'chinese', 'spanish', 'arabic', 'korean', 'vietnamese']\n",
    "print(dirs)\n",
    "base_dir = '/home/mayank/MTP/begin_again/Error-Driven-ASR-Personalization/CMU_expts/accent-without/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_list, ground_list_Y, ground_features = [], [], []\n",
    "for i, _dir in enumerate(dirs):\n",
    "    selection_file_path = base_dir + _dir + '/manifests/test.json'\n",
    "    selection_file_list = [json.loads(line.strip()) for line in open(selection_file_path)]\n",
    "    selection_file_list = selection_file_list\n",
    "    ground_list.extend(selection_file_list)\n",
    "    ground_features.append(load_features(selection_file_path, \"wv8\"))\n",
    "    print(_dir+\" has \"+str(len(selection_file_list))+\" samples.\")\n",
    "    ground_list_Y.extend([i]*len(selection_file_list))\n",
    "    \n",
    "ground_features = np.concatenate(ground_features, axis=0)\n",
    "ground_features_Y = np.asarray(ground_list_Y).reshape(-1, 1) \n",
    "print(len(ground_list), ground_features.shape, ground_features_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _color_map(dirs):\n",
    "#     color = [\"midnightblue\", \"royalblue\", \"indigo\", \"darkgreen\", 'lime', \"green\", 'pink', 'fuchsia', 'red', \n",
    "#              'yellow', 'black']\n",
    "    color = [\"midnightblue\", \"darkgreen\", 'lime', 'pink', 'red', \n",
    "             'yellow', 'black']\n",
    "    color_map = {}\n",
    "    for _dir, color in zip(dirs+['query_set', 'selected_set'], color):\n",
    "        color_map[_dir] = color\n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = ground_features, ground_features_Y\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print('\\n\\n')\n",
    "feat_cols = ['dim'+str(i) for i in range(X.shape[1])]\n",
    "df = pd.DataFrame(X, columns=feat_cols)\n",
    "df['y'] = y\n",
    "\n",
    "label_map = dict(enumerate(dirs))\n",
    "df['label'] = df['y'].apply(lambda i: label_map[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perp=0.83*(X.shape[0]**0.5)\n",
    "iters=3000\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=perp, n_iter=iters)\n",
    "tsne_results = tsne.fit_transform(df[feat_cols].values)\n",
    "\n",
    "df['tsne-2d-one'] = tsne_results[:,0]\n",
    "df['tsne-2d-two'] = tsne_results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,5))\n",
    "_ax = fig.add_subplot(1,1,1)\n",
    "_ax.title.set_text('new wv8 {}-accent ground set: perplexity {}, iters {}'.format(len(dirs), int(perp), iters))\n",
    "g = sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"label\",\n",
    "    palette=sns.color_palette(\"hls\", len(dirs)),\n",
    "    data=df,\n",
    "    legend=\"full\",\n",
    "#     markers= [0.5]*y.shape[0],\n",
    "#     legend=False,\n",
    "    alpha=0.6,\n",
    "    ax = _ax\n",
    ")\n",
    "plt.figure(dpi=1200)\n",
    "# plt.legend(loc='upper right')\n",
    "g.legend(\n",
    "         loc='upper right', \n",
    "#          loc=1,\n",
    "         bbox_to_anchor=(1.013, 1.017), \n",
    "         prop={'size':9}, markerscale=1)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('L2_t-SNE-new-wv8-{}-{}.svg'.format(int(perp), iters)) # , bbox_inches='tight', pad_inches=0\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import statistics\n",
    "\n",
    "budget_size = 100\n",
    "list_total_duration = []\n",
    "for i in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    temp_ground_list = ground_list[:]\n",
    "    random.seed(41 + i)\n",
    "    random.shuffle(temp_ground_list)\n",
    "    selected_list = temp_ground_list[:budget_size]     \n",
    "    total_duration = sum([i['duration'] for i in selected_list])\n",
    "    list_total_duration.append(total_duration)\n",
    "print(list_total_duration)\n",
    "print(statistics.mean(list_total_duration), statistics.variance(list_total_duration)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, json, os, time, pickle\n",
    "from tqdm import tqdm\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "def _color_map(dirs):\n",
    "    color = [\"midnightblue\", \"darkgreen\", 'lime', 'pink', 'red', \n",
    "             'yellow', 'black']\n",
    "    color_map = {}\n",
    "    for _dir, color in zip(dirs+['query_set', 'selected_set'], color):\n",
    "        color_map[_dir] = color\n",
    "    return color_map\n",
    "\n",
    "def load_features(file_dir, feature):\n",
    "    features = []\n",
    "    with open(file_dir.replace('.json', '_'+feature+'.file'), 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                features.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                break\n",
    "    print(features[-1].shape)\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    return features\n",
    "\n",
    "\n",
    "def df_from(file_type, feature, dirs):\n",
    "    t1 = time.time()\n",
    "    ground_list, ground_list_Y, ground_features = [], [], []\n",
    "    for i, _dir in enumerate(dirs):\n",
    "        \n",
    "        selection_file_path = '../mz-isca/expts/' + _dir + '/manifests/{}.json'.format(file_type)\n",
    "        selection_file_list = [json.loads(line.strip()) for line in open(selection_file_path)]\n",
    "        selection_file_list = selection_file_list[:700]\n",
    "        ground_list.extend(selection_file_list)\n",
    "        ground_features.append(load_features(selection_file_path, feature)[:700])\n",
    "        \n",
    "        print(_dir+\" has \"+str(len(selection_file_list))+\" samples.\")\n",
    "        ground_list_Y.extend([i]*len(selection_file_list))\n",
    "    \n",
    "    ground_features = np.concatenate(ground_features, axis=0)\n",
    "    ground_features_Y = np.asarray(ground_list_Y).reshape(-1, 1) \n",
    "    print(len(ground_list), ground_features.shape, ground_features_Y.shape)\n",
    "    \n",
    "    X, y = ground_features, ground_features_Y\n",
    "    \n",
    "    print(X.shape, y.shape)\n",
    "    print('\\n\\n')\n",
    "    feat_cols = ['dim'+str(i) for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(X, columns=feat_cols)\n",
    "    df['y'] = y\n",
    "    \n",
    "    label_map = dict(enumerate(dirs))\n",
    "    df['label'] = df['y'].apply(lambda i: label_map[i])\n",
    "\n",
    "    perp=50\n",
    "    iters=1500\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=perp, n_iter=iters)\n",
    "    tsne_results = tsne.fit_transform(df[feat_cols].values)\n",
    "\n",
    "    df['tsne-2d-one'] = tsne_results[:,0]\n",
    "    df['tsne-2d-two'] = tsne_results[:,1]\n",
    "    \n",
    "    t2 = time.time()\n",
    "    print(\"in {:.1f} min\".format((t2-t1)/60))\n",
    "    return df\n",
    "\n",
    "def tnse_plot(dirs, title, fname, df):\n",
    "    perp, iters = 50, 2000\n",
    "    fig = plt.figure(figsize=(6,5))\n",
    "    _ax = fig.add_subplot(1,1,1)\n",
    "    _ax.title.set_text('{} {}-accent ground set: perp {}, iters {}'.format(title, len(dirs), int(perp), iters))\n",
    "    g = sns.scatterplot(x=\"tsne-2d-one\", y=\"tsne-2d-two\", hue=\"label\", palette=sns.color_palette(\"hls\", len(dirs)), data=df, legend=\"full\", alpha=0.6, ax = _ax)\n",
    "    plt.figure(dpi=1200)\n",
    "    g.legend(loc='upper right', bbox_to_anchor=(1.013, 1.017), prop={'size':9}, markerscale=1)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('{}-{}-{}.svg'.format(fname, int(perp), iters))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['african', 'indian', 'hongkong', 'philippines', \n",
    "        'england', 'scotland', 'us', 'ireland', \n",
    "       'canada', 'australia'\n",
    "       'bermuda', 'malaysia']\n",
    "\n",
    "train_dirs = ['african', 'indian', 'hongkong', 'philippines', \n",
    "           'england', 'scotland', 'us', 'ireland']\n",
    "\n",
    "df_train = df_from(\"test\", 'wv10_100', train_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resource_dirs = ['african', 'indian', 'hongkong', 'philippines', \n",
    "           'england', 'australia', 'scotland', 'us', 'ireland', \n",
    "           'canada']\n",
    "df_resource = df_from(\"test\", 'wv10_100', resource_dirs)\n",
    "tnse_plot(resource_dirs, \"mz-wv10_100 res\", \"res-wv10_100\", df_resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnse_plot(train_dirs, \"mz-wv10_100 train\", \"train-wv10_100\", df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def _color_map(dirs):\n",
    "    color = [\"midnightblue\", \"darkgreen\", 'lime', 'pink', 'red', \n",
    "             'yellow', 'black']\n",
    "    color_map = {}\n",
    "    for _dir, color in zip(dirs+['query_set', 'selected_set'], color):\n",
    "        color_map[_dir] = color\n",
    "    return color_map\n",
    "\n",
    "def df_from(file_type, feature):\n",
    "    t1 = time.time()\n",
    "    dirs = ['hindi', 'chinese', 'spanish', 'arabic', 'korean', 'vietnamese']\n",
    "    ground_list, ground_list_Y, ground_features = [], [], []\n",
    "    for i, _dir in enumerate(dirs):\n",
    "        \n",
    "        selection_file_path = base_dir + _dir + '/manifests/{}.json'.format(file_type)\n",
    "        selection_file_list = [json.loads(line.strip()) for line in open(selection_file_path)]\n",
    "        selection_file_list = selection_file_list[:1000]\n",
    "        ground_list.extend(selection_file_list)\n",
    "        ground_features.append(load_features(selection_file_path, feature)[:1000])\n",
    "        \n",
    "        print(_dir+\" has \"+str(len(selection_file_list))+\" samples.\")\n",
    "        ground_list_Y.extend([i]*len(selection_file_list))\n",
    "    \n",
    "    ground_features = np.concatenate(ground_features, axis=0)\n",
    "    ground_features_Y = np.asarray(ground_list_Y).reshape(-1, 1) \n",
    "    print(len(ground_list), ground_features.shape, ground_features_Y.shape)\n",
    "    \n",
    "    X, y = ground_features, ground_features_Y\n",
    "    \n",
    "    print(X.shape, y.shape)\n",
    "    print('\\n\\n')\n",
    "    feat_cols = ['dim'+str(i) for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(X, columns=feat_cols)\n",
    "    df['y'] = y\n",
    "    \n",
    "    label_map = dict(enumerate(dirs))\n",
    "    df['label'] = df['y'].apply(lambda i: label_map[i])\n",
    "\n",
    "    perp=0.83*(X.shape[0]**0.5)\n",
    "    iters=3000\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=perp, n_iter=iters)\n",
    "    tsne_results = tsne.fit_transform(df[feat_cols].values)\n",
    "\n",
    "    df['tsne-2d-one'] = tsne_results[:,0]\n",
    "    df['tsne-2d-two'] = tsne_results[:,1]\n",
    "    \n",
    "    t2 = time.time()\n",
    "    print(\"in {:.1f} min\".format((t2-t1)/60))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_from(\"selection\", 'w2v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,5))\n",
    "_ax = fig.add_subplot(1,1,1)\n",
    "_ax.title.set_text('old w2v2 {}-accent ground set: perplexity {}, iters {}'.format(len(dirs), int(perp), iters))\n",
    "g = sns.scatterplot(x=\"tsne-2d-one\", y=\"tsne-2d-two\", hue=\"label\", palette=sns.color_palette(\"hls\", len(dirs)), data=df, legend=\"full\", alpha=0.6, ax = _ax)\n",
    "plt.figure(dpi=1200)\n",
    "g.legend(loc='upper right', bbox_to_anchor=(1.013, 1.017), prop={'size':9}, markerscale=1)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('L2_t-SNE-old-w2v2-{}-{}.svg'.format(int(perp), iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_from(\"test\", 'w2v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,5))\n",
    "_ax = fig.add_subplot(1,1,1)\n",
    "_ax.title.set_text('new w2v2 {}-accent ground set: perplexity {:.2f}, iters {}'.format(len(dirs), perp, iters))\n",
    "g = sns.scatterplot(x=\"tsne-2d-one\", y=\"tsne-2d-two\", hue=\"label\", palette=sns.color_palette(\"hls\", len(dirs)), data=df_new, legend=\"full\", alpha=0.6, ax = _ax)\n",
    "plt.figure(dpi=1200)\n",
    "g.legend(loc='upper right', bbox_to_anchor=(1.013, 1.017), prop={'size':9}, markerscale=1)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('L2_t-SNE-new-w2v2-{}-{}.svg'.format(int(perp), iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_39 = df_from(\"test\", '39')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,5))\n",
    "_ax = fig.add_subplot(1,1,1)\n",
    "_ax.title.set_text('MFCC {}-accent ground set: perplexity {:.2f}, iters {}'.format(len(dirs), perp, iters))\n",
    "g = sns.scatterplot(x=\"tsne-2d-one\", y=\"tsne-2d-two\", hue=\"label\", palette=sns.color_palette(\"hls\", len(dirs)), data=df_39, legend=\"full\", alpha=0.6, ax = _ax)\n",
    "plt.figure(dpi=1200)\n",
    "g.legend(loc='upper right', bbox_to_anchor=(1.013, 1.017), prop={'size':9}, markerscale=1)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('L2_t-SNE-mfcc-{}-{}.svg'.format(int(perp), iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "base_dir = '../mz-isca/classifier-data/val/'\n",
    "feature = 'wv8'\n",
    "jsons = [f.name for f in os.scandir(base_dir) if not(f.is_dir())]\n",
    "\n",
    "def load_features_dir(file_path, feature):\n",
    "    features = []\n",
    "    file_dir, accent = '/'.join(file_path.split('/')[:-1]), file_path.split('/')[-1].split('.json')[0]\n",
    "#     print(file_dir, accent)\n",
    "    with open(\"{}/{}/{}_{}.file\".format(file_dir, feature, accent, feature), 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                features.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                break\n",
    "    print(features[-1].shape)\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    return features\n",
    "\n",
    "def df_from_val(feature):\n",
    "    t1 = time.time()\n",
    "    \n",
    "    base_dir = '../mz-isca/classifier-data/val/'\n",
    "    feature = 'wv8'\n",
    "    jsons = [f.name for f in os.scandir(base_dir) if not(f.is_dir())]\n",
    "    print(jsons)\n",
    "    \n",
    "    ground_list, ground_list_Y, ground_features = [], [], []\n",
    "    \n",
    "    for i, json_file in enumerate(jsons):\n",
    "        \n",
    "        selection_file_path = base_dir + json_file\n",
    "        selection_file_list = [json.loads(line.strip()) for line in open(selection_file_path)]\n",
    "        selection_file_list = selection_file_list[:500]\n",
    "        ground_list.extend(selection_file_list)\n",
    "        ground_features.append(load_features_dir(selection_file_path, feature)[:500])\n",
    "        \n",
    "        print(json_file+\" has \"+str(len(selection_file_list))+\" samples.\")\n",
    "        ground_list_Y.extend([i]*len(selection_file_list))\n",
    "    \n",
    "    ground_features = np.concatenate(ground_features, axis=0)\n",
    "    ground_features_Y = np.asarray(ground_list_Y).reshape(-1, 1) \n",
    "    print(len(ground_list), ground_features.shape, ground_features_Y.shape)\n",
    "    \n",
    "    X, y = ground_features, ground_features_Y\n",
    "    \n",
    "    print(X.shape, y.shape)\n",
    "    print('\\n\\n')\n",
    "    feat_cols = ['dim'+str(i) for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(X, columns=feat_cols)\n",
    "    df['y'] = y\n",
    "    \n",
    "    label_map = dict(enumerate(jsons))\n",
    "    df['label'] = df['y'].apply(lambda i: label_map[i])\n",
    "\n",
    "    perp=0.83*(X.shape[0]**0.5)\n",
    "    iters=3000\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=perp, n_iter=iters)\n",
    "    tsne_results = tsne.fit_transform(df[feat_cols].values)\n",
    "\n",
    "    df['tsne-2d-one'] = tsne_results[:,0]\n",
    "    df['tsne-2d-two'] = tsne_results[:,1]\n",
    "    \n",
    "    t2 = time.time()\n",
    "    print(\"in {:.1f} min\".format((t2-t1)/60))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_from_val('wv8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,5))\n",
    "_ax = fig.add_subplot(1,1,1)\n",
    "_ax.title.set_text('wv10 val {}-accent ground set: perp {}, iter {}'.format(len(dirs), int(perp), iters))\n",
    "g = sns.scatterplot(x=\"tsne-2d-one\", y=\"tsne-2d-two\", hue=\"label\", palette=sns.color_palette(\"hls\", len(jsons)), data=df_val, legend=\"full\", alpha=0.6, ax = _ax)\n",
    "plt.figure(dpi=1200)\n",
    "g.legend(loc='upper right', bbox_to_anchor=(1.013, 1.017), prop={'size':9}, markerscale=1)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "base_dir = '../mz-isca/classifier-data/inval/'\n",
    "jsons = [f.name for f in os.scandir(base_dir) if not(f.is_dir())]\n",
    "\n",
    "def load_features_dir(file_path, feature):\n",
    "    features = []\n",
    "    file_dir, accent = '/'.join(file_path.split('/')[:-1]), file_path.split('/')[-1].split('.json')[0]\n",
    "#     print(file_dir, accent)\n",
    "    with open(\"{}/{}/{}_{}.file\".format(file_dir, feature, accent, feature), 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                features.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                break\n",
    "    print(features[-1].shape)\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    return features\n",
    "\n",
    "def df_from_val(feature):\n",
    "    t1 = time.time()\n",
    "    \n",
    "    base_dir = '../mz-isca/classifier-data/inval/'\n",
    "    jsons = [f.name for f in os.scandir(base_dir) if not(f.is_dir())]\n",
    "    print(jsons)\n",
    "    \n",
    "    ground_list, ground_list_Y, ground_features = [], [], []\n",
    "    \n",
    "    for i, json_file in enumerate(jsons):\n",
    "        \n",
    "        selection_file_path = base_dir + json_file\n",
    "        selection_file_list = [json.loads(line.strip()) for line in open(selection_file_path)]\n",
    "        selection_file_list = selection_file_list[:350]\n",
    "        ground_list.extend(selection_file_list)\n",
    "        ground_features.append(load_features_dir(selection_file_path, feature)[:350])\n",
    "        \n",
    "        print(json_file+\" has \"+str(len(selection_file_list))+\" samples.\")\n",
    "        ground_list_Y.extend([i]*len(selection_file_list))\n",
    "    \n",
    "    ground_features = np.concatenate(ground_features, axis=0)\n",
    "    ground_features_Y = np.asarray(ground_list_Y).reshape(-1, 1) \n",
    "    print(len(ground_list), ground_features.shape, ground_features_Y.shape)\n",
    "    \n",
    "    X, y = ground_features, ground_features_Y\n",
    "    \n",
    "    print(X.shape, y.shape)\n",
    "    print('\\n\\n')\n",
    "    feat_cols = ['dim'+str(i) for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(X, columns=feat_cols)\n",
    "    df['y'] = y\n",
    "    \n",
    "    label_map = dict(enumerate(jsons))\n",
    "    df['label'] = df['y'].apply(lambda i: label_map[i])\n",
    "\n",
    "    perp=70\n",
    "    iters=2500\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=perp, n_iter=iters)\n",
    "    tsne_results = tsne.fit_transform(df[feat_cols].values)\n",
    "\n",
    "    df['tsne-2d-one'] = tsne_results[:,0]\n",
    "    df['tsne-2d-two'] = tsne_results[:,1]\n",
    "    \n",
    "    t2 = time.time()\n",
    "    print(\"in {:.1f} min\".format((t2-t1)/60))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inval = df_from_val('wv108')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,5))\n",
    "_ax = fig.add_subplot(1,1,1)\n",
    "_ax.title.set_text('wv10 inval {}-accent ground set: perp {}, iter {}'.format(len(dirs), int(perp), iters))\n",
    "g = sns.scatterplot(x=\"tsne-2d-one\", y=\"tsne-2d-two\", hue=\"label\", palette=sns.color_palette(\"hls\", len(jsons)), data=df_inval, legend=\"full\", alpha=0.6, ax = _ax)\n",
    "plt.figure(dpi=1200)\n",
    "g.legend( loc='upper left', bbox_to_anchor=(1.013, 1.017), prop={'size':9}, markerscale=1)\n",
    "fig.tight_layout()\n",
    "fig.savefig('mz-inval-wv108-{}-{}.svg'.format(int(perp), iters))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w2v2",
   "language": "python",
   "name": "w2v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) \n[GCC 7.5.0]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
