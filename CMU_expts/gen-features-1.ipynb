{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f45f8289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4af3700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import numpy as np, pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers.file_utils import ModelOutput\n",
    "from transformers import AutoConfig, Wav2Vec2Processor\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import (\n",
    "    Wav2Vec2PreTrainedModel,\n",
    "    Wav2Vec2Model\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torchaudio, os, sys, json, pickle, librosa\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afb70663",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@dataclass\n",
    "class SpeechClassifierOutput(ModelOutput):\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    logits: torch.FloatTensor = None\n",
    "    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    attentions: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    hidden_rep: Optional[Tuple[torch.FloatTensor]] = None\n",
    "\n",
    "\n",
    "\n",
    "class Wav2Vec2ClassificationHead(nn.Module):\n",
    "    \"\"\"Head for wav2vec classification task.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(config.final_dropout)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = features\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x0 = self.dropout(x)\n",
    "#         print('----------------------------')\n",
    "#         print(x0[:,-10:])\n",
    "#         print(x0.shape)\n",
    "#         print('----------------------------')\n",
    "        x1 = self.out_proj(x0)\n",
    "        return x0, x1\n",
    "\n",
    "class Wav2Vec2ForSpeechClassification(Wav2Vec2PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.pooling_mode = config.pooling_mode\n",
    "        self.config = config\n",
    "\n",
    "        self.wav2vec2 = Wav2Vec2Model(config)\n",
    "        self.classifier = Wav2Vec2ClassificationHead(config)\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "    def freeze_feature_extractor(self):\n",
    "        self.wav2vec2.feature_extractor._freeze_parameters()\n",
    "        for module in self.wav2vec2.encoder.layers[:10]:\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def merged_strategy(self, hidden_states, mode=\"mean\"):\n",
    "        if mode == \"mean\":\n",
    "            outputs = torch.mean(hidden_states, dim=1)\n",
    "        elif mode == \"sum\":\n",
    "            outputs = torch.sum(hidden_states, dim=1)\n",
    "        elif mode == \"max\":\n",
    "            outputs = torch.max(hidden_states, dim=1)[0]\n",
    "        else:\n",
    "            raise Exception(\"The pooling method hasn't been defined! Your pooling mode must be one of these ['mean', 'sum', 'max']\")\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_values,\n",
    "            attention_mask=None,\n",
    "            output_attentions=None,\n",
    "            output_hidden_states=None,\n",
    "            return_dict=None,\n",
    "            labels=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        outputs = self.wav2vec2(\n",
    "            input_values,\n",
    "            attention_mask=attention_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        hidden_states = outputs[0]\n",
    "        hidden_states = self.merged_strategy(hidden_states, mode=self.pooling_mode)\n",
    "        hidden_rep, logits = self.classifier(hidden_states)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (hidden_rep + logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SpeechClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "            hidden_rep=hidden_rep\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c07c65b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bdbea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name_or_path = \"/mnt/data/aman/mayank/MTP/mount_points/jan_19/Error-Driven-ASR-Personalization/MCV_accent/data/dristi_accent-recognition/checkpoint-6400/\"\n",
    "model_name_or_path = \"/home/mayank/MTP/begin_again/Error-Driven-ASR-Personalization/mz-isca/classifier-data/training_data/8acc_10freeze/checkpoint-4000/\"\n",
    "config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name_or_path)\n",
    "sampling_rate = processor.feature_extractor.sampling_rate\n",
    "model = Wav2Vec2ForSpeechClassification.from_pretrained(model_name_or_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "346e99b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mswara\u001b[m  Thu Mar 24 13:05:28 2022\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 79'C\u001b[m, \u001b[32m 12 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 5176\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mpiyush\u001b[m(\u001b[33m781M\u001b[m) \u001b[1m\u001b[30mpiyush\u001b[m(\u001b[33m779M\u001b[m) \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m2837M\u001b[m) \u001b[1m\u001b[30mpiyush\u001b[m(\u001b[33m773M\u001b[m)\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 60'C\u001b[m, \u001b[32m 11 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 7697\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m3139M\u001b[m) \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m2345M\u001b[m) \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m2209M\u001b[m)\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 78'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m10363\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m10359M\u001b[m)\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 77'C\u001b[m, \u001b[1m\u001b[32m 35 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 5747\u001b[m / \u001b[33m11177\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m5743M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0dbe4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(path, sampling_rate):\n",
    "    speech_array, _sampling_rate = torchaudio.load(path)\n",
    "    resampler = torchaudio.transforms.Resample(_sampling_rate)\n",
    "    speech = resampler(speech_array).squeeze().numpy()\n",
    "    return speech\n",
    "\n",
    "def predict(path, sampling_rate):\n",
    "#     print(path)\n",
    "    speech = speech_file_to_array_fn(path, sampling_rate)\n",
    "    features = processor(speech, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "    input_values = features.input_values.to(device)\n",
    "    attention_mask = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        op = model(input_values, attention_mask=attention_mask)\n",
    "        logits = op.logits\n",
    "        hidden_rep = op.hidden_rep\n",
    "        \n",
    "    scores = F.softmax(logits, dim=1).detach().cpu().numpy()[0]\n",
    "    outputs = [{\"Accent\": config.id2label[i], \"Score\": f\"{round(score * 100, 3):.1f}%\"} for i, score in enumerate(scores)]\n",
    "    return outputs, hidden_rep\n",
    "#     return outputs, logits\n",
    "\n",
    "def prediction(df_row):\n",
    "    if 'path' in df_row: path = df_row[\"path\"]\n",
    "    else: path = df_row[\"audio_filepath\"]\n",
    "    speech, sr = torchaudio.load(path)\n",
    "    speech = speech[0].numpy().squeeze()\n",
    "    speech = librosa.resample(np.asarray(speech), sr, sampling_rate)\n",
    "    outputs, hidden_rep = predict(path, sampling_rate)\n",
    "#     print(hidden_rep[:,-10:])\n",
    "    return hidden_rep\n",
    "\n",
    "def extract_features(file_list, file_dir):\n",
    "    with open(file_dir.replace('.json', '_wv8.file'), 'wb') as f:\n",
    "        for file in tqdm(file_list):\n",
    "            w2v2_features = prediction(file).cpu().detach().numpy()\n",
    "            pickle.dump(w2v2_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d246806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_to_dir(file_list, file_path, feature):\n",
    "    file_dir, accent = '/'.join(file_path.split('/')[:-1]), file_path.split('/')[-1].split('.json')[0]\n",
    "    print(file_dir, accent)\n",
    "    with open(\"{}/{}/{}_{}.file\".format(file_dir, feature, accent, feature), 'wb') as f:\n",
    "        for file in tqdm(file_list):\n",
    "            file['audio_filepath'] = file['audio_filepath'].replace('/wav/', '/clips/').replace('.wav', '.mp3')\n",
    "            features = prediction(file).cpu().detach().numpy()\n",
    "            pickle.dump(features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f2ccdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../mz-isca/classifier-data/inval'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7002db00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['philippines.json', 'scotland.json', 'hongkong.json', 'indian.json', 'us.json', 'england.json', 'ireland.json', 'african.json']\n"
     ]
    }
   ],
   "source": [
    "base_dir = '../mz-isca/classifier-data/inval/'\n",
    "feature = 'wv10'\n",
    "os.makedirs(base_dir+feature, exist_ok = True)\n",
    "jsons = [f.name for f in os.scandir(base_dir) if not(f.is_dir())]\n",
    "print(jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15afb0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_file_starting\n",
      "../mz-isca/classifier-data/inval us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [02:54<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "test_file_ending ...\n",
      "\n",
      "\n",
      "test_file_starting\n",
      "../mz-isca/classifier-data/inval england\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [02:44<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "test_file_ending ...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for json_file in jsons[4:6]:\n",
    "\n",
    "#     seed_file_dir = manifests_path + 'seed.json'\n",
    "#     seed_file = open(seed_file_dir)\n",
    "#     seed_list = [json.loads(line.strip()) for line in seed_file]\n",
    "\n",
    "#     print('seed_file_starting')\n",
    "#     print(seed_file_dir)\n",
    "#     extract_features(seed_list, seed_file_dir)\n",
    "#     print(len(seed_list))\n",
    "#     print('seed_file_ending ...\\n')\n",
    "    \n",
    "    \n",
    "#     selection_file_dir = manifests_path + 'selection.json'\n",
    "#     selection_file = open(selection_file_dir)\n",
    "#     selection_list = [json.loads(line.strip()) for line in selection_file]\n",
    "    \n",
    "#     print('selection_file_starting')\n",
    "#     extract_features(selection_list, selection_file_dir)\n",
    "#     print(len(selection_list))\n",
    "#     print('selection_file_ending ...\\n\\n')\n",
    "    \n",
    "    \n",
    "    test_file_name = base_dir+json_file\n",
    "    test_file = open(test_file_name)\n",
    "    test_list = [json.loads(line.strip()) for line in test_file]\n",
    "\n",
    "    print('test_file_starting')\n",
    "    extract_features_to_dir(test_list[:350], test_file_name, feature)\n",
    "    print(len(test_list))\n",
    "    print('test_file_ending ...\\n\\n')\n",
    "    \n",
    "    \n",
    "#     dev_file_dir = manifests_path + 'dev.json'\n",
    "#     dev_file = open(dev_file_dir)\n",
    "#     dev_list = [json.loads(line.strip()) for line in dev_file]\n",
    "\n",
    "#     print('dev_file_starting')\n",
    "#     print(dev_file_dir)\n",
    "#     extract_features(dev_list, dev_file_dir)\n",
    "#     print(len(dev_list))\n",
    "#     print('dev_file_ending ...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b63971c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________\n",
      "hindi\n",
      "test_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1224/1224 [12:39<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1224\n",
      "test_file_ending ...\n",
      "\n",
      "\n",
      "____________________\n",
      "chinese\n",
      "test_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1224/1224 [13:32<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1224\n",
      "test_file_ending ...\n",
      "\n",
      "\n",
      "____________________\n",
      "spanish\n",
      "test_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1191/1191 [17:50<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1191\n",
      "test_file_ending ...\n",
      "\n",
      "\n",
      "____________________\n",
      "arabic\n",
      "test_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1182/1182 [13:59<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1182\n",
      "test_file_ending ...\n",
      "\n",
      "\n",
      "____________________\n",
      "korean\n",
      "test_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1224/1224 [13:52<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1224\n",
      "test_file_ending ...\n",
      "\n",
      "\n",
      "____________________\n",
      "vietnamese\n",
      "test_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1224/1224 [10:01<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1224\n",
      "test_file_ending ...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# base_dir = 'accent-without/'\n",
    "\n",
    "# accents = ['hindi', 'chinese', 'spanish', 'arabic', 'korean', 'vietnamese']\n",
    "\n",
    "# for accent in accents:\n",
    "#     manifests_path = base_dir + accent + '/manifests/'\n",
    "#     print('_'*20)\n",
    "#     print(accent)\n",
    "\n",
    "# #     seed_file_dir = manifests_path + 'seed.json'\n",
    "# #     seed_file = open(seed_file_dir)\n",
    "# #     seed_list = [json.loads(line.strip()) for line in seed_file]\n",
    "\n",
    "# #     print('seed_file_starting')\n",
    "# #     print(seed_file_dir)\n",
    "# #     extract_features(seed_list, seed_file_dir)\n",
    "# #     print(len(seed_list))\n",
    "# #     print('seed_file_ending ...\\n')\n",
    "    \n",
    "    \n",
    "# #     selection_file_dir = manifests_path + 'selection.json'\n",
    "# #     selection_file = open(selection_file_dir)\n",
    "# #     selection_list = [json.loads(line.strip()) for line in selection_file]\n",
    "    \n",
    "# #     print('selection_file_starting')\n",
    "# #     extract_features(selection_list, selection_file_dir)\n",
    "# #     print(len(selection_list))\n",
    "# #     print('selection_file_ending ...\\n\\n')\n",
    "    \n",
    "    \n",
    "#     test_file_dir = manifests_path + 'test.json'\n",
    "#     test_file = open(test_file_dir)\n",
    "#     test_list = [json.loads(line.strip()) for line in test_file]\n",
    "\n",
    "#     print('test_file_starting')\n",
    "#     extract_features(test_list, test_file_dir)\n",
    "#     print(len(test_list))\n",
    "#     print('test_file_ending ...\\n\\n')\n",
    "    \n",
    "    \n",
    "# #     dev_file_dir = manifests_path + 'dev.json'\n",
    "# #     dev_file = open(dev_file_dir)\n",
    "# #     dev_list = [json.loads(line.strip()) for line in dev_file]\n",
    "\n",
    "# #     print('dev_file_starting')\n",
    "# #     print(dev_file_dir)\n",
    "# #     extract_features(dev_list, dev_file_dir)\n",
    "# #     print(len(dev_list))\n",
    "# #     print('dev_file_ending ...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeb8396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsons_path = '.json'\n",
    "# jsons = [f.name for f in os.scandir('../MCV_accent/invalidated/') if '.json' in f.name and f.name.split('.')[0] not in ['unlabelled',\n",
    "# def path_proc(pth):\n",
    "#     return pth.replace('./', '~/MTP/begin_again/Error-Driven-ASR-Personalization/mz-expts/')                                                                                                            'other']]\n",
    "# print(jsons)\n",
    "\n",
    "# for file in tqdm(jsons):\n",
    "#     print('_'*20)\n",
    "    \n",
    "    \n",
    "#     json_file_path = '../MCV_accent/invalidated/' + file \n",
    "#     json_file = open(json_file_path)\n",
    "#     json_list = [json.loads(line.strip()) for line in json_file]\n",
    "#     print(json_file_path)\n",
    "    \n",
    "#     extract_features(json_list, json_file_path)\n",
    "#     print(len(json_list))\n",
    "#     print('_'*20, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719382b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f931774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde4bb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7fc71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w2v2",
   "language": "python",
   "name": "w2v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
