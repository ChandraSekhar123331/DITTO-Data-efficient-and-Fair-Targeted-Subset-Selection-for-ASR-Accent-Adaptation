{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os, sys\n",
    "import json\n",
    "import argparse\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from collections import Counter\n",
    "import time\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import submodlib\n",
    "from submodlib.helper import create_kernel\n",
    "from submodlib.functions.facilityLocationMutualInformation import FacilityLocationMutualInformationFunction\n",
    "from submodlib.functions.facilityLocationVariantMutualInformation import FacilityLocationVariantMutualInformationFunction\n",
    "from submodlib.functions.graphCutMutualInformation import GraphCutMutualInformationFunction\n",
    "from submodlib.functions.logDeterminantMutualInformation import LogDeterminantMutualInformationFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_set': 'k', 'selected_set': 'r', 'test_set': 'b', 'ABA': 'c', 'SKA': 'c', 'YBAA': 'c', 'ZHAA': 'c', 'BWC': 'y', 'LXC': 'y', 'NCC': 'y', 'TXHC': 'y', 'ASI': 'm', 'RRBI': 'm', 'SVBI': 'm', 'TNI': 'm', 'HJK': 'orange', 'HKK': 'orange', 'YDCK': 'orange', 'YKWK': 'orange', 'EBVS': 'limegreen', 'ERMS': 'limegreen', 'MBMPS': 'limegreen', 'NJS': 'limegreen', 'HQTV': 'yellow', 'PNV': 'yellow', 'THV': 'yellow', 'TLV': 'yellow'}\n"
     ]
    }
   ],
   "source": [
    "accent_map = {\"ABA\":\"arabic\",\"SKA\":\"arabic\",\"YBAA\":\"arabic\",\"ZHAA\":\"arabic\",\n",
    "              \"BWC\":\"chinese\",\"LXC\":\"chinese\",\"NCC\":\"chinese\",\"TXHC\":\"chinese\",\n",
    "              \"ASI\":\"hindi\",\"RRBI\":\"hindi\",\"SVBI\":\"hindi\",\"TNI\":\"hindi\",\n",
    "              \"HJK\":\"korean\",\"HKK\":\"korean\",\"YDCK\":\"korean\",\"YKWK\":\"korean\",\n",
    "              \"EBVS\":\"spanish\",\"ERMS\":\"spanish\",\"MBMPS\":\"spanish\",\"NJS\":\"spanish\",\n",
    "              \"HQTV\":\"vietnamese\",\"PNV\":\"vietnamese\",\"THV\":\"vietnamese\",\"TLV\":\"vietnamese\"\n",
    "              }\n",
    "\n",
    "def _color_map(dirs):\n",
    "    color_map = {}\n",
    "    accent_color_map = {}\n",
    "    for accent, color in zip(['arabic', 'hindi', 'chinese', 'spanish', 'korean', 'vietnamese'],\n",
    "                             ['c', 'm', 'y', 'limegreen', 'orange', 'yellow']):\n",
    "        accent_color_map[accent] = color\n",
    "    for _dir, color in zip(['query_set', 'selected_set', 'test_set'], ['k', 'r', 'b']):\n",
    "        color_map[_dir] = color\n",
    "    for _dir in dirs:\n",
    "        color_map[_dir] = accent_color_map[accent_map[_dir]]\n",
    "    for accent in ['arabic', 'hindi', 'chinese', 'spanish', 'korean', 'vietnamese']:\n",
    "        for _dir in dirs:\n",
    "            if accent_map[_dir]==accent:\n",
    "                color_map[_dir] = accent_color_map[accent]\n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_PCA(X, y, _dirs, pca_result, extra_result, label_map, _ax, color_map, marker_sizes):\n",
    "    feat_cols = ['dim'+str(i) for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(X, columns=feat_cols)\n",
    "    df['y'] = y\n",
    "    label_map = dict(enumerate(_dirs))\n",
    "    df['label'] = df['y'].apply(lambda i: label_map[i])\n",
    "    df['pca-one'] = np.concatenate([pca_result[:,0], extra_result[:, 0]], axis=0)\n",
    "    df['pca-two'] = np.concatenate([pca_result[:,1], extra_result[:, 1]], axis=0)\n",
    "    g = sns.scatterplot(\n",
    "        x=\"pca-one\", y=\"pca-two\",\n",
    "        hue=\"label\",\n",
    "        palette=color_map,\n",
    "        data=df,\n",
    "        legend=\"full\",\n",
    "        alpha=0.6,\n",
    "        s=marker_sizes,\n",
    "        ax = _ax\n",
    "    )\n",
    "    g.legend(loc='center right', bbox_to_anchor=(0.05, 0.9))\n",
    "\n",
    "def _plot_TSNE(X, y, _dirs, _ax, color_map, markers, marker_sizes):\n",
    "    feat_cols = ['dim'+str(i) for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(X, columns=feat_cols)\n",
    "    df['y'] = y\n",
    "\n",
    "    label_map = dict(enumerate(_dirs))\n",
    "    df['label'] = df['y'].apply(lambda i: label_map[i])\n",
    "    \n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "    tsne_results = tsne.fit_transform(df[feat_cols].values)\n",
    "\n",
    "    df['tsne-2d-one'] = tsne_results[:,0]\n",
    "    df['tsne-2d-two'] = tsne_results[:,1]\n",
    "\n",
    "    g = sns.scatterplot(\n",
    "        x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "        hue=\"label\",\n",
    "        palette=color_map,\n",
    "        data=df,\n",
    "        legend=\"full\",\n",
    "        alpha=0.6,\n",
    "        markers=markers,\n",
    "        s=marker_sizes,\n",
    "        ax = _ax\n",
    "    )\n",
    "    g.legend(loc='center right', bbox_to_anchor=(0.05, 0.9))\n",
    "\n",
    "\n",
    "def plot_TSNE(dirs, run_dir, ground_features, ground_features_Y, query_features, test_features, selected_indices, selected_gains, fxn):\n",
    "    n = len(dirs)\n",
    "    selected_features = ground_features[selected_indices]\n",
    "    color_map = _color_map(dirs)\n",
    "    fig = plt.figure(figsize=(30,30))\n",
    "\n",
    "#    _ax = fig.add_subplot(3,2,1)\n",
    "    _ax = fig.add_subplot(2,2,1)\n",
    "    X = np.concatenate([ground_features, query_features, selected_features], axis=0)\n",
    "    y = np.concatenate([ground_features_Y, np.zeros((len(query_features), 1))+n, np.zeros((len(selected_features), 1))+n+1], axis=0)\n",
    "    marker_sizes = np.concatenate([np.zeros((len(ground_features),))+5, np.zeros((len(query_features),))+20, np.zeros((len(selected_features),))+20], axis=0)\n",
    "    _plot_TSNE(X, y, dirs+['query_set', 'selected_set'], _ax, color_map, [',']*len(dirs)+['.', '*'], marker_sizes)\n",
    "\n",
    "# #    _ax = fig.add_subplot(3,2,3)\n",
    "# #    X = np.concatenate([ground_features], axis=0)\n",
    "# #    y = np.concatenate([ground_features_Y], axis=0)\n",
    "# #    _plot_TSNE(X, y, dirs, _ax, color_map, [',']*len(dirs))\n",
    "\n",
    "# #    _ax = fig.add_subplot(3,2,5)    \n",
    "# #    X = np.concatenate([ground_features, test_features], axis=0)\n",
    "# #    y = np.concatenate([ground_features_Y, np.zeros((len(test_features), 1))+n], axis=0)\n",
    "# #    _plot_TSNE(X, y, dirs+['test_set'], _ax, color_map, [',']*len(dirs)+['1'])\n",
    "\n",
    "# #    _ax = fig.add_subplot(3,2,6)    \n",
    "    _ax = fig.add_subplot(2,2,3)    \n",
    "    X = np.concatenate([ground_features, test_features, query_features, selected_features], axis=0)\n",
    "    y = np.concatenate([ground_features_Y, np.zeros((len(test_features), 1))+n, np.zeros((len(query_features), 1))+n+1, np.zeros((len(selected_features), 1)) + n + 2], axis=0)\n",
    "    marker_sizes = np.concatenate([np.zeros((len(ground_features),))+5, np.zeros((len(test_features),))+20, np.zeros((len(query_features),))+20, np.zeros((len(selected_features),))+20], axis=0)\n",
    "    _plot_TSNE(X, y, dirs+['test_set', 'query_set', 'selected_set'], _ax, color_map, [',']*len(dirs)+['.', '1', '*'], marker_sizes)\n",
    "    \n",
    "# #    _ax = fig.add_subplot(3,2,2)    \n",
    "    _ax = fig.add_subplot(2,2,2)    \n",
    "    _ax.bar(range(len(selected_features)), selected_gains, color ='maroon', width = 0.4)\n",
    "    _ax.set_xlabel('samples')\n",
    "    _ax.set_ylabel('gains')\n",
    "\n",
    "    fig.suptitle(fxn, fontsize = 34, fontweight ='bold')\n",
    "    plt.savefig(run_dir+'/plots/TSNE_visualization_mole.png')\n",
    "\n",
    "def plot_PCA(dirs, run_dir, ground_features, ground_features_Y, query_features, test_features, selected_indices, selected_gains, fxn):\n",
    "    n = len(dirs)\n",
    "    selected_features = ground_features[selected_indices]\n",
    "    color_map = _color_map(dirs)\n",
    "    fig = plt.figure(figsize=(30,30))\n",
    "    pca = PCA(n_components=3)\n",
    "\n",
    "    _ax = fig.add_subplot(3,2,3)\n",
    "    X = np.concatenate([ground_features], axis=0)\n",
    "    marker_sizes = np.concatenate([np.zeros((len(ground_features),))+5], axis=0)\n",
    "    y = np.concatenate([ground_features_Y], axis=0)\n",
    "\n",
    "    feat_cols = ['dim'+str(i) for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(X, columns=feat_cols)\n",
    "    df['y'] = y\n",
    "    label_map = dict(enumerate(dirs))\n",
    "    df['label'] = df['y'].apply(lambda i: label_map[i])\n",
    "\n",
    "    pca_result = pca.fit_transform(df[feat_cols].values)\n",
    "    df['pca-one'] = pca_result[:,0]\n",
    "    df['pca-two'] = pca_result[:,1] \n",
    "    df['pca-three'] = pca_result[:,2]\n",
    "\n",
    "    _ax = fig.add_subplot(3,2,3)\n",
    "    g = sns.scatterplot(\n",
    "        x=\"pca-one\", y=\"pca-two\",\n",
    "        hue=\"label\",\n",
    "        palette=color_map, \n",
    "        data=df,\n",
    "        legend=\"full\",\n",
    "        alpha=0.6,\n",
    "        s=marker_sizes,\n",
    "        ax = _ax\n",
    "    )\n",
    "    g.legend(loc='center right', bbox_to_anchor=(0.05, 0.9))\n",
    "\n",
    "    query_select_transform = pca.transform(np.concatenate([query_features, selected_features], axis=0))\n",
    "    test_transform = pca.transform(test_features)\n",
    "    query_select_test_transform = pca.transform(np.concatenate([test_features, query_features, selected_features], axis=0))\n",
    "\n",
    "    X = np.concatenate([ground_features, query_features, selected_features], axis=0)\n",
    "    marker_sizes = np.concatenate([np.zeros((len(ground_features),))+5, np.zeros((len(query_features),))+20, np.zeros((len(selected_features),))+20], axis=0)\n",
    "    y = np.concatenate([ground_features_Y, np.zeros((len(query_features), 1))+n, np.zeros((len(selected_features), 1))+n+1], axis=0)\n",
    "    _ax = fig.add_subplot(3,2,1)\n",
    "    _plot_PCA(X, y, dirs+['query_set', 'selected_set'], pca_result, query_select_transform, label_map, _ax, color_map, marker_sizes)\n",
    "\n",
    "    _ax = fig.add_subplot(3,2,5)\n",
    "    X = np.concatenate([ground_features, test_features], axis=0)\n",
    "    marker_sizes = np.concatenate([np.zeros((len(ground_features),))+5, np.zeros((len(test_features),))+20,], axis=0)\n",
    "    y = np.concatenate([ground_features_Y, np.zeros((len(test_features), 1))+n], axis=0)    \n",
    "    _plot_PCA(X, y, dirs+['test_set'], pca_result, test_transform, label_map, _ax, color_map, marker_sizes)\n",
    "\n",
    "    _ax = fig.add_subplot(3,2,6)\n",
    "    X = np.concatenate([ground_features, test_features, query_features, selected_features], axis=0)\n",
    "    marker_sizes = np.concatenate([np.zeros((len(ground_features),))+5, np.zeros((len(test_features),))+20, np.zeros((len(query_features),))+20, np.zeros((len(selected_features),))+20], axis=0)\n",
    "    y = np.concatenate([ground_features_Y, np.zeros((len(test_features), 1))+n, np.zeros((len(query_features), 1))+n+1, np.zeros((len(selected_features), 1))+n+2], axis=0)\n",
    "    _plot_PCA(X, y, dirs+['test_set', 'query_set', 'selected_set'], pca_result, query_select_test_transform, label_map, _ax, color_map, marker_sizes)\n",
    "\n",
    "    _ax = fig.add_subplot(3,2,2)    \n",
    "    _ax.bar(range(len(selected_features)), selected_gains, color ='maroon', width = 0.4)\n",
    "    _ax.set_xlabel('samples')\n",
    "    _ax.set_ylabel('gains')\n",
    "\n",
    "    fig.suptitle(fxn, fontsize = 14, fontweight ='bold')\n",
    "    plt.savefig(run_dir+'/plots/PCA_visualization_mole.png')\n",
    "\n",
    "def plots(dirs, run_dir, ground_features, ground_features_Y, query_features, test_features, selected_indices, selected_gains, fxn):\n",
    "    plot_TSNE(dirs, run_dir, ground_features, ground_features_Y, query_features, test_features, selected_indices, selected_gains, fxn)  \n",
    "    plot_PCA(dirs, run_dir, ground_features, ground_features_Y, query_features, test_features, selected_indices, selected_gains, fxn)\n",
    "\n",
    "#    X = np.concatenate([ground_features, query_features, ground_features[selected_indices]], axis=0)\n",
    "#    y = np.concatenate([ground_features_Y, np.zeros((len(query_features), 1)) + len(dirs), np.zeros((len(selected_indices), 1)) + len(dirs) + 1], axis=0)\n",
    "#    print(X.shape, ground_features.shape, query_features.shape, len(selected_indices))\n",
    "#    print(y.shape, ground_features_Y.shape)\n",
    "#    \n",
    "#    feat_cols = ['dim'+str(i) for i in range(X.shape[1])]\n",
    "#    df = pd.DataFrame(X, columns=feat_cols)\n",
    "#    df['y'] = y\n",
    "#    \n",
    "#    label_map = dict(enumerate(dirs + ['query_set', 'selected_set']))\n",
    "#    df['label'] = df['y'].apply(lambda i: label_map[i])\n",
    "#    \n",
    "#    tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "#    tsne_results = tsne.fit_transform(df[feat_cols].values)\n",
    "#    \n",
    "#    df['tsne-2d-one'] = tsne_results[:,0]\n",
    "#    df['tsne-2d-two'] = tsne_results[:,1]\n",
    "#\n",
    "#    color_map = _color_map(dirs)\n",
    "#    fig = plt.figure(figsize=(20,10))\n",
    "#    \n",
    "#    ax = fig.add_subplot(1,2,1)\n",
    "#    g = sns.scatterplot(\n",
    "#        x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "#        hue=\"label\",\n",
    "#        palette=color_map,\n",
    "#        data=df,\n",
    "#        legend=\"full\",\n",
    "#        alpha=0.6, \n",
    "#        ax = ax\n",
    "#    )\n",
    "#    g.legend(loc='center right', bbox_to_anchor=(0.05, 0.9))\n",
    "#    \n",
    "#    ax = fig.add_subplot(1,2,2)\n",
    "#    ax.bar(range(len(selected_indices)), selected_gains, color ='maroon', width = 0.4)\n",
    "#    ax.set_xlabel('samples')\n",
    "#    ax.set_ylabel('gains')\n",
    "#    \n",
    "#    fig.suptitle(fxn, fontsize = 14, fontweight ='bold')\n",
    "#    plt.savefig(run_dir+'/plots/visualization.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subset(dirs, base_dir, query_dir, ground_list, ground_features, ground_features_Y, query_list, query_features, test_features, greedyList, budget_size, target_size, speaker, fxn, similarity, etaValue, feature_type):\n",
    "    list_total_selection, list_total_count, list_total_duration = [], [], []\n",
    "    list_speaker_sample_count, list_speaker_sample_duration = [], []\n",
    "    output_dir = os.path.join(base_dir, query_dir, f'TSS_output/all/budget_{budget_size}/target_{target_size}/{fxn}/eta_{etaValue}/{similarity}/{feature_type}')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for i in [1, 2, 3]:\n",
    "        run = f'run_{i}'\n",
    "        run_dir = os.path.join(output_dir, run)\n",
    "        for folder in ['train', 'output', 'plots']:\n",
    "            os.makedirs(os.path.join(run_dir, folder), exist_ok=True)\n",
    "            \n",
    "        all_indices = [j[0] for j in greedyList]\n",
    "        all_gains = [j[1] for j in greedyList]\n",
    "        total_duration, index = 0, 0\n",
    "        while total_duration + ground_list[all_indices[index]]['duration'] <= 360:\n",
    "            total_duration += ground_list[all_indices[index]]['duration']\n",
    "            index += 1\n",
    "\n",
    "        list_total_count.append(index)\n",
    "        list_total_duration.append(total_duration)\n",
    "        selected_indices = all_indices[:index]\n",
    "        selected_gains = all_gains[:index]\n",
    "        selected_list = [ground_list[j] for j in selected_indices]\n",
    "        train_list = selected_list + query_list\n",
    "        \n",
    "        speaker_sample_count, speaker_sample_duration = 0, 0\n",
    "        for item in selected_list:\n",
    "            if accent_map[item['audio_filepath'].split('/')[-3]] == accent_map[speaker]:\n",
    "                speaker_sample_count += 1\n",
    "                speaker_sample_duration += item['duration']\n",
    "        list_speaker_sample_count.append(speaker_sample_count)\n",
    "        list_speaker_sample_duration.append(speaker_sample_duration)\n",
    "        list_total_selection.append(Counter([item['audio_filepath'].split('/')[-3] for item in selected_list]))\n",
    "        \n",
    "#        with open(base_dir + query_dir + f'train/error_model/{budget_size}/seed_{i}/train.json', 'w') as f:\n",
    "#            for line in train_list:\n",
    "#                f.write('{}\\n'.format(json.dumps(line)))\n",
    "\n",
    "#         with open(f'{run_dir}/train/train.json', 'w') as f:\n",
    "#             for line in train_list:\n",
    "#                 f.write('{}\\n'.format(json.dumps(line)))\n",
    "        plots(dirs, run_dir, ground_features, ground_features_Y, query_features, test_features, selected_indices, selected_gains, fxn)\n",
    "    print('\\n subset computed .... \\n')\n",
    "    stats = 'total selection : ' + ' '.join(map(str, list_total_count)) + ' -> {0:.2f}\\n'.format(statistics.mean(list_total_count))\n",
    "    stats += 'total selection duration: ' + ' '.join(map(str, list_total_duration)) + ' -> {0:.2f}\\n'.format(statistics.mean(list_total_duration))\n",
    "    stats += 'speaker selection: ' + ' '.join(map(str, list_speaker_sample_count)) + ' -> {0:.2f}\\n'.format(statistics.mean(list_speaker_sample_count))\n",
    "    stats += 'speaker duration: ' + ' '.join(map(str, list_speaker_sample_duration)) + ' -> {0:.2f}\\n'.format(statistics.mean(list_speaker_sample_duration))\n",
    "    stats += '\\nall selections: ' + str(list_total_selection)\n",
    "    \n",
    "    with open(output_dir + '/stats_mole.txt', 'w') as f:\n",
    "        f.write(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_greedyList(ground_kernel, query_kernel, query_query_kernel, fxn, budget_size, etaValue):\n",
    "    print(f'\\ncreating {fxn} object\\n')\n",
    "    if fxn == 'FL1MI':\n",
    "        obj1 = FacilityLocationMutualInformationFunction(n=len(ground_kernel), num_queries=query_kernel.shape[1], query_sijs=query_kernel, data_sijs=ground_kernel, magnificationEta=etaValue)\n",
    "    elif fxn == 'FL2MI':\n",
    "        obj1 = FacilityLocationVariantMutualInformationFunction(n=len(ground_kernel), num_queries=query_kernel.shape[1], query_sijs=query_kernel, queryDiversityEta=etaValue)\n",
    "    elif fxn == 'GCMI':\n",
    "        obj1 = GraphCutMutualInformationFunction(n=len(ground_kernel), num_queries=query_kernel.shape[1], query_sijs=query_kernel)\n",
    "    elif fxn == 'LogDMI':\n",
    "        obj1 = LogDeterminantMutualInformationFunction(n=len(ground_kernel), num_queries=query_kernel.shape[1], lambdaVal=1, query_sijs=query_kernel, data_sijs=ground_kernel, query_query_sijs=query_query_kernel, magnificationEta=etaValue)\n",
    "    else:\n",
    "        print('\\n\\n\\n............... ERROR not a valid FUNCTION ............\\n\\n\\n')\n",
    "        exit()\n",
    "    print(f'\\n{fxn} object created\\n')\n",
    "    print('\\ngenerating greedyList...\\n') \n",
    "    greedyList = obj1.maximize(budget=3*budget_size, optimizer='LazyGreedy', stopIfZeroGain=False, stopIfNegativeGain=False, epsilon=0.1, verbose=False)\n",
    "    print('\\n.... greedyList generated ... \\n')\n",
    "    return greedyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(file_dir, feature_type):\n",
    "    features = []\n",
    "    with open(file_dir.replace('.json', f'_{feature_type}.file'), 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                features.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                break\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    print(features.shape)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(base_dir, target_size, budget_size, speaker, similarity, feature_type):\n",
    "#    dirs = ['kannada_male_english', 'malayalam_male_english', 'rajasthani_male_english', 'hindi_male_english', 'tamil_male_english', 'gujarati_female_english', 'manipuri_female_english', 'assamese_female_english']\n",
    "    dirs = [f.name for f in os.scandir('/home/mayank/MTP/begin_again/Error-Driven-ASR-Personalization/CMU_expts/speaker_without/') if f.is_dir()]\n",
    "    dirs.remove('.ipynb_checkpoints')\n",
    "    dirs.remove('reserved_TSS_output')\n",
    "    dirs.remove(speaker)\n",
    "\n",
    "    query_dir = f'{speaker}/manifests/' \n",
    "    query_file_path = base_dir + query_dir + 'seed.json'\n",
    "    query_list = [json.loads(line.strip()) for line in open(query_file_path)]\n",
    "    query_features = load_features(query_file_path, feature_type)\n",
    "    query_list, query_features = query_list[:target_size], query_features[:target_size]\n",
    "\n",
    "    ground_list, ground_list_Y, ground_features = [], [], []\n",
    "    for i, _dir in enumerate(dirs):\n",
    "#         if _dir==speaker:\n",
    "#             continue\n",
    "#         print(\"base: {}\".format(base_dir), \"dir: {}\".format(_dir))\n",
    "        selection_file_path = base_dir + _dir + '/manifests/selection.json'\n",
    "        selection_file_list = [json.loads(line.strip()) for line in open(selection_file_path)]\n",
    "        if accent_map[speaker]!=accent_map[_dir]:\n",
    "            selection_file_list=selection_file_list[:3*len(selection_file_list)//4]\n",
    "        ground_list.extend(selection_file_list[:])\n",
    "        ground_features.append(load_features(selection_file_path, feature_type))\n",
    "        ground_list_Y.extend([i]*len(selection_file_list))   \n",
    "    ground_features = np.concatenate(ground_features, axis=0)\n",
    "    ground_features_Y = np.asarray(ground_list_Y).reshape(-1, 1) \n",
    "\n",
    "    ### test file\n",
    "    test_file_path = base_dir + query_dir + 'test.json'\n",
    "    test_list = [json.loads(line.strip()) for line in open(test_file_path)]\n",
    "    test_features = load_features(test_file_path, feature_type)\n",
    "\n",
    "    print(len(ground_list), ground_features.shape)\n",
    "    print(len(query_list), query_features.shape)\n",
    "    print(len(test_list), test_features.shape)\n",
    "\n",
    "    print('creating kernels ....')\n",
    "    t1 = time.time()\n",
    "    ground_kernel = create_kernel(ground_features, metric=similarity, mode='dense')\n",
    "    query_kernel = create_kernel(query_features, metric=similarity, mode='dense', X_rep=ground_features)\n",
    "    query_query_kernel = create_kernel(query_features, metric=similarity, mode='dense', X_rep=query_features)\n",
    "    t2 = time.time()\n",
    "    print('kernel creation done ....', t2-t1)\n",
    "\n",
    "    print('ground_kernel: ', ground_kernel.shape)\n",
    "    print('query_kernel: ', query_kernel.shape)\n",
    "    print('query_query_kernel: ', query_query_kernel.shape)\n",
    "\n",
    "    return dirs, query_dir, ground_list, ground_features, ground_features_Y, ground_kernel, query_list, query_features, query_kernel, query_query_kernel, test_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 39)\n",
      "base:  dir: THV\n",
      "(742, 39)\n",
      "base:  dir: YKWK\n",
      "(741, 39)\n",
      "base:  dir: ERMS\n",
      "(742, 39)\n",
      "base:  dir: BWC\n",
      "(741, 39)\n",
      "base:  dir: ASI\n",
      "(741, 39)\n",
      "base:  dir: YDCK\n",
      "(741, 39)\n",
      "base:  dir: TNI\n",
      "(741, 39)\n",
      "base:  dir: YBAA\n",
      "(741, 39)\n",
      "base:  dir: TXHC\n",
      "(742, 39)\n",
      "base:  dir: ZHAA\n",
      "(742, 39)\n",
      "base:  dir: LXC\n",
      "(741, 39)\n",
      "base:  dir: MBMPS\n",
      "(742, 39)\n",
      "base:  dir: RRBI\n",
      "(741, 39)\n",
      "base:  dir: NCC\n",
      "(741, 39)\n",
      "base:  dir: HJK\n",
      "(741, 39)\n",
      "base:  dir: HKK\n",
      "(741, 39)\n",
      "base:  dir: TLV\n",
      "(742, 39)\n",
      "base:  dir: SVBI\n",
      "(742, 39)\n",
      "base:  dir: EBVS\n",
      "(654, 39)\n",
      "base:  dir: HQTV\n",
      "(742, 39)\n",
      "base:  dir: NJS\n",
      "(741, 39)\n",
      "base:  dir: SKA\n",
      "(631, 39)\n",
      "base:  dir: PNV\n",
      "(742, 39)\n",
      "(306, 39)\n",
      "13157 (16855, 39)\n",
      "50 (50, 39)\n",
      "306 (306, 39)\n",
      "creating kernels ....\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "create_kernel() got an unexpected keyword argument 'X_rep'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ea5e212a398b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_features_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_query_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbudget_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeaker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-6158227e4058>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(base_dir, target_size, budget_size, speaker, similarity, feature_type)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mground_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dense'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mquery_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dense'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mground_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mquery_query_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dense'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: create_kernel() got an unexpected keyword argument 'X_rep'"
     ]
    }
   ],
   "source": [
    "fxns=['FL1MI' 'FL2MI' 'GCMI' 'LogDMI']\n",
    "\n",
    "target_size=50\n",
    "budget_size=100\n",
    "etaValue=1.1\n",
    "similarity=\"euclidean\"\n",
    "fxn=fxns[0]\n",
    "speaker=\"ABA\"\n",
    "feature_type=\"39\"\n",
    "base_dir = ''\n",
    "\n",
    "dirs, query_dir, ground_list, ground_features, ground_features_Y, ground_kernel, query_list, query_features, query_kernel, query_query_kernel, test_features = preprocess(base_dir, target_size, budget_size, speaker, similarity, feature_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedyList = generate_greedyList(ground_kernel, query_kernel, query_query_kernel, fxn, budget_size, etaValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_subset(dirs, base_dir, query_dir, ground_list, ground_features, ground_features_Y, query_list, query_features, test_features, greedyList, budget_size, target_size, speaker, fxn, similarity, etaValue, feature_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
