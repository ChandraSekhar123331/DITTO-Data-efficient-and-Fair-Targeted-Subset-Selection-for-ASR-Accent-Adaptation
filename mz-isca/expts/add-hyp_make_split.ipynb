{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d88a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['african', 'indian', 'hongkong', 'philippines', 'england', 'scotland', 'ireland', 'australia', 'canada', 'us', 'bermuda', 'southatlandtic', 'wales', 'malaysia']\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import librosa, glob, sys, pickle, random, re, os, csv, pathlib, ast, os.path, json\n",
    "import pandas as pd\n",
    "from statistics import mean, variance\n",
    "from tqdm import tqdm\n",
    "accents = ['african', 'indian', 'hongkong', 'philippines', \n",
    "           'england', 'scotland', 'ireland', 'australia', \n",
    "           'canada', 'us', \n",
    "           'bermuda', 'southatlandtic', 'wales', 'malaysia']\n",
    "print(accents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "712e5169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1685 1685\n"
     ]
    }
   ],
   "source": [
    "# for accent in accents:\n",
    "for accent in ['malaysia']:\n",
    "    all_file_path = \"{}/manifests/quartznet_outputs/all.txt\".format(accent)\n",
    "    \n",
    "    ref_hyp_file = open(all_file_path, 'r')\n",
    "    paragraphs = ref_hyp_file.read().strip().split('\\n\\n')\n",
    "    hyp_list = [para.strip().split('\\n')[4][5:] for para in paragraphs]\n",
    "    \n",
    "    all_json_path = \"{}/manifests/all.json\".format(accent)\n",
    "    all_json = open(all_json_path, 'r')\n",
    "    samples = all_json.readlines()\n",
    "    \n",
    "    new_json_file = open(\"{}/all.json\".format(accent), 'w')\n",
    "    new_json_samples = []\n",
    "    print(len(hyp_list), len(samples))\n",
    "    for sample, hyp in zip(samples, hyp_list):\n",
    "        new_dict = json.loads(sample)\n",
    "        new_dict['pseudo_text'] = hyp\n",
    "        json.dump(new_dict, new_json_file)\n",
    "        new_json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1ec688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = \"rajasthani_male_english\"\n",
    "all_file_path = \"{}/manifests/quartznet_outputs/all.txt\".format(speaker)\n",
    "    \n",
    "ref_hyp_file = open(all_file_path, 'r')\n",
    "paragraphs = ref_hyp_file.read().strip().split('\\n\\n')\n",
    "hyp_list = [para.strip().split('\\n')[4][5:] for para in paragraphs]\n",
    "    \n",
    "all_json_path = \"{}/manifests/all.json\".format(speaker)\n",
    "all_json = open(all_json_path, 'r')\n",
    "samples = all_json.readlines()\n",
    "    \n",
    "new_json_file = open(\"{}/all.json\".format(speaker), 'w')\n",
    "new_json_samples = []\n",
    "for sample, hyp in zip(samples, hyp_list):\n",
    "    new_dict = json.loads(sample)\n",
    "    new_dict['pseudo_text'] = hyp\n",
    "    json.dump(new_dict, new_json_file)\n",
    "    new_json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "096ce533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write(json_path, items, file):\n",
    "    with open(json_path+file, 'w') as f:\n",
    "        for item in tqdm(items):\n",
    "            json.dump(item, f)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69254685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, selection, seed, dev, seed_plus_dev, test for tamil_male_english\n",
      "[7546, 5282, 50, 50, 100, 2037]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 31521.90it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 20313.37it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 26810.94it/s]\n",
      "100%|██████████| 2037/2037 [00:00<00:00, 40884.30it/s]\n",
      "100%|██████████| 5282/5282 [00:00<00:00, 51243.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, selection, seed, dev, seed_plus_dev, test for gujarati_female_english\n",
      "[4670, 3269, 50, 50, 100, 1260]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 22192.08it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 30318.81it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 38304.15it/s]\n",
      "100%|██████████| 1260/1260 [00:00<00:00, 52194.75it/s]\n",
      "100%|██████████| 3269/3269 [00:00<00:00, 57020.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, selection, seed, dev, seed_plus_dev, test for kannada_male_english\n",
      "[4777, 3343, 50, 50, 100, 1290]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 17210.93it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 18997.66it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 23090.03it/s]\n",
      "100%|██████████| 1290/1290 [00:00<00:00, 43644.50it/s]\n",
      "100%|██████████| 3343/3343 [00:00<00:00, 53917.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, selection, seed, dev, seed_plus_dev, test for malayalam_male_english\n",
      "[5130, 3590, 50, 50, 100, 1386]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 22322.00it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 17164.45it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 20129.12it/s]\n",
      "100%|██████████| 1386/1386 [00:00<00:00, 39274.31it/s]\n",
      "100%|██████████| 3590/3590 [00:00<00:00, 45736.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, selection, seed, dev, seed_plus_dev, test for hindi_male_english\n",
      "[5131, 3591, 50, 50, 100, 1386]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 36339.49it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 40611.00it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 21920.69it/s]\n",
      "100%|██████████| 1386/1386 [00:00<00:00, 48889.92it/s]\n",
      "100%|██████████| 3591/3591 [00:00<00:00, 55279.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, selection, seed, dev, seed_plus_dev, test for manipuri_female_english\n",
      "[10035, 7024, 50, 50, 100, 2709]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 35187.11it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 49182.74it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 48640.89it/s]\n",
      "100%|██████████| 2709/2709 [00:00<00:00, 41960.85it/s]\n",
      "100%|██████████| 7024/7024 [00:00<00:00, 56503.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, selection, seed, dev, seed_plus_dev, test for assamese_female_english\n",
      "[8378, 5864, 50, 50, 100, 2262]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 30301.29it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 46582.67it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 49496.15it/s]\n",
      "100%|██████████| 2262/2262 [00:00<00:00, 57314.60it/s]\n",
      "100%|██████████| 5864/5864 [00:00<00:00, 55168.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, selection, seed, dev, seed_plus_dev, test for rajasthani_male_english\n",
      "[4809, 3366, 50, 50, 100, 1298]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 36954.22it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 17140.60it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 18086.69it/s]\n",
      "100%|██████████| 1298/1298 [00:00<00:00, 35682.40it/s]\n",
      "100%|██████████| 3366/3366 [00:00<00:00, 56345.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for speaker in speakers:\n",
    "    json_path = speaker + '/'\n",
    "    with open(json_path+'all.json', 'r') as jd:\n",
    "        files = jd.readlines()\n",
    "        files = [json.loads(file) for file in files]\n",
    "        \n",
    "        random.seed(42)\n",
    "        random.shuffle(files)\n",
    "        \n",
    "        num_samples = len(files)\n",
    "        p70, p97, p97_50 = int(num_samples*.7), int(num_samples*.97), int(num_samples*.97)+50\n",
    "        \n",
    "        assert p97_50 <= num_samples-50\n",
    "        selection, test, dev, seed = files[:p70], files[p70:p97], files[p97:p97_50], files[num_samples-50:]\n",
    "        seed_plus_dev = seed+dev\n",
    "        \n",
    "        print(\"total, selection, seed, dev, seed_plus_dev, test for {}\".format(speaker))\n",
    "        print(list(map(len, [files, selection, seed, dev, seed_plus_dev, test])))\n",
    "        _write(json_path, seed, 'seed.json')\n",
    "        _write(json_path, dev, 'dev.json')\n",
    "        _write(json_path, seed_plus_dev, 'seed_plus_dev.json')\n",
    "        _write(json_path, test, 'test.json')\n",
    "        _write(json_path, selection, 'selection.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w2v2",
   "language": "python",
   "name": "w2v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
