{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a22f7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import librosa, glob, sys, json, pickle, os, random, linecache, statistics\n",
    "from tqdm import tqdm\n",
    "import pandas as pd, numpy as np\n",
    "from IPython.core.display import display, HTML\n",
    "from collections import Counter\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec2fbf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json(file_type, accent):\n",
    "    ref = open(f'{accent}/all.json', 'r')\n",
    "    files = ref.readlines()\n",
    "    files = [json.loads(file) for file in files]\n",
    "    path_dict = [(file[\"audio_filepath\"], file[\"pseudo_text\"]) for file in files]\n",
    "    path_dict = dict(path_dict)\n",
    "    json_file = open(f\"{accent}/manifests/{file_type}.json\", 'r')\n",
    "    samples = json_file.readlines()\n",
    "    new_json_file = open(f\"{accent}/{file_type}.json\", 'w')\n",
    "#     new_json_file = open(f\"{speaker}/temp.json\", 'w')\n",
    "    new_json_samples = []\n",
    "    for sample in samples:\n",
    "        new_dict = json.loads(sample)\n",
    "        new_dict['pseudo_text'] = path_dict[new_dict['audio_filepath']]\n",
    "        json.dump(new_dict, new_json_file)\n",
    "        new_json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "037b269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accents = ['african', 'indian', 'hongkong', 'philippines', \n",
    "           'england', 'scotland', 'ireland', 'australia', \n",
    "           'canada', 'us', \n",
    "           'bermuda', 'southatlandtic', 'wales', 'malaysia']\n",
    "file_types = [\"all\", \"test\", \"selection\", \"seed\", \"seed_plus_dev\", \"dev\"]\n",
    "for accent in accents:\n",
    "    for file_type in file_types:\n",
    "        if file_type in ['all', 'seed_plus_dev']: continue\n",
    "        convert_json(file_type, accent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a22e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "for accent in accents:\n",
    "    file_type = 'seed_plus_dev'\n",
    "    seed_file = open(f\"{accent}/seed.json\", 'r')\n",
    "    dev_file = open(f\"{accent}/dev.json\", 'r')\n",
    "    seed_samples = seed_file.readlines()\n",
    "    dev_samples = dev_file.readlines()\n",
    "    dev_samples = dev_samples[:50]\n",
    "    new_json_file = open(f\"{accent}/{file_type}.json\", 'w')\n",
    "    new_json_samples = []\n",
    "    samples = seed_samples+dev_samples\n",
    "    random.shuffle(samples)\n",
    "    for sample in samples:\n",
    "        json.dump(json.loads(sample), new_json_file)\n",
    "        new_json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701c46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up random selections\n",
    "accents = ['african', 'indian', 'hongkong', 'philippines', \n",
    "           'england', 'scotland', 'ireland', 'australia', \n",
    "           'canada', 'us', \n",
    "           'bermuda', 'southatlandtic', 'wales', 'malaysia']\n",
    "# random.seed(42)\n",
    "\n",
    "def _write(manifests_path, items, file):\n",
    "    with open(manifests_path+file, 'w') as f:\n",
    "        for item in items:\n",
    "            json.dump(item, f)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l */selection.json\n",
    "!wc -l random/all_selection.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2984ae0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350\n",
      "6200\n",
      "7200\n",
      "8550\n",
      "14100\n",
      "15450\n",
      "16450\n",
      "17800\n",
      "19850\n",
      "33800\n",
      "33800\n",
      "33800\n",
      "33800\n",
      "33800\n"
     ]
    }
   ],
   "source": [
    "global_files = []\n",
    "manifests_path = 'random/'\n",
    "\n",
    "for accent in accents:\n",
    "\taccent_json = open(accent+'/selection.json', 'r')\n",
    "\tfiles = accent_json.readlines()\n",
    "\tfiles = [json.loads(file) for file in files]\n",
    "\trandom.shuffle(files)\n",
    "\tglobal_files.extend(files)\n",
    "\tprint(len(global_files))\n",
    "\n",
    "random.shuffle(global_files)\n",
    "_write(manifests_path, global_files, 'all_selection.json')\n",
    "def budget(budget_size):\n",
    "    return int(5.4*budget_size)\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "ground_list = [json.loads(line.strip()) for line in open('random/all_selection.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1855e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for budget_size in [100, 200, 250, 300, 400, 500, 600, 700, 800, 1000, 2000, 2500, 3500]:\n",
    "    output_dir = 'random/{}'.format(budget_size)\n",
    "    list_total_selection, list_total_count, list_total_duration = [], [], []\n",
    "    list_accent_sample_count, list_accent_sample_duration = {}, {}\n",
    "    for accent in accents:\n",
    "        list_accent_sample_count[accent] = []\n",
    "        list_accent_sample_duration[accent] = []\n",
    "    \n",
    "    for i in [1, 2, 3]:\n",
    "        run = f'run_{i}'\n",
    "        run_dir = os.path.join(output_dir, run)\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "        # for folder in ['train', 'output', 'plots']:\n",
    "        #     os.makedirs(os.path.join(run_dir, folder))\n",
    "        all_indices = list(range(len(ground_list)))\n",
    "        random.seed(i)\n",
    "        random.shuffle(all_indices)\n",
    "        total_duration, index = 0, 0\n",
    "        while total_duration + ground_list[all_indices[index]]['duration'] <= budget(budget_size):\n",
    "            total_duration += ground_list[all_indices[index]]['duration']\n",
    "            index += 1\n",
    "        list_total_count.append(index)\n",
    "        list_total_duration.append(total_duration)\n",
    "        selected_indices = all_indices[:index]\n",
    "        selected_list = [ground_list[j] for j in selected_indices]\n",
    "\n",
    "#        train_list = selected_list + query_list\n",
    "        train_list = selected_list\n",
    "        \n",
    "        for accent in accents:\n",
    "            accent_sample_count, accent_sample_duration = 0, 0\n",
    "            for item in selected_list:\n",
    "                if item['audio_filepath'].split('/')[-4] == accent:\n",
    "                    accent_sample_count += 1\n",
    "                    accent_sample_duration += item['duration']\n",
    "            list_accent_sample_count[accent].append(accent_sample_count)\n",
    "            list_accent_sample_duration[accent].append(accent_sample_duration)\n",
    "        list_total_selection.append(Counter([item['audio_filepath'].split('/')[-4] for item in selected_list]))\n",
    "        \n",
    "#        with open(base_dir + query_dir + f'train/error_model/{budget_size}/seed_{i}/train.json', 'w') as f:\n",
    "#            for line in train_list:\n",
    "#                f.write('{}\\n'.format(json.dumps(line)))\n",
    "        with open(f'{run_dir}/train.json', 'w') as f:\n",
    "            for line in train_list:\n",
    "                f.write('{}\\n'.format(json.dumps(line)))\n",
    "                \n",
    "#        plots(dirs, run_dir, ground_features, ground_features_Y, query_features, test_features, selected_indices)\n",
    "    \n",
    "    stats = 'total selection : ' + ' '.join(map(str, list_total_count)) + ' -> {0:.2f}\\n'.format(statistics.mean(list_total_count))\n",
    "    stats += 'total selection duration: ' + ' '.join(map(str, list_total_duration)) + ' -> {0:.2f}\\n'.format(statistics.mean(list_total_duration))\n",
    "    for accent in accents:\n",
    "        stats += '\\naccent: {}\\n'.format(accent)\n",
    "        stats += 'accented selection: ' + ' '.join(map(str, list_accent_sample_count[accent])) + ' -> {0:.2f}\\n'.format(statistics.mean(list_accent_sample_count[accent]))\n",
    "        stats += 'accented duration: ' + ' '.join(map(str, list_accent_sample_duration[accent])) + ' -> {0:.2f}\\n'.format(statistics.mean(list_accent_sample_duration[accent]))\n",
    "    stats += '\\nall selections: ' + str(list_total_selection)\n",
    "    \n",
    "    with open(output_dir + '/stats.txt', 'w') as f:\n",
    "        f.write(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa626e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import json, os, torch, statistics, glob, librosa, pickle, torchaudio\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "mfcc_transform = T.MFCC(\n",
    "    sample_rate=22050,\n",
    "    n_mfcc=39,\n",
    "    melkwargs={\n",
    "      'n_fft': 2048,\n",
    "      'n_mels': 256,\n",
    "      'hop_length': 512,\n",
    "      'mel_scale': 'htk',\n",
    "    }\n",
    ")\n",
    "base_dir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b6d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_list, file_dir):\n",
    "    file_type = file_dir.split('/')[-1].replace('.json', '')\n",
    "    feature_dir = '/'.join(file_dir.split('/')[:-1])+'/39/'\n",
    "    os.makedirs(os.path.dirname(feature_dir), exist_ok=True)\n",
    "    feature_file = feature_dir+file_type+'_39.file'\n",
    "    with open(feature_file, 'wb') as f:\n",
    "        for file in tqdm(file_list):\n",
    "            waveform, sample_rate = torchaudio.load(file['audio_filepath'])\n",
    "            mfcc_features = mfcc_transform(waveform).mean(2).detach().numpy()\n",
    "            pickle.dump(mfcc_features, f)\n",
    "    print(\"completed\", file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6237e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = ['african', 'indian', 'hongkong', 'philippines', \n",
    "           'england', 'scotland', 'ireland', 'australia', \n",
    "           'canada', 'us', \n",
    "           'bermuda', 'southatlandtic', 'wales', 'malaysia']\n",
    "file_types = [\"test\", \"selection\", \"seed\"]\n",
    "for speaker in speakers:\n",
    "    print(speaker)\n",
    "    for file_type in file_types:\n",
    "#         print(file_type)\n",
    "        file_dir = f'{speaker}/{file_type}.json'\n",
    "        opened_file = open(file_dir)\n",
    "        json_list = [json.loads(line.strip()) for line in opened_file]\n",
    "        extract_features(json_list, file_dir)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc1db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_file_dir = 'assamese_female_english/seed.json'\n",
    "seed_file = open(seed_file_dir)\n",
    "seed_list = [json.loads(line.strip()) for line in seed_file]\n",
    "extract_features(seed_list, seed_file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a7757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration(json_file):\n",
    "    dur_list = [json.loads(line.strip())['duration'] for line in open(json_file)]\n",
    "    print(4.92*100, \"requested duration\")\n",
    "    print(int(4.92*len(dur_list)), \"is num_selected x 4.92\", f\"{len(dur_list)} samples\")\n",
    "    print(sum(dur_list), \"selected duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration('kannada_male_english/all/budget_200/target_20/FL2MI/39/budget_100/error_model/run_2/train.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w2v2",
   "language": "python",
   "name": "w2v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
