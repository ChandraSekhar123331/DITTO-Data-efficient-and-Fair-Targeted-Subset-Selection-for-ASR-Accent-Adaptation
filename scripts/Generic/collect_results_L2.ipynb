{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from cmath import inf\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from utils.dataset import Dataset, get_accent, get_path, update_config\n",
    "from utils.utils import read_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WER_test_file(test_file):\n",
    "    try:\n",
    "        txt_file = open(test_file, \"r\")\n",
    "        lines = txt_file.readlines()\n",
    "        matched = \"\"\n",
    "        for line in lines:\n",
    "            if \"==========>>>>>>Evaluation Greedy WER: \" in line:\n",
    "                txt_file.close()\n",
    "                return float(line.rstrip().split(\": \")[1])\n",
    "    except:\n",
    "        # txt_file.close()\n",
    "        print(test_file)\n",
    "        print(\"weiowdnio\")\n",
    "        return inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CER_test_file(test_file):\n",
    "    try:\n",
    "        txt_file = open(test_file, \"r\")\n",
    "        lines = txt_file.readlines()\n",
    "        matched = \"\"\n",
    "        for line in lines:\n",
    "            if \"==========>>>>>>Evaluation Greedy CER: \" in line:\n",
    "                txt_file.close()\n",
    "                return float(line.rstrip().split(\": \")[1])\n",
    "    except:\n",
    "        # txt_file.close()\n",
    "        print(test_file)\n",
    "        print(\"weiowdnio\")\n",
    "        return inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(path, dataset_name):\n",
    "    return str(Counter([get_accent(line, dataset_name)[:3] for line in read_lines(path)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accent_speech(path, accent, dataset_name):\n",
    "    lines = read_lines(path)\n",
    "    total_duration = round(np.sum([line[\"duration\"] for line in lines]), 2)\n",
    "    accented_duration = round(np.sum([line[\"duration\"] for line in lines if get_accent(line, dataset_name) == accent]), 2)\n",
    "    return f\"{accented_duration}/{total_duration}\", f\"{round(100 * accented_duration/total_duration, 2)}%\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_global_random(config):\n",
    "    expt_results = []\n",
    "    glob_str = f'{os.path.join(config[\"FULL_DATASET_PATH\"], \"*\", \"results\", \"budget_*\", \"global_random\")}'\n",
    "    # print(glob_str)\n",
    "    lst = glob(glob_str) \n",
    "\n",
    "    for setting in lst:\n",
    "        result = {}\n",
    "        path = setting\n",
    "        path = path.replace(f'{config[\"FULL_DATASET_PATH\"]}', \"\").strip(os.path.sep)\n",
    "        result[\"accent\"] = path.split(os.path.sep)[0]\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        assert path.split(os.path.sep[0])[0] == \"results\"\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        budget = path.split(os.path.sep)[0].replace(\"budget_\", \"\")\n",
    "        result[\"budget\"] = budget\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        assert path.split(os.path.sep[0])[0] == \"global_random\"\n",
    "        result[\"method\"] = path.split(os.path.sep[0])[0]\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        for run in range(1, 4):\n",
    "            test_path = os.path.join(setting, f\"run_{run}\", \"test_infer_log.txt\")\n",
    "            result[f\"WER-{run}\"] = WER_test_file(test_path)\n",
    "            result[f\"CER-{run}\"] = CER_test_file(test_path)\n",
    "            json_path = os.path.join(setting, f\"run_{run}\", \"train.json\")\n",
    "            result[f\"duration-{run}\"], result[f\"percent-{run}\"] = get_accent_speech(json_path, result[\"accent\"], dataset_name=config[\"dataset\"])\n",
    "            result[f\"counter-{run}\"] = get_counts(json_path, dataset_name=config[\"dataset\"])\n",
    "        # print(result)\n",
    "        \n",
    "        expt_results.append(result)\n",
    "    return expt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_global_entropy(config):\n",
    "    expt_results = []\n",
    "    glob_str = f'{os.path.join(config[\"FULL_DATASET_PATH\"], \"*\", \"results\", \"budget_*\", \"global_entropy\", \"agg_*\")}'\n",
    "    # print(glob_str)\n",
    "    lst = glob(glob_str) \n",
    "\n",
    "    for setting in lst:\n",
    "        result = {}\n",
    "        path = setting\n",
    "        path = path.replace(f'{config[\"FULL_DATASET_PATH\"]}', \"\").strip(os.path.sep)\n",
    "        result[\"accent\"] = path.split(os.path.sep)[0]\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        assert path.split(os.path.sep[0])[0] == \"results\"\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        budget = path.split(os.path.sep)[0].replace(\"budget_\", \"\")\n",
    "        result[\"budget\"] = budget\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        assert path.split(os.path.sep[0])[0] == \"global_entropy\"\n",
    "        result[\"method\"] = path.split(os.path.sep[0])[0]\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "\n",
    "        while path:\n",
    "                s = path.split(os.path.sep)[0]\n",
    "                result[s.split('_')[0]] = s.split('_')[1]\n",
    "                path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "\n",
    "        for run in range(1, 4):\n",
    "            try:\n",
    "                test_path = os.path.join(setting, f\"run_{run}\", \"test_infer_log.txt\")\n",
    "                result[f\"WER-{run}\"] = WER_test_file(test_path)\n",
    "                result[f\"CER-{run}\"] = CER_test_file(test_path)\n",
    "                json_path = os.path.join(setting, f\"run_{run}\", \"train.json\")\n",
    "                result[f\"duration-{run}\"], result[f\"percent-{run}\"] = get_accent_speech(json_path, result[\"accent\"], dataset_name=config[\"dataset\"])\n",
    "                result[f\"counter-{run}\"] = get_counts(json_path, dataset_name=config[\"dataset\"])\n",
    "            except:\n",
    "                continue\n",
    "        # print(result)\n",
    "        \n",
    "        expt_results.append(result)\n",
    "    return expt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_global_SM(config):\n",
    "    expt_results = []\n",
    "    glob_str = f'{os.path.join(config[\"FULL_DATASET_PATH\"], \"*\", \"results\", \"budget_*\", \"global-SM\", \"fxn_*\", \"feature_*\", \"sim_*\", \"lambdaVal_*\")}'\n",
    "    # print(glob_str)\n",
    "    lst = glob(glob_str) \n",
    "\n",
    "    for setting in lst:\n",
    "        result = {}\n",
    "        path = setting\n",
    "        path = path.replace(f'{config[\"FULL_DATASET_PATH\"]}', \"\").strip(os.path.sep)\n",
    "        result[\"accent\"] = path.split(os.path.sep)[0]\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        assert path.split(os.path.sep[0])[0] == \"results\"\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        budget = path.split(os.path.sep)[0].replace(\"budget_\", \"\")\n",
    "        result[\"budget\"] = budget\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        assert path.split(os.path.sep[0])[0] == \"global-SM\"\n",
    "        result[\"method\"] = path.split(os.path.sep[0])[0]\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "\n",
    "        while path:\n",
    "            s = path.split(os.path.sep)[0]\n",
    "            result[s.split('_')[0]] = s.split('_')[1]\n",
    "            path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "\n",
    "        for run in range(1, 4):\n",
    "            test_path = os.path.join(setting, f\"run_{run}\", \"test_infer_log.txt\")\n",
    "            result[f\"WER-{run}\"] = WER_test_file(test_path)\n",
    "            result[f\"CER-{run}\"] = CER_test_file(test_path)\n",
    "            json_path = os.path.join(setting, f\"run_{run}\", \"train.json\")\n",
    "            result[f\"duration-{run}\"], result[f\"percent-{run}\"] = get_accent_speech(json_path, result[\"accent\"], dataset_name=config[\"dataset\"])\n",
    "            result[f\"counter-{run}\"] = get_counts(json_path, dataset_name=config[\"dataset\"])\n",
    "\n",
    "        # print(result)\n",
    "        expt_results.append(result)\n",
    "    return expt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_TSS_mixed_results(config):\n",
    "    expt_results = []\n",
    "    glob_str = f'{os.path.join(config[\"FULL_DATASET_PATH\"], \"*\", \"results\", \"budget_*\", \"mixed\", \"*\", \"global-TSS\", \"target_*\", \"fxn_*\", \"feature_*\", \"sim_*\", \"eta_*\")}'\n",
    "    # print(glob_str)\n",
    "    lst = glob(glob_str) \n",
    "\n",
    "    for setting in lst:\n",
    "        result = {}\n",
    "        path = setting\n",
    "        # print(path)\n",
    "        path = path.replace(f'{config[\"FULL_DATASET_PATH\"]}', \"\").strip(os.path.sep)\n",
    "        result[\"accent\"] = path.split(os.path.sep)[0]\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}/', \"\").strip(os.path.sep)\n",
    "        assert path.split(os.path.sep[0])[0] == \"results\"\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        budget = path.split(os.path.sep)[0].replace(\"budget_\", \"\")\n",
    "        result[\"budget\"] = budget\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        assert path.split(os.path.sep[0])[0] == \"mixed\"\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        result[\"query_accent\"] = path.split(os.path.sep[0])[0]\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        assert path.split(os.path.sep[0])[0] == \"global-TSS\"\n",
    "        result[\"method\"] = path.split(os.path.sep[0])[0]\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "\n",
    "        while path:\n",
    "            s = path.split(os.path.sep)[0]\n",
    "            result[s.split('_')[0]] = s.split('_')[1]\n",
    "            path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "\n",
    "        for run in range(1, 4):\n",
    "            test_path = os.path.join(setting, f\"run_{run}\", \"test_infer_log.txt\")\n",
    "            result[f\"WER-{run}\"] = WER_test_file(test_path)\n",
    "            result[f\"CER-{run}\"] = CER_test_file(test_path)\n",
    "            json_path = os.path.join(setting, f\"run_{run}\", \"train.json\")\n",
    "            result[f\"duration-{run}\"], result[f\"percent-{run}\"] = get_accent_speech(json_path, result[\"accent\"], dataset_name=config[\"dataset\"])\n",
    "            result[f\"counter-{run}\"] = get_counts(json_path, dataset_name=config[\"dataset\"])\n",
    "\n",
    "        # print(result)\n",
    "        expt_results.append(result)\n",
    "    return expt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_two_stage_TSS_error_results(config):\n",
    "    expt_results = []\n",
    "    glob_str = f'{os.path.join(config[\"FULL_DATASET_PATH\"], \"*\", \"results\", \"budget_*\", \"mixed\", \"*\", \"budget_*\", \"global-TSS\", \"target_*\", \"fxn_*\", \"feature_*\", \"sim_*\", \"eta_*\", \"budget_*\", \"error_model\", \"trainBudget_*\", \"mode_*\", \"pseudoTrans_*\")}'\n",
    "    # print(glob_str)\n",
    "    lst = glob(glob_str) \n",
    "    # print(lst)\n",
    "\n",
    "    for setting in lst:\n",
    "        result = {}\n",
    "        path = setting\n",
    "        # print(path)\n",
    "        path = path.replace(f'{config[\"FULL_DATASET_PATH\"]}', \"\").strip(os.path.sep)\n",
    "        result[\"accent\"] = path.split(os.path.sep)[0]\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}/', \"\").strip(os.path.sep)\n",
    "        assert path.split(os.path.sep[0])[0] == \"results\"\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        budget = path.split(os.path.sep)[0].replace(\"budget_\", \"\")\n",
    "        result[\"budget(Stage2)\"] = budget\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        assert path.split(os.path.sep[0])[0] == \"mixed\"\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        result[\"query_accent\"] = path.split(os.path.sep[0])[0]\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "\n",
    "        result[\"budget(Stage1)\"] = path.split(os.path.sep[0])[0].split('_')[1]\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "\n",
    "        assert path.split(os.path.sep[0])[0] == \"global-TSS\"\n",
    "        result[\"method\"] = path.split(os.path.sep[0])[0]\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "\n",
    "\n",
    "\n",
    "        while path and path.split(os.path.sep)[0]!=\"error_model\":\n",
    "            s = path.split(os.path.sep)[0]\n",
    "            result[s.split('_')[0]] = s.split('_')[1]\n",
    "            path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "\n",
    "        result[\"method(Stage2)\"] = path.split(os.path.sep[0])[0]\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        while path and path.split(os.path.sep)[0]!=\"error_model\":\n",
    "            s = path.split(os.path.sep)[0]\n",
    "            result[s.split('_')[0]+\"(Stage2)\"] = s.split('_')[1]\n",
    "            path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "\n",
    "\n",
    "        for run in range(1, 4):\n",
    "            try:\n",
    "                test_path = os.path.join(setting, f\"run_{run}\", \"test_infer_log.txt\")\n",
    "                result[f\"WER-{run}\"] = WER_test_file(test_path)\n",
    "                result[f\"CER-{run}\"] = CER_test_file(test_path)\n",
    "                json_path = os.path.join(setting, f\"run_{run}\", \"train.json\")\n",
    "                result[f\"duration-{run}\"], result[f\"percent-{run}\"] = get_accent_speech(json_path, result[\"accent\"], dataset_name=config[\"dataset\"])\n",
    "                result[f\"counter-{run}\"] = get_counts(json_path, dataset_name=config[\"dataset\"])\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # print(result)\n",
    "        expt_results.append(result)\n",
    "    return expt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_pretrain_results(config):\n",
    "    expt_results = []\n",
    "    glob_str = f'{os.path.join(config[\"FULL_DATASET_PATH\"], \"*\", \"quartznet_outputs\")}'\n",
    "    # print(glob_str)\n",
    "    lst = glob(glob_str) \n",
    "    # print(lst)\n",
    "\n",
    "    for setting in lst:\n",
    "        result = {}\n",
    "        path = setting\n",
    "        # print(path)\n",
    "        path = path.replace(f'{config[\"FULL_DATASET_PATH\"]}', \"\").strip(os.path.sep)\n",
    "        result[\"accent\"] = path.split(os.path.sep)[0]\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}/', \"\").strip(os.path.sep)\n",
    "        assert path.split(os.path.sep[0])[0] == \"quartznet_outputs\"\n",
    "        path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "        result[\"method\"] = \"pretrain\"\n",
    "        try:\n",
    "            test_path = os.path.join(setting, \"test_infer_log.txt\")\n",
    "            result[f\"WER\"] = WER_test_file(test_path)\n",
    "            result[f\"CER\"] = CER_test_file(test_path)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # print(result)\n",
    "        expt_results.append(result)\n",
    "    # print(expt_results)\n",
    "    return expt_results\n",
    "\n",
    "# config = {}\n",
    "\n",
    "# config[\"dataset\"] = \"L2\"\n",
    "# config[\"server\"] = \"SWARA\"\n",
    "# config = update_config(config)\n",
    "# collect_pretrain_results(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_mixed_selections(config, query_accent, query_set):\n",
    "    expt_results = []\n",
    "    glob_str = f'{os.path.join(config[\"FULL_DATASET_PATH\"], \"mixed\", f\"{query_accent}\", \"results\", \"budget_*\", \"global-TSS\", \"target_*\", \"fxn_*\", \"feature_*\", \"sim_*\", \"eta_*\")}'\n",
    "    # print(glob_str)\n",
    "    lst = glob(glob_str) \n",
    "    # print(lst)\n",
    "\n",
    "    for setting in lst:\n",
    "        for accent in query_set:\n",
    "            result = {}\n",
    "            result[\"accent\"] = accent\n",
    "            path = setting\n",
    "            # print(path)\n",
    "            path = path.replace(f'{config[\"FULL_DATASET_PATH\"]}', \"\").strip(os.path.sep)\n",
    "            path = path.replace(f'mixed', \"\").strip(os.path.sep)\n",
    "\n",
    "            result[\"query_accent\"] = path.split(os.path.sep[0])[0]\n",
    "            path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "\n",
    "            assert path.split(os.path.sep[0])[0] == \"results\"\n",
    "            path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "\n",
    "            budget = path.split(os.path.sep)[0].replace(\"budget_\", \"\")\n",
    "            result[\"budget\"] = budget\n",
    "            path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "\n",
    "            assert path.split(os.path.sep[0])[0] == \"global-TSS\"\n",
    "            result[\"method\"] = path.split(os.path.sep[0])[0]\n",
    "            path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "\n",
    "            while path:\n",
    "                s = path.split(os.path.sep)[0]\n",
    "                result[s.split('_')[0]] = s.split('_')[1]\n",
    "                path = path.replace(f'{path.split(os.path.sep[0])[0]}', \"\").strip(os.path.sep)\n",
    "\n",
    "            for run in range(1, 4):\n",
    "                try:\n",
    "                    json_path = os.path.join(setting, f\"run_{run}\", \"train.json\")\n",
    "                    result[f\"duration-{run}\"], result[f\"percent-{run}\"] = get_accent_speech(json_path, result[\"accent\"], dataset_name=config[\"dataset\"])\n",
    "                    result[f\"counter-{run}\"] = get_counts(json_path, dataset_name=config[\"dataset\"])\n",
    "                    test_path = os.path.join(setting, f\"run_{run}\", \"test_infer_log.txt\")\n",
    "                    result[f\"WER-{run}\"] = WER_test_file(test_path)\n",
    "                    result[f\"CER-{run}\"] = CER_test_file(test_path)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            # print(result)\n",
    "            expt_results.append(result)\n",
    "    return expt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_selection_results(config):\n",
    "    selection_results = []\n",
    "    selection_results.extend(collect_mixed_selections(config, \"arabic-spanish::1-1\", [\"arabic\", \"spanish\"]))\n",
    "    selection_results.extend(collect_mixed_selections(config, \"chinese-vietnamese::1-1\", [\"chinese\", \"vietnamese\"]))\n",
    "\n",
    "    for result in selection_results:\n",
    "        try:\n",
    "            if(\"sim\" in result): result[\"sim\"] = result[\"sim\"][:3]\n",
    "            if(\"method(Stage2)\" in result): result[\"method\"] = result[\"method\"] + (\"-\" + result[\"method(Stage2)\"] if result[\"method(Stage2)\"] else \"\")\n",
    "            result[\"method\"] = result[\"method\"].replace(\"global\", \"\")\n",
    "            result[\"method\"] = result[\"method\"].strip(\"-_ \")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    temp_df = pd.DataFrame(selection_results, columns=[\"budget\", \"query_accent\", \"method\", \"fxn\", \"feature\", \"sim\", \"counter-1\", \"duration-1\", \"percent-1\", \"accent\"])\n",
    "    temp_df = temp_df.sort_values([\"query_accent\", \"sim\", \"fxn\", \"accent\"], ignore_index=True)\n",
    "    def format_results(query_accent, data):\n",
    "        mask = (data[\"query_accent\"] == query_accent)\n",
    "        masked_data = data.loc[mask]\n",
    "        cols = list(masked_data.columns)\n",
    "        specific_columns = [_ for _ in cols if _.startswith(\"WER\") or _.startswith(\"CER\") or _.startswith(\"duration\") or _.startswith(\"percent\") or _ == \"accent\"]\n",
    "        common_columns = list(set(cols) - set(specific_columns))\n",
    "        # print(common_columns)\n",
    "        masked_data = masked_data.pivot(index=common_columns, columns='accent', values=specific_columns).reset_index()\n",
    "        return masked_data\n",
    "\n",
    "    format_results(\"arabic-spanish::1-1\", temp_df).to_csv(\"../../Results/TSS/L2/arabic-spanish-1-1-selections.csv\", index=False)\n",
    "    format_results(\"chinese-vietnamese::1-1\", temp_df).to_csv(\"../../Results/TSS/L2/chinese-vietnamese-1-1-selections.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def format_selection_results(df):\n",
    "\n",
    "#     def collect_formatted_results(query_set, query_composn, data):\n",
    "#         query_composn = [str(_) for _ in query_composn]\n",
    "#         query_accent = \"-\".join(query_set) + \"::\" + \"-\".join(query_composn)\n",
    "#         mask = ((data[\"query_accent\"] == query_accent) | ((data[\"query_accent\"].isnull()) & (data[\"accent\"].isin(query_set))))\n",
    "#         masked_data = data.loc[mask]\n",
    "#         cols = list(masked_data.columns)\n",
    "#         specific_columns = [_ for _ in cols if _.startswith(\"WER\") or _.startswith(\"CER\") or _.startswith(\"duration\") or _.startswith(\"percent\") or _ == \"accent\"]\n",
    "#         common_columns = list(set(cols) - set(specific_columns))\n",
    "#         # print(common_columns)\n",
    "#         masked_data = masked_data.pivot(index=common_columns, columns='accent', values=specific_columns).reset_index()\n",
    "#         return masked_data\n",
    "    \n",
    "#     temp_df = df[[\"accent\", \"budget\", \"query_accent\", \"fxn\", \"sim\",\"counter-1\", \"duration-1\", \"percent-1\"]]\n",
    "#     temp_df = temp_df.sort_values([\"query_accent\", \"sim\", \"fxn\", \"accent\"], ignore_index=True)\n",
    "#     collect_formatted_results([\"arabic\", \"spanish\"], [1, 1], temp_df).to_csv(\"../../Results/TSS/L2/arabic-spanish-1-1-selection.csv\", index=False)\n",
    "#     collect_formatted_results([\"chinese\", \"vietnamese\"], [1, 1], temp_df).to_csv(\"../../Results/TSS/L2/chinese-vietnamese-1-1-selection.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_finetune_results(config):\n",
    "    L2_results = []\n",
    "    L2_results.extend(collect_global_random(config))\n",
    "    L2_results.extend(collect_global_SM(config))\n",
    "    L2_results.extend(collect_TSS_mixed_results(config))\n",
    "    L2_results.extend(collect_two_stage_TSS_error_results(config))\n",
    "    L2_results.extend(collect_global_entropy(config))\n",
    "\n",
    "\n",
    "    for result in L2_results:\n",
    "        try:\n",
    "            result[\"WER-mean\"] = round(np.nanmean([result[\"WER-1\"], result[\"WER-2\"], result[\"WER-3\"]]), 3)\n",
    "            result[\"WER-std\"] = round(np.nanstd([result[\"WER-1\"], result[\"WER-2\"], result[\"WER-3\"]]), 3)\n",
    "            result[\"CER-mean\"] = round(np.nanmean([result[\"CER-1\"], result[\"CER-2\"], result[\"CER-3\"]]), 3)\n",
    "            result[\"CER-std\"] = round(np.nanstd([result[\"CER-1\"], result[\"CER-2\"], result[\"CER-3\"]]), 3)\n",
    "            if(\"sim\" in result): result[\"sim\"] = result[\"sim\"][:3]\n",
    "            if(\"method(Stage2)\" in result): result[\"method\"] = result[\"method\"] + (\"-\" + result[\"method(Stage2)\"] if result[\"method(Stage2)\"] else \"\")\n",
    "            result[\"method\"] = result[\"method\"].replace(\"global\", \"\")\n",
    "            result[\"method\"] = result[\"method\"].strip(\"-_ \")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(L2_results)\n",
    "    df = df.sort_values([\"accent\", \"method\"], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_finetune_results(df):\n",
    "    temp_df = df[[\"accent\", \"budget\", \"query_accent\", \"fxn\", \"sim\",\"counter-1\", \"duration-1\", \"percent-1\"]]\n",
    "    temp_df = temp_df.sort_values([\"query_accent\", \"sim\", \"fxn\", \"accent\"], ignore_index=True)\n",
    "\n",
    "    def collect_formatted_results(query_set, query_composn, data):\n",
    "        query_composn = [str(_) for _ in query_composn]\n",
    "        query_accent = \"-\".join(query_set) + \"::\" + \"-\".join(query_composn)\n",
    "        mask = ((data[\"query_accent\"] == query_accent) | ((data[\"query_accent\"].isnull()) & (data[\"accent\"].isin(query_set))))\n",
    "        masked_data = data.loc[mask]\n",
    "        cols = list(masked_data.columns)\n",
    "        specific_columns = [_ for _ in cols if _.startswith(\"WER\") or _.startswith(\"CER\") or _.startswith(\"duration\") or _.startswith(\"percent\") or _ == \"accent\"]\n",
    "        common_columns = list(set(cols) - set(specific_columns))\n",
    "        # print(common_columns)\n",
    "        masked_data = masked_data.pivot(index=common_columns, columns='accent', values=specific_columns).reset_index()\n",
    "        return masked_data\n",
    "    \n",
    "    collect_formatted_results([\"arabic\", \"spanish\"], [1, 1], df).to_csv(\"../../Results/TSS/L2/arabic-spanish-1-1.csv\", index=False)\n",
    "    collect_formatted_results([\"chinese\", \"vietnamese\"], [1, 1], df).to_csv(\"../../Results/TSS/L2/chinese-vietnamese-1-1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "config[\"dataset\"] = \"L2\"\n",
    "config[\"server\"] = \"SWARA\"\n",
    "config = update_config(config)\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main_finetune_results(config)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_finetune_results(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_selection_results(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "error",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, May 19 2021, 18:05:58) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc33b118a8b882057d92ab3e840283c71bfc0408e638fa49ffb4a6668b810896"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
