{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accent_list = [\n",
    "    \"african\",  \"australia\", \"bermuda\",\n",
    "    \"canada\", \"england\", \"hongkong\",\n",
    "    \"indian\", \"ireland\", \"malaysia\", \n",
    "    \"newzealand\", \"philippines\", \"scotland\",\n",
    "    \"singapore\", \"southatlandtic\", \"us\", \n",
    "    \"wales\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment this cell only when you explicitly require it.\n",
    "## This creates files/dirs so be careful\n",
    "## Chandra\n",
    "# for accent in accent_list:\n",
    "#    os.system(f\"mkdir -p ../data/{accent}/\")\n",
    "#    os.system(f\"cp ../../../mz-isca/validated/accent-trans/{accent}.json ../data/{accent}/all_validated.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write(path, json_list):\n",
    "    with open(path, 'w') as file:\n",
    "        for json_entry in json_list:\n",
    "            json.dump(json_entry, file)\n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exec this cell with care\n",
    "## As this creates/modifies some files\n",
    "## Chandra\n",
    "\n",
    "\n",
    "for accent in accent_list:\n",
    "    all_validated_json_path = f\"../data/{accent}/all_validated.json\"\n",
    "\n",
    "    with open(all_validated_json_path, 'r') as all_validated_json_file:\n",
    "        json_lst = [json.loads(line.strip()) for line in all_validated_json_file.readlines()]\n",
    "\n",
    "        rng.shuffle(json_lst)\n",
    "\n",
    "        all_json_sz = min(8000, len(json_lst))\n",
    "        all_json_inds = rng.choice(len(json_lst), all_json_sz, replace=False)\n",
    "        all_json_lst = [json_lst[ind] for ind in all_json_inds]\n",
    "\n",
    "        all_json_path = f\"../data/{accent}/all.json\"\n",
    "        _write(all_json_path, all_json_lst)\n",
    "    #     json_lst = [json.loads(line.strip()) for line in all_json_file.readlines()]\n",
    "\n",
    "    #     # print(\"Old json lst size\", len(json_lst))\n",
    "\n",
    "    #     rng.shuffle(json_lst)\n",
    "\n",
    "\n",
    "    #     dev_path = f\"../data/{accent}/dev.json\"\n",
    "    #     dev_sz = 50\n",
    "\n",
    "    #     dev_lst = rng.choice(len(json_lst), dev_sz, replace=False)\n",
    "\n",
    "    #     # print(\"dev _lst\", len(dev_lst))\n",
    "    #     dev_json_items = [json_lst[_] for _ in dev_lst]\n",
    "\n",
    "    #     _write(dev_path, dev_json_items)\n",
    "\n",
    "    #     json_lst = [json_lst[ind] for ind in range(len(json_lst)) if ind not in dev_lst]\n",
    "\n",
    "    #     # print(\"new json lst size\", len(json_lst))\n",
    "\n",
    "\n",
    "\n",
    "    #     for json_entry in json_lst:\n",
    "    #         speaker_id = json_entry[\"client_id\"]\n",
    "    #         if speaker_id in speaker_dict.keys():\n",
    "    #             speaker_dict[speaker_id].append(json_entry)\n",
    "    #         else:\n",
    "    #             speaker_dict[speaker_id] = [json_entry]\n",
    "    \n",
    "    # print(accent, len(speaker_dict.keys()))\n",
    "\n",
    "\n",
    "    # sorted_speakers = list(speaker_dict.keys())\n",
    "\n",
    "    # sorted_speakers.sort(key=lambda user_id: len(speaker_dict[user_id]), reverse = True)\n",
    "\n",
    "    # total_speakers = len(sorted_speakers)\n",
    "    # lower = total_speakers//4\n",
    "    # upper = total_speakers * 3//4\n",
    "\n",
    "    # reqd_user_cnt = max(2, (upper - lower + 1)*2//10) # 0.1% of users are selected\n",
    "\n",
    "    # assert reqd_user_cnt <= upper-lower + 1\n",
    "\n",
    "    # test_user_ids = rng.choice(sorted_speakers[lower: upper + 1], size=reqd_user_cnt, replace=False)\n",
    "\n",
    "\n",
    "    # test_path = f\"../data/{accent}/test.json\"\n",
    "    # selection_path = f\"../data/{accent}/selection.json\"\n",
    "\n",
    "    # test_json_list = []\n",
    "    # selection_json_list = []\n",
    "\n",
    "    # for user_id in sorted_speakers:\n",
    "        \n",
    "    #     if user_id in test_user_ids:\n",
    "    #         test_json_list.extend(speaker_dict[user_id])            \n",
    "    #     else:\n",
    "    #         selection_json_list.extend(speaker_dict[user_id])\n",
    "\n",
    "    # rng.shuffle(test_json_list)\n",
    "    # rng.shuffle(selection_json_list)\n",
    "\n",
    "    # _write(test_path, test_json_list)\n",
    "\n",
    "    # _write(selection_path, selection_json_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: need to run the mp3wav.py\n",
    "# Run the below command in a seperate bash shell instead of here\n",
    "# !pwd; cd ../; pwd; which python; python scripts/mp3wav.py;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "african num_speakers = 229 all_json_count: 8000\n",
      "african test_speakers = 68 test_json_count: 1037\n",
      "african remaining speakers after removing test_entries = 161\n",
      "african seed_json_count: 50\n",
      "african remaining speakers after removing seed_entries = 159\n",
      "african remaining samples after removing seed_entries = 6913\n",
      "african dev_json_count: 691\n",
      "african remaining speakers after removing dev_entries = 105\n",
      "african selection_json_count: 6222\n",
      "australia num_speakers = 498 all_json_count: 8000\n",
      "australia test_speakers = 149 test_json_count: 713\n",
      "australia remaining speakers after removing test_entries = 349\n",
      "australia seed_json_count: 50\n",
      "australia remaining speakers after removing seed_entries = 339\n",
      "australia remaining samples after removing seed_entries = 7237\n",
      "australia dev_json_count: 723\n",
      "australia remaining speakers after removing dev_entries = 189\n",
      "australia selection_json_count: 6514\n",
      "bermuda num_speakers = 41 all_json_count: 643\n",
      "bermuda test_speakers = 12 test_json_count: 100\n",
      "bermuda remaining speakers after removing test_entries = 29\n",
      "bermuda seed_json_count: 50\n",
      "bermuda remaining speakers after removing seed_entries = 23\n",
      "bermuda remaining samples after removing seed_entries = 493\n",
      "bermuda dev_json_count: 49\n",
      "bermuda remaining speakers after removing dev_entries = 19\n",
      "bermuda selection_json_count: 444\n",
      "canada num_speakers = 636 all_json_count: 7999\n",
      "canada test_speakers = 190 test_json_count: 883\n",
      "canada remaining speakers after removing test_entries = 446\n",
      "canada seed_json_count: 50\n",
      "canada remaining speakers after removing seed_entries = 432\n",
      "canada remaining samples after removing seed_entries = 7066\n",
      "canada dev_json_count: 706\n",
      "canada remaining speakers after removing dev_entries = 285\n",
      "canada selection_json_count: 6360\n",
      "england num_speakers = 1262 all_json_count: 8000\n",
      "england test_speakers = 378 test_json_count: 892\n",
      "england remaining speakers after removing test_entries = 884\n",
      "england seed_json_count: 50\n",
      "england remaining speakers after removing seed_entries = 861\n",
      "england remaining samples after removing seed_entries = 7058\n",
      "england dev_json_count: 705\n",
      "england remaining speakers after removing dev_entries = 578\n",
      "england selection_json_count: 6353\n",
      "hongkong num_speakers = 111 all_json_count: 2750\n",
      "hongkong test_speakers = 33 test_json_count: 301\n",
      "hongkong remaining speakers after removing test_entries = 78\n",
      "hongkong seed_json_count: 50\n",
      "hongkong remaining speakers after removing seed_entries = 73\n",
      "hongkong remaining samples after removing seed_entries = 2399\n",
      "hongkong dev_json_count: 239\n",
      "hongkong remaining speakers after removing dev_entries = 46\n",
      "hongkong selection_json_count: 2160\n",
      "indian num_speakers = 1116 all_json_count: 7999\n",
      "indian test_speakers = 334 test_json_count: 733\n",
      "indian remaining speakers after removing test_entries = 782\n",
      "indian seed_json_count: 50\n",
      "indian remaining speakers after removing seed_entries = 763\n",
      "indian remaining samples after removing seed_entries = 7216\n",
      "indian dev_json_count: 721\n",
      "indian remaining speakers after removing dev_entries = 478\n",
      "indian selection_json_count: 6495\n",
      "ireland num_speakers = 173 all_json_count: 7999\n",
      "ireland test_speakers = 51 test_json_count: 708\n",
      "ireland remaining speakers after removing test_entries = 122\n",
      "ireland seed_json_count: 50\n",
      "ireland remaining speakers after removing seed_entries = 121\n",
      "ireland remaining samples after removing seed_entries = 7241\n",
      "ireland dev_json_count: 724\n",
      "ireland remaining speakers after removing dev_entries = 66\n",
      "ireland selection_json_count: 6517\n",
      "malaysia num_speakers = 81 all_json_count: 1685\n",
      "malaysia test_speakers = 24 test_json_count: 271\n",
      "malaysia remaining speakers after removing test_entries = 57\n",
      "malaysia seed_json_count: 50\n",
      "malaysia remaining speakers after removing seed_entries = 53\n",
      "malaysia remaining samples after removing seed_entries = 1364\n",
      "malaysia dev_json_count: 136\n",
      "malaysia remaining speakers after removing dev_entries = 42\n",
      "malaysia selection_json_count: 1228\n",
      "newzealand num_speakers = 136 all_json_count: 8000\n",
      "newzealand test_speakers = 40 test_json_count: 605\n",
      "newzealand remaining speakers after removing test_entries = 96\n",
      "newzealand seed_json_count: 50\n",
      "newzealand remaining speakers after removing seed_entries = 94\n",
      "newzealand remaining samples after removing seed_entries = 7345\n",
      "newzealand dev_json_count: 734\n",
      "newzealand remaining speakers after removing dev_entries = 46\n",
      "newzealand selection_json_count: 6611\n",
      "philippines num_speakers = 108 all_json_count: 4158\n",
      "philippines test_speakers = 32 test_json_count: 438\n",
      "philippines remaining speakers after removing test_entries = 76\n",
      "philippines seed_json_count: 50\n",
      "philippines remaining speakers after removing seed_entries = 76\n",
      "philippines remaining samples after removing seed_entries = 3670\n",
      "philippines dev_json_count: 367\n",
      "philippines remaining speakers after removing dev_entries = 47\n",
      "philippines selection_json_count: 3303\n",
      "scotland num_speakers = 152 all_json_count: 8000\n",
      "scotland test_speakers = 45 test_json_count: 619\n",
      "scotland remaining speakers after removing test_entries = 107\n",
      "scotland seed_json_count: 50\n",
      "scotland remaining speakers after removing seed_entries = 105\n",
      "scotland remaining samples after removing seed_entries = 7331\n",
      "scotland dev_json_count: 733\n",
      "scotland remaining speakers after removing dev_entries = 57\n",
      "scotland selection_json_count: 6598\n",
      "singapore num_speakers = 61 all_json_count: 2967\n",
      "singapore test_speakers = 18 test_json_count: 262\n",
      "singapore remaining speakers after removing test_entries = 43\n",
      "singapore seed_json_count: 50\n",
      "singapore remaining speakers after removing seed_entries = 39\n",
      "singapore remaining samples after removing seed_entries = 2655\n",
      "singapore dev_json_count: 265\n",
      "singapore remaining speakers after removing dev_entries = 22\n",
      "singapore selection_json_count: 2390\n",
      "southatlandtic num_speakers = 5 all_json_count: 203\n",
      "southatlandtic test_speakers = 2 test_json_count: 45\n",
      "southatlandtic remaining speakers after removing test_entries = 3\n",
      "southatlandtic seed_json_count: 50\n",
      "southatlandtic remaining speakers after removing seed_entries = 1\n",
      "southatlandtic remaining samples after removing seed_entries = 108\n",
      "southatlandtic dev_json_count: 10\n",
      "southatlandtic remaining speakers after removing dev_entries = 1\n",
      "southatlandtic selection_json_count: 98\n",
      "us num_speakers = 2443 all_json_count: 7999\n",
      "us test_speakers = 732 test_json_count: 1098\n",
      "us remaining speakers after removing test_entries = 1711\n",
      "us seed_json_count: 50\n",
      "us remaining speakers after removing seed_entries = 1685\n",
      "us remaining samples after removing seed_entries = 6851\n",
      "us dev_json_count: 685\n",
      "us remaining speakers after removing dev_entries = 1349\n",
      "us selection_json_count: 6166\n",
      "wales num_speakers = 61 all_json_count: 1550\n",
      "wales test_speakers = 18 test_json_count: 202\n",
      "wales remaining speakers after removing test_entries = 43\n",
      "wales seed_json_count: 50\n",
      "wales remaining speakers after removing seed_entries = 43\n",
      "wales remaining samples after removing seed_entries = 1298\n",
      "wales dev_json_count: 129\n",
      "wales remaining speakers after removing dev_entries = 24\n",
      "wales selection_json_count: 1169\n"
     ]
    }
   ],
   "source": [
    "for accent in accent_list:\n",
    "    all_json_path = f\"../data/{accent}/all.json\"\n",
    "    \n",
    "    with open(all_json_path, 'r') as all_json_file:\n",
    "        json_lst = [json.loads(line.strip()) for line in all_json_file.readlines()]\n",
    "        rng.shuffle(json_lst)\n",
    "        speaker_dict = dict()\n",
    "        for item in json_lst:\n",
    "            speaker_id = item[\"client_id\"]\n",
    "            if speaker_id not in speaker_dict.keys():\n",
    "                speaker_dict[speaker_id] = [item]\n",
    "            else:\n",
    "                speaker_dict[speaker_id].append(item)\n",
    "\n",
    "        print(accent, f\"num_speakers = {len(speaker_dict.keys())}\", f\"all_json_count: {len(json_lst)}\")\n",
    "\n",
    "        sorted_speakers = list(speaker_dict.keys())\n",
    "\n",
    "        sorted_speakers.sort(key = lambda speaker_id: len(speaker_dict[speaker_id]), reverse = True)\n",
    "\n",
    "        total_speakers = len(sorted_speakers)\n",
    "        lower = total_speakers//4\n",
    "        upper = total_speakers * 3//4\n",
    "\n",
    "        test_speaker_count = max(2, int(0.3 * total_speakers))\n",
    "        \n",
    "        test_speakers = rng.choice(sorted_speakers[lower: upper + 1], test_speaker_count, replace = False)\n",
    "\n",
    "        test_json_lst = []\n",
    "        for test_user in test_speakers:\n",
    "            test_json_lst.extend(speaker_dict[test_user])\n",
    "        \n",
    "        rng.shuffle(test_json_lst)\n",
    "\n",
    "        test_json_path = f\"../data/{accent}/test.json\"\n",
    "        print(accent, f\"test_speakers = {test_speaker_count}\", f\"test_json_count: {len(test_json_lst)}\")\n",
    "\n",
    "        _write(test_json_path, test_json_lst)\n",
    "\n",
    "\n",
    "        rem_speakers = [speaker for speaker in sorted_speakers if speaker not in test_speakers]\n",
    "\n",
    "        rng.shuffle(rem_speakers)\n",
    "        print(accent, f\"remaining speakers after removing test_entries = {len(rem_speakers)}\")\n",
    "\n",
    "        for speaker in rem_speakers:\n",
    "            rng.shuffle(speaker_dict[speaker])\n",
    "        \n",
    "        seed_cnt = 50\n",
    "        seed_lst = []\n",
    "\n",
    "        for curr_ind in range(seed_cnt):\n",
    "            speaker_id = rem_speakers[(curr_ind)%len(rem_speakers)]\n",
    "\n",
    "            seed_lst.append(speaker_dict[speaker_id][-1])\n",
    "\n",
    "            speaker_dict[speaker_id].pop()\n",
    "\n",
    "            if len(speaker_dict[speaker_id]) == 0:\n",
    "                assert speaker_id in rem_speakers\n",
    "                rem_speakers.remove(speaker_id)\n",
    "\n",
    "        print(accent, f\"seed_json_count: {len(seed_lst)}\")\n",
    "        print(accent, f\"remaining speakers after removing seed_entries = {len(rem_speakers)}\")\n",
    "\n",
    "        seed_path = f\"../data/{accent}/seed.json\"\n",
    "        _write(seed_path, seed_lst)\n",
    "\n",
    "        rng.shuffle(rem_speakers)\n",
    "        left_samples = 0\n",
    "\n",
    "        for speaker in rem_speakers:\n",
    "            rng.shuffle(speaker_dict[speaker])\n",
    "            left_samples += len(speaker_dict[speaker])\n",
    "            assert len(speaker_dict[speaker]) != 0\n",
    "\n",
    "        print(accent, f\"remaining samples after removing seed_entries = {left_samples}\")\n",
    "\n",
    "        dev_cnt = int(0.1 * left_samples)\n",
    "\n",
    "        dev_lst = []\n",
    "\n",
    "        for curr_ind in range(dev_cnt):\n",
    "            speaker_id = rem_speakers[(curr_ind)%len(rem_speakers)]\n",
    "\n",
    "            dev_lst.append(speaker_dict[speaker_id][-1])\n",
    "\n",
    "            speaker_dict[speaker_id].pop()\n",
    "\n",
    "            if len(speaker_dict[speaker_id]) == 0:\n",
    "                assert speaker_id in rem_speakers\n",
    "                rem_speakers.remove(speaker_id)\n",
    "\n",
    "\n",
    "        print(accent, f\"dev_json_count: {len(dev_lst)}\")\n",
    "        print(accent, f\"remaining speakers after removing dev_entries = {len(rem_speakers)}\")\n",
    "\n",
    "        dev_path = f\"../data/{accent}/dev.json\"\n",
    "        _write(dev_path, dev_lst)\n",
    "\n",
    "        selection_path = f\"../data/{accent}/selection.json\"\n",
    "        selection_lst = []\n",
    "\n",
    "        for speaker in rem_speakers:\n",
    "            selection_lst.extend(speaker_dict[speaker])\n",
    "\n",
    "        print(accent, f\"selection_json_count: {len(selection_lst)}\")\n",
    "\n",
    "        _write(selection_path, selection_lst)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydub import AudioSegment\n",
    "# for accent in accent_list:\n",
    "#     for file_name in [\"selection\", \"test\", \"dev\", \"all\"]:\n",
    "#         print(accent, file_name, \"Started\")\n",
    "#         file_path = f\"../data/{accent}/{file_name}.json\"\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             json_lst = [json.loads(line.strip()) for line in file.readlines()]\n",
    "\n",
    "#             new_json_lst = []\n",
    "#             for entry in json_lst:\n",
    "#                 new_entry = entry\n",
    "#                 try:\n",
    "#                     audio = AudioSegment.from_file(entry[\"audio_filepath\"])\n",
    "#                     new_entry[\"duration\"] = audio.duration_seconds\n",
    "#                     new_json_lst.append(new_entry)\n",
    "#                 except:\n",
    "#                     print(entry[\"audio_filepath\"])\n",
    "\n",
    "#         _write(file_path, new_json_lst)\n",
    "\n",
    "\n",
    "\n",
    "#         print(accent, file_name, \"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c2a1a7c5adb1740f8fe2dd087b575ca5bab2c91d5b8eac06a896a0517011c673"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
