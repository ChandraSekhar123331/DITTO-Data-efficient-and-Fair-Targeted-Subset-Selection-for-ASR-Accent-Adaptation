{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45f8289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4af3700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import numpy as np, pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers.file_utils import ModelOutput\n",
    "from transformers import AutoConfig, Wav2Vec2Processor\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import (\n",
    "    Wav2Vec2PreTrainedModel,\n",
    "    Wav2Vec2Model\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torchaudio, os, sys, json, pickle, librosa\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb70663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dataclass\n",
    "# class SpeechClassifierOutput(ModelOutput):\n",
    "# #     loss: Optional[torch.FloatTensor] = None\n",
    "# #     logits: torch.FloatTensor = None\n",
    "#     hidden_states: Optional[Tuple[torch.FloatTensor]]\n",
    "# #     attentions: Optional[Tuple[torch.FloatTensor]]\n",
    "# #     h1: Optional[Tuple[torch.FloatTensor]] = None\n",
    "#     h2: Optional[Tuple[torch.FloatTensor]] = None\n",
    "\n",
    "# class Wav2Vec2ClassificationHead(nn.Module):\n",
    "#     \"\"\"Head for wav2vec classification task.\"\"\"\n",
    "\n",
    "#     def __init__(self, config):\n",
    "#         super().__init__()\n",
    "#         self.dense1 = nn.Linear(config.hidden_size, 300)\n",
    "#         self.dense2 = nn.Linear(300, 100)\n",
    "#         self.dropout = nn.Dropout(config.final_dropout)\n",
    "#         self.out_proj = nn.Linear(100, config.num_labels)\n",
    "\n",
    "\n",
    "#     def forward(self, features, **kwargs):\n",
    "#         x = features\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.dense1(x)\n",
    "#         x1 = torch.tanh(x)\n",
    "#         x2 = self.dropout(x1)\n",
    "#         x2 = self.dense2(x2)\n",
    "#         x2 = torch.tanh(x2)\n",
    "#         x3 = self.dropout(x2)        \n",
    "#         x3 = self.out_proj(x3)\n",
    "#         return x1, x2, x3\n",
    "\n",
    "class Wav2Vec2ForSpeechClassification(Wav2Vec2PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        config.pooling_mode = \"mean\"\n",
    "        self.pooling_mode = config.pooling_mode\n",
    "        self.config = config\n",
    "\n",
    "        self.wav2vec2 = Wav2Vec2Model(config)\n",
    "#         self.classifier = Wav2Vec2ClassificationHead(config)\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "    def freeze_feature_extractor(self):\n",
    "        self.wav2vec2.feature_extractor._freeze_parameters()\n",
    "        for module in self.wav2vec2.encoder.layers[:10]:\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def merged_strategy(self, hidden_states, mode=\"mean\"):\n",
    "        if mode == \"mean\":\n",
    "            outputs = torch.mean(hidden_states, dim=1)\n",
    "        elif mode == \"sum\":\n",
    "            outputs = torch.sum(hidden_states, dim=1)\n",
    "        elif mode == \"max\":\n",
    "            outputs = torch.max(hidden_states, dim=1)[0]\n",
    "        else:\n",
    "            raise Exception(\"The pooling method hasn't been defined! Your pooling mode must be one of these ['mean', 'sum', 'max']\")\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_values,\n",
    "            attention_mask=None,\n",
    "            output_attentions=None,\n",
    "            output_hidden_states=None,\n",
    "            return_dict=None,\n",
    "            labels=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        outputs = self.wav2vec2(\n",
    "            input_values,\n",
    "            attention_mask=attention_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        hidden_states = outputs[0]\n",
    "        hidden_states = self.merged_strategy(hidden_states, mode=self.pooling_mode)\n",
    "#         print(\"type of hidden_states is = \", type(hidden_states))\n",
    "        return hidden_states\n",
    "#         hidden_rep, logits = self.classifier(hidden_states)\n",
    "#         h1, h2, logits = self.classifier(hidden_states)\n",
    "\n",
    "#         loss = None\n",
    "#         if labels is not None:\n",
    "#             if self.config.problem_type is None:\n",
    "#                 if self.num_labels == 1:\n",
    "#                     self.config.problem_type = \"regression\"\n",
    "#                 elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "#                     self.config.problem_type = \"single_label_classification\"\n",
    "#                 else:\n",
    "#                     self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "#             if self.config.problem_type == \"regression\":\n",
    "#                 loss_fct = MSELoss()\n",
    "#                 loss = loss_fct(logits.view(-1, self.num_labels), labels)\n",
    "#             elif self.config.problem_type == \"single_label_classification\":\n",
    "#                 loss_fct = CrossEntropyLoss()\n",
    "#                 loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "#             elif self.config.problem_type == \"multi_label_classification\":\n",
    "#                 loss_fct = BCEWithLogitsLoss()\n",
    "#                 loss = loss_fct(logits, labels)\n",
    "\n",
    "#         if not return_dict:\n",
    "#             output = (h1 + h2 + logits,) + outputs[2:]\n",
    "#             return ((loss,) + output) if loss is not None else output\n",
    "        \n",
    "#         return SpeechClassifierOutput(\n",
    "# #             loss=loss,\n",
    "# #             logits=logits,\n",
    "#             hidden_states=outputs.hidden_states,\n",
    "# #             attentions=outputs.attentions,\n",
    "# #             h1=h1,\n",
    "# #             h2=h2\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c07c65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export CUDA_VISIBLE_DEVICES=0\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "346e99b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mswara\u001b[m  Tue May 24 01:38:27 2022\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 52'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 8725\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m8721M\u001b[m)\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 81'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 7947\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m7943M\u001b[m)\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 82'C\u001b[m, \u001b[1m\u001b[32m 73 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 6549\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m6545M\u001b[m)\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 53'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 6705\u001b[m / \u001b[33m11177\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m6701M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28d935af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bdbea82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at /home/mayank/MTP/begin_again/Error-Driven-ASR-Personalization/w2v2/w2v2_timit/checkpoint-7000/ were not used when initializing Wav2Vec2ForSpeechClassification: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing Wav2Vec2ForSpeechClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForSpeechClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# model_name_or_path = \"/mnt/data/aman/mayank/MTP/mount_points/jan_19/Error-Driven-ASR-Personalization/MCV_accent/data/dristi_accent-recognition/checkpoint-6400/\"\n",
    "model_name_or_path = \"/home/mayank/MTP/begin_again/Error-Driven-ASR-Personalization/w2v2/w2v2_timit/checkpoint-7000/\"\n",
    "config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name_or_path)\n",
    "sampling_rate = processor.feature_extractor.sampling_rate\n",
    "model = Wav2Vec2ForSpeechClassification.from_pretrained(model_name_or_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efda2596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mswara\u001b[m  Tue May 24 01:38:33 2022\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 53'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 8725\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m8721M\u001b[m)\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 81'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 7947\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m7943M\u001b[m)\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 84'C\u001b[m, \u001b[1m\u001b[32m 96 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 7746\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m6545M\u001b[m) \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m1197M\u001b[m)\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 53'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 6705\u001b[m / \u001b[33m11177\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m6701M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dbe4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(path, sampling_rate):\n",
    "    speech_array, _sampling_rate = torchaudio.load(path)\n",
    "    resampler = torchaudio.transforms.Resample(_sampling_rate)\n",
    "    speech = resampler(speech_array).squeeze().numpy()\n",
    "    return speech\n",
    "\n",
    "def predict(path, sampling_rate):\n",
    "#     print(path)\n",
    "    speech = speech_file_to_array_fn(path, sampling_rate)\n",
    "    features = processor(speech, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "    input_values = features.input_values.to(device)\n",
    "    attention_mask = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        op = model(input_values, attention_mask=attention_mask)\n",
    "#         logits = op.logits\n",
    "#         h1 = op.h1\n",
    "#         h2 = op.h2\n",
    "#         print(list(op))\n",
    "        pooled_w2v2_features = op\n",
    "        \n",
    "#     scores = F.softmax(logits, dim=1).detach().cpu().numpy()[0]\n",
    "#     outputs = [{\"Accent\": config.id2label[i], \"Score\": f\"{round(score * 100, 3):.1f}%\"} for i, score in enumerate(scores)]\n",
    "#     return outputs, h1, h2, logits\n",
    "    return pooled_w2v2_features\n",
    "\n",
    "def prediction(df_row):\n",
    "    if 'path' in df_row: path = df_row[\"path\"]\n",
    "    else: path = df_row[\"audio_filepath\"]\n",
    "    speech, sr = torchaudio.load(path)\n",
    "    speech = speech[0].numpy().squeeze()\n",
    "    speech = librosa.resample(np.asarray(speech), sr, sampling_rate)\n",
    "#     outputs, h1, h2, h3 = predict(path, sampling_rate)\n",
    "    outputs = predict(path, sampling_rate)\n",
    "    return outputs\n",
    "\n",
    "def extract_features(file_list, file_dir):\n",
    "    with open(file_dir.replace('.json', '_w2v2.file'), 'wb') as f:\n",
    "        for file in tqdm(file_list):\n",
    "            w2v2_features = prediction(file).cpu().detach().numpy()\n",
    "            pickle.dump(w2v2_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa7ddb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________\n",
      "malayalam_male_english\n",
      "seed_file_starting\n",
      "./indic-scripts/malayalam_male_english/manifests/seed.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/50 [00:00<00:38,  1.27it/s]\u001b[A\n",
      "  4%|▍         | 2/50 [00:01<00:22,  2.12it/s]\u001b[A\n",
      "  6%|▌         | 3/50 [00:01<00:19,  2.43it/s]\u001b[A\n",
      "  8%|▊         | 4/50 [00:01<00:16,  2.86it/s]\u001b[A\n",
      " 10%|█         | 5/50 [00:01<00:12,  3.48it/s]\u001b[A\n",
      " 12%|█▏        | 6/50 [00:01<00:10,  4.12it/s]\u001b[A\n",
      " 14%|█▍        | 7/50 [00:02<00:15,  2.77it/s]\u001b[A\n",
      " 16%|█▌        | 8/50 [00:03<00:17,  2.46it/s]\u001b[A\n",
      " 18%|█▊        | 9/50 [00:03<00:16,  2.44it/s]\u001b[A\n",
      " 20%|██        | 10/50 [00:04<00:18,  2.18it/s]\u001b[A\n",
      " 22%|██▏       | 11/50 [00:04<00:15,  2.49it/s]\u001b[A\n",
      " 24%|██▍       | 12/50 [00:04<00:15,  2.44it/s]\u001b[A\n",
      " 26%|██▌       | 13/50 [00:05<00:13,  2.76it/s]\u001b[A\n",
      " 28%|██▊       | 14/50 [00:05<00:12,  2.97it/s]\u001b[A\n",
      " 30%|███       | 15/50 [00:05<00:12,  2.86it/s]\u001b[A\n",
      " 32%|███▏      | 16/50 [00:06<00:11,  2.86it/s]\u001b[A\n",
      " 34%|███▍      | 17/50 [00:06<00:10,  3.08it/s]\u001b[A\n",
      " 36%|███▌      | 18/50 [00:06<00:10,  3.13it/s]\u001b[A\n",
      " 38%|███▊      | 19/50 [00:06<00:08,  3.72it/s]\u001b[A\n",
      " 40%|████      | 20/50 [00:07<00:09,  3.20it/s]\u001b[A\n",
      " 42%|████▏     | 21/50 [00:07<00:09,  3.21it/s]\u001b[A\n",
      " 44%|████▍     | 22/50 [00:07<00:08,  3.36it/s]\u001b[A\n",
      " 46%|████▌     | 23/50 [00:08<00:07,  3.45it/s]\u001b[A\n",
      " 48%|████▊     | 24/50 [00:08<00:07,  3.69it/s]\u001b[A\n",
      " 50%|█████     | 25/50 [00:08<00:06,  4.04it/s]\u001b[A\n",
      " 52%|█████▏    | 26/50 [00:08<00:05,  4.34it/s]\u001b[A\n",
      " 54%|█████▍    | 27/50 [00:08<00:04,  4.71it/s]\u001b[A\n",
      " 56%|█████▌    | 28/50 [00:09<00:05,  4.23it/s]\u001b[A\n",
      " 58%|█████▊    | 29/50 [00:09<00:04,  4.30it/s]\u001b[A\n",
      " 60%|██████    | 30/50 [00:09<00:04,  4.20it/s]\u001b[A\n",
      " 62%|██████▏   | 31/50 [00:09<00:04,  4.56it/s]\u001b[A\n",
      " 64%|██████▍   | 32/50 [00:09<00:03,  4.58it/s]\u001b[A\n",
      " 66%|██████▌   | 33/50 [00:10<00:03,  4.85it/s]\u001b[A\n",
      " 68%|██████▊   | 34/50 [00:10<00:03,  4.69it/s]\u001b[A\n",
      " 70%|███████   | 35/50 [00:10<00:03,  4.98it/s]\u001b[A\n",
      " 72%|███████▏  | 36/50 [00:10<00:02,  4.76it/s]\u001b[A\n",
      " 74%|███████▍  | 37/50 [00:10<00:02,  4.86it/s]\u001b[A\n",
      " 76%|███████▌  | 38/50 [00:11<00:02,  5.03it/s]\u001b[A\n",
      " 78%|███████▊  | 39/50 [00:11<00:02,  5.17it/s]\u001b[A\n",
      " 80%|████████  | 40/50 [00:11<00:02,  4.67it/s]\u001b[A\n",
      " 82%|████████▏ | 41/50 [00:11<00:02,  4.32it/s]\u001b[A\n",
      " 84%|████████▍ | 42/50 [00:12<00:01,  4.27it/s]\u001b[A\n",
      " 86%|████████▌ | 43/50 [00:12<00:01,  3.54it/s]\u001b[A\n",
      " 88%|████████▊ | 44/50 [00:12<00:01,  3.65it/s]\u001b[A\n",
      " 90%|█████████ | 45/50 [00:12<00:01,  4.13it/s]\u001b[A\n",
      " 92%|█████████▏| 46/50 [00:13<00:01,  3.58it/s]\u001b[A\n",
      " 94%|█████████▍| 47/50 [00:13<00:00,  3.82it/s]\u001b[A\n",
      " 96%|█████████▌| 48/50 [00:13<00:00,  4.00it/s]\u001b[A\n",
      " 98%|█████████▊| 49/50 [00:13<00:00,  4.21it/s]\u001b[A\n",
      "100%|██████████| 50/50 [00:14<00:00,  3.55it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "seed_file_ending ...\n",
      "\n",
      "selection_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3491 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/3491 [00:00<18:52,  3.08it/s]\u001b[A\n",
      "  0%|          | 2/3491 [00:00<16:18,  3.57it/s]\u001b[A\n",
      "  0%|          | 3/3491 [00:00<16:31,  3.52it/s]\u001b[A\n",
      "  0%|          | 4/3491 [00:01<18:03,  3.22it/s]\u001b[A\n",
      "  0%|          | 5/3491 [00:01<15:51,  3.66it/s]\u001b[A\n",
      "  0%|          | 6/3491 [00:01<13:45,  4.22it/s]\u001b[A\n",
      "  0%|          | 7/3491 [00:01<15:54,  3.65it/s]\u001b[A\n",
      "  0%|          | 8/3491 [00:02<17:21,  3.34it/s]\u001b[A\n",
      "  0%|          | 9/3491 [00:02<17:27,  3.33it/s]\u001b[A\n",
      "  0%|          | 10/3491 [00:03<21:14,  2.73it/s]\u001b[A\n",
      "  0%|          | 11/3491 [00:03<28:46,  2.02it/s]\u001b[A\n",
      "  0%|          | 12/3491 [00:04<31:31,  1.84it/s]\u001b[A\n",
      "  0%|          | 13/3491 [00:05<32:13,  1.80it/s]\u001b[A\n",
      "  0%|          | 14/3491 [00:05<26:35,  2.18it/s]\u001b[A\n",
      "  0%|          | 15/3491 [00:05<21:57,  2.64it/s]\u001b[A\n",
      "  0%|          | 16/3491 [00:05<19:45,  2.93it/s]\u001b[A\n",
      "  0%|          | 17/3491 [00:06<21:28,  2.70it/s]\u001b[A\n",
      "  1%|          | 18/3491 [00:06<22:05,  2.62it/s]\u001b[A\n",
      "  1%|          | 19/3491 [00:07<23:41,  2.44it/s]\u001b[A\n",
      "  1%|          | 20/3491 [00:07<22:32,  2.57it/s]\u001b[A\n",
      "  1%|          | 21/3491 [00:08<27:03,  2.14it/s]\u001b[A\n",
      "  1%|          | 22/3491 [00:08<31:14,  1.85it/s]\u001b[A\n",
      "  1%|          | 23/3491 [00:09<26:05,  2.22it/s]\u001b[A\n",
      "  1%|          | 24/3491 [00:09<25:49,  2.24it/s]\u001b[A\n",
      "  1%|          | 25/3491 [00:09<23:14,  2.48it/s]\u001b[A\n",
      "  1%|          | 26/3491 [00:10<21:51,  2.64it/s]\u001b[A\n",
      "  1%|          | 27/3491 [00:10<17:43,  3.26it/s]\u001b[A\n",
      "  1%|          | 28/3491 [00:10<16:13,  3.56it/s]\u001b[A\n",
      "  1%|          | 29/3491 [00:10<15:16,  3.78it/s]\u001b[A\n",
      "  1%|          | 30/3491 [00:10<14:40,  3.93it/s]\u001b[A\n",
      "  1%|          | 31/3491 [00:11<13:50,  4.16it/s]\u001b[A\n",
      "  1%|          | 32/3491 [00:11<16:59,  3.39it/s]\u001b[A\n",
      "  1%|          | 33/3491 [00:12<22:39,  2.54it/s]\u001b[A\n",
      "  1%|          | 34/3491 [00:12<27:25,  2.10it/s]\u001b[A\n",
      "  1%|          | 35/3491 [00:12<21:06,  2.73it/s]\u001b[A\n",
      "  1%|          | 36/3491 [00:13<20:48,  2.77it/s]\u001b[A\n",
      "  1%|          | 37/3491 [00:13<18:25,  3.12it/s]\u001b[A\n",
      "  1%|          | 38/3491 [00:14<24:30,  2.35it/s]\u001b[A\n",
      "  1%|          | 39/3491 [00:14<21:08,  2.72it/s]\u001b[A\n",
      "  1%|          | 40/3491 [00:14<19:20,  2.97it/s]\u001b[A\n",
      "  1%|          | 41/3491 [00:15<18:09,  3.17it/s]\u001b[A\n",
      "  1%|          | 42/3491 [00:15<17:23,  3.31it/s]\u001b[A\n",
      "  1%|          | 43/3491 [00:15<15:46,  3.64it/s]\u001b[A\n",
      "  1%|▏         | 44/3491 [00:15<15:48,  3.64it/s]\u001b[A\n",
      "  1%|▏         | 45/3491 [00:16<15:32,  3.70it/s]\u001b[A\n",
      "  1%|▏         | 46/3491 [00:16<20:46,  2.76it/s]\u001b[A\n",
      "  1%|▏         | 47/3491 [00:17<23:25,  2.45it/s]\u001b[A\n",
      "  1%|▏         | 48/3491 [00:17<25:49,  2.22it/s]\u001b[A\n",
      "  1%|▏         | 49/3491 [00:18<24:55,  2.30it/s]\u001b[A\n",
      "  1%|▏         | 50/3491 [00:18<29:45,  1.93it/s]\u001b[A\n",
      "  1%|▏         | 51/3491 [00:19<25:45,  2.23it/s]\u001b[A\n",
      "  1%|▏         | 52/3491 [00:19<26:03,  2.20it/s]\u001b[A\n",
      "  2%|▏         | 53/3491 [00:20<29:28,  1.94it/s]\u001b[A\n",
      "  2%|▏         | 54/3491 [00:20<23:56,  2.39it/s]\u001b[A\n",
      "  2%|▏         | 55/3491 [00:20<20:23,  2.81it/s]\u001b[A\n",
      "  2%|▏         | 56/3491 [00:20<19:23,  2.95it/s]\u001b[A\n",
      "  2%|▏         | 57/3491 [00:21<18:32,  3.09it/s]\u001b[A\n",
      "  2%|▏         | 58/3491 [00:21<20:26,  2.80it/s]\u001b[A\n",
      "  2%|▏         | 59/3491 [00:21<20:48,  2.75it/s]\u001b[A\n",
      "  2%|▏         | 60/3491 [00:22<19:04,  3.00it/s]\u001b[A\n",
      "  2%|▏         | 61/3491 [00:22<17:48,  3.21it/s]\u001b[A\n",
      "  2%|▏         | 62/3491 [00:22<17:51,  3.20it/s]\u001b[A\n",
      "  2%|▏         | 63/3491 [00:23<19:32,  2.92it/s]\u001b[A\n",
      "  2%|▏         | 64/3491 [00:23<17:55,  3.19it/s]\u001b[A\n",
      "  2%|▏         | 65/3491 [00:23<17:14,  3.31it/s]\u001b[A\n",
      "  2%|▏         | 66/3491 [00:24<16:14,  3.52it/s]\u001b[A\n",
      "  2%|▏         | 67/3491 [00:24<15:52,  3.59it/s]\u001b[A\n",
      "  2%|▏         | 68/3491 [00:24<17:17,  3.30it/s]\u001b[A\n",
      "  2%|▏         | 69/3491 [00:24<17:52,  3.19it/s]\u001b[A\n",
      "  2%|▏         | 70/3491 [00:25<16:47,  3.40it/s]\u001b[A\n",
      "  2%|▏         | 71/3491 [00:25<17:55,  3.18it/s]\u001b[A\n",
      "  2%|▏         | 72/3491 [00:26<19:54,  2.86it/s]\u001b[A\n",
      "  2%|▏         | 73/3491 [00:26<19:01,  3.00it/s]\u001b[A\n",
      "  2%|▏         | 74/3491 [00:26<17:07,  3.33it/s]\u001b[A\n",
      "  2%|▏         | 75/3491 [00:27<20:44,  2.75it/s]\u001b[A\n",
      "  2%|▏         | 76/3491 [00:27<21:47,  2.61it/s]\u001b[A\n",
      "  2%|▏         | 77/3491 [00:27<19:45,  2.88it/s]\u001b[A\n",
      "  2%|▏         | 78/3491 [00:28<19:45,  2.88it/s]\u001b[A\n",
      "  2%|▏         | 79/3491 [00:28<18:51,  3.02it/s]\u001b[A\n",
      "  2%|▏         | 80/3491 [00:28<21:41,  2.62it/s]\u001b[A\n",
      "  2%|▏         | 81/3491 [00:29<22:46,  2.49it/s]\u001b[A\n",
      "  2%|▏         | 82/3491 [00:29<21:16,  2.67it/s]\u001b[A\n",
      "  2%|▏         | 83/3491 [00:30<23:07,  2.46it/s]\u001b[A\n",
      "  2%|▏         | 84/3491 [00:30<22:44,  2.50it/s]\u001b[A\n",
      "  2%|▏         | 85/3491 [00:30<20:35,  2.76it/s]\u001b[A\n",
      "  2%|▏         | 86/3491 [00:31<21:53,  2.59it/s]\u001b[A\n",
      "  2%|▏         | 87/3491 [00:31<26:38,  2.13it/s]\u001b[A\n",
      "  3%|▎         | 88/3491 [00:32<29:46,  1.90it/s]\u001b[A\n",
      "  3%|▎         | 89/3491 [00:33<29:45,  1.91it/s]\u001b[A\n",
      "  3%|▎         | 90/3491 [00:33<26:23,  2.15it/s]\u001b[A\n",
      "  3%|▎         | 91/3491 [00:33<23:29,  2.41it/s]\u001b[A\n",
      "  3%|▎         | 92/3491 [00:34<22:33,  2.51it/s]\u001b[A\n",
      "  3%|▎         | 93/3491 [00:34<18:40,  3.03it/s]\u001b[A\n",
      "  3%|▎         | 94/3491 [00:34<17:13,  3.29it/s]\u001b[A\n",
      "  3%|▎         | 95/3491 [00:34<15:17,  3.70it/s]\u001b[A\n",
      "  3%|▎         | 96/3491 [00:34<14:46,  3.83it/s]\u001b[A\n",
      "  3%|▎         | 97/3491 [00:35<13:58,  4.05it/s]\u001b[A\n",
      "  3%|▎         | 98/3491 [00:35<15:38,  3.62it/s]\u001b[A\n",
      "  3%|▎         | 99/3491 [00:35<13:38,  4.15it/s]\u001b[A\n",
      "  3%|▎         | 100/3491 [00:35<14:00,  4.04it/s]\u001b[A\n",
      "  3%|▎         | 101/3491 [00:36<18:29,  3.06it/s]\u001b[A\n",
      "  3%|▎         | 102/3491 [00:36<19:31,  2.89it/s]\u001b[A\n",
      "  3%|▎         | 103/3491 [00:36<17:23,  3.25it/s]\u001b[A\n",
      "  3%|▎         | 104/3491 [00:37<22:40,  2.49it/s]\u001b[A\n",
      "  3%|▎         | 105/3491 [00:38<24:20,  2.32it/s]\u001b[A\n",
      "  3%|▎         | 106/3491 [00:38<27:52,  2.02it/s]\u001b[A\n",
      "  3%|▎         | 107/3491 [00:39<26:52,  2.10it/s]\u001b[A\n",
      "  3%|▎         | 108/3491 [00:39<23:39,  2.38it/s]\u001b[A\n",
      "  3%|▎         | 109/3491 [00:40<25:46,  2.19it/s]\u001b[A\n",
      "  3%|▎         | 110/3491 [00:40<25:25,  2.22it/s]\u001b[A\n",
      "  3%|▎         | 111/3491 [00:40<24:40,  2.28it/s]\u001b[A\n",
      "  3%|▎         | 112/3491 [00:41<23:51,  2.36it/s]\u001b[A\n",
      "  3%|▎         | 113/3491 [00:41<20:44,  2.71it/s]\u001b[A\n",
      "  3%|▎         | 114/3491 [00:41<21:58,  2.56it/s]\u001b[A\n",
      "  3%|▎         | 115/3491 [00:42<21:38,  2.60it/s]\u001b[A\n",
      "  3%|▎         | 116/3491 [00:42<19:11,  2.93it/s]\u001b[A\n",
      "  3%|▎         | 117/3491 [00:43<24:19,  2.31it/s]\u001b[A\n",
      "  3%|▎         | 118/3491 [00:43<23:20,  2.41it/s]\u001b[A\n",
      "  3%|▎         | 119/3491 [00:44<23:44,  2.37it/s]\u001b[A\n",
      "  3%|▎         | 120/3491 [00:44<24:20,  2.31it/s]\u001b[A\n",
      "  3%|▎         | 121/3491 [00:45<28:01,  2.00it/s]\u001b[A\n",
      "  3%|▎         | 122/3491 [00:45<24:16,  2.31it/s]\u001b[A\n",
      "  4%|▎         | 123/3491 [00:45<20:33,  2.73it/s]\u001b[A\n",
      "  4%|▎         | 124/3491 [00:45<18:11,  3.09it/s]\u001b[A\n",
      "  4%|▎         | 125/3491 [00:46<18:41,  3.00it/s]\u001b[A\n",
      "  4%|▎         | 126/3491 [00:46<17:45,  3.16it/s]\u001b[A\n",
      "  4%|▎         | 127/3491 [00:46<17:02,  3.29it/s]\u001b[A\n",
      "  4%|▎         | 128/3491 [00:46<14:55,  3.75it/s]\u001b[A\n",
      "  4%|▎         | 129/3491 [00:47<13:41,  4.09it/s]\u001b[A\n",
      "  4%|▎         | 130/3491 [00:47<12:48,  4.37it/s]\u001b[A\n",
      "  4%|▍         | 131/3491 [00:47<17:08,  3.27it/s]\u001b[A\n",
      "  4%|▍         | 132/3491 [00:48<16:53,  3.31it/s]\u001b[A\n",
      "  4%|▍         | 133/3491 [00:48<20:26,  2.74it/s]\u001b[A\n",
      "  4%|▍         | 134/3491 [00:48<18:13,  3.07it/s]\u001b[A\n",
      "  4%|▍         | 135/3491 [00:49<20:50,  2.68it/s]\u001b[A\n",
      "  4%|▍         | 136/3491 [00:49<20:38,  2.71it/s]\u001b[A\n",
      "  4%|▍         | 137/3491 [00:50<21:11,  2.64it/s]\u001b[A\n",
      "  4%|▍         | 138/3491 [00:50<25:53,  2.16it/s]\u001b[A\n",
      "  4%|▍         | 139/3491 [00:51<28:55,  1.93it/s]\u001b[A\n",
      "  4%|▍         | 140/3491 [00:51<28:59,  1.93it/s]\u001b[A\n",
      "  4%|▍         | 141/3491 [00:52<34:05,  1.64it/s]\u001b[A\n",
      "  4%|▍         | 142/3491 [00:53<28:48,  1.94it/s]\u001b[A\n",
      "  4%|▍         | 143/3491 [00:53<27:27,  2.03it/s]\u001b[A\n",
      "  4%|▍         | 144/3491 [00:53<22:25,  2.49it/s]\u001b[A\n",
      "  4%|▍         | 145/3491 [00:53<19:27,  2.87it/s]\u001b[A\n",
      "  4%|▍         | 146/3491 [00:54<19:41,  2.83it/s]\u001b[A\n",
      "  4%|▍         | 147/3491 [00:54<23:05,  2.41it/s]\u001b[A\n",
      "  4%|▍         | 148/3491 [00:55<22:27,  2.48it/s]\u001b[A\n",
      "  4%|▍         | 149/3491 [00:55<25:52,  2.15it/s]\u001b[A\n",
      "  4%|▍         | 150/3491 [00:56<22:16,  2.50it/s]\u001b[A\n",
      "  4%|▍         | 151/3491 [00:56<21:53,  2.54it/s]\u001b[A\n",
      "  4%|▍         | 152/3491 [00:56<21:57,  2.53it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 153/3491 [00:57<21:29,  2.59it/s]\u001b[A\n",
      "  4%|▍         | 154/3491 [00:57<21:01,  2.65it/s]\u001b[A\n",
      "  4%|▍         | 155/3491 [00:57<21:03,  2.64it/s]\u001b[A\n",
      "  4%|▍         | 156/3491 [00:58<19:39,  2.83it/s]\u001b[A\n",
      "  4%|▍         | 157/3491 [00:58<20:43,  2.68it/s]\u001b[A\n",
      "  0%|          | 0/1 [01:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d5584ee897cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'selection_file_starting'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselection_file_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'selection_file_ending ...\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-eab9e19a1428>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(file_list, file_dir)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_w2v2.file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mw2v2_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v2_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-eab9e19a1428>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(df_row)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'path'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_row\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"audio_filepath\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mspeech\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mspeech\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeech\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mspeech\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/w2v2/lib/python3.6/site-packages/torchaudio/backend/sox_io_backend.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     return torch.ops.torchaudio.sox_io_load_audio_file(\n\u001b[0;32m--> 153\u001b[0;31m         filepath, frame_offset, num_frames, normalize, channels_first, format)\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_dir = './'\n",
    "\n",
    "accents = [ 'malayalam_male_english']\n",
    "# 'african', 'indian', 'hongkong', 'philippines', \n",
    "#            'england', \n",
    "# 'scotland', 'ireland', 'australia', \n",
    "#            'canada', \n",
    "#            'bermuda', 'southatlandtic', 'wales', 'malaysia']\n",
    "\n",
    "for accent in tqdm(accents):\n",
    "    manifests_path = base_dir + f'indic-scripts/{accent}/manifests/'\n",
    "#     manifests_path = base_dir + accent + '/manifests/'\n",
    "    print('_'*20)\n",
    "    print(accent)\n",
    "\n",
    "    seed_file_dir = manifests_path + 'seed.json'\n",
    "    seed_file = open(seed_file_dir)\n",
    "    seed_list = [json.loads(line.strip()) for line in seed_file]\n",
    "\n",
    "    print('seed_file_starting')\n",
    "    print(seed_file_dir)\n",
    "    extract_features(seed_list, seed_file_dir)\n",
    "    print(len(seed_list))\n",
    "    print('seed_file_ending ...\\n')\n",
    "    \n",
    "    \n",
    "    selection_file_dir = manifests_path + 'selection.json'\n",
    "    selection_file = open(selection_file_dir)\n",
    "    selection_list = [json.loads(line.strip()) for line in selection_file]\n",
    "    \n",
    "    print('selection_file_starting')\n",
    "    extract_features(selection_list, selection_file_dir)\n",
    "    print(len(selection_list))\n",
    "    print('selection_file_ending ...\\n\\n')\n",
    "    \n",
    "    \n",
    "    test_file_dir = manifests_path + 'test.json'\n",
    "    test_file = open(test_file_dir)\n",
    "    test_list = [json.loads(line.strip()) for line in test_file]\n",
    "\n",
    "    print('test_file_starting')\n",
    "    extract_features(test_list, test_file_dir)\n",
    "    print(len(test_list))\n",
    "    print('test_file_ending ...\\n\\n')\n",
    "    \n",
    "    \n",
    "    dev_file_dir = manifests_path + 'dev.json'\n",
    "    dev_file = open(dev_file_dir)\n",
    "    dev_list = [json.loads(line.strip()) for line in dev_file]\n",
    "\n",
    "    print('dev_file_starting')\n",
    "    print(dev_file_dir)\n",
    "    extract_features(dev_list, dev_file_dir)\n",
    "    print(len(dev_list))\n",
    "    print('dev_file_ending ...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719382b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f931774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde4bb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7fc71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w2v2",
   "language": "python",
   "name": "w2v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
