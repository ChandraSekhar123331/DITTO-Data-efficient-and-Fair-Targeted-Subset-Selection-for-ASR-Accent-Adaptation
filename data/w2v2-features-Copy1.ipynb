{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45f8289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4af3700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import numpy as np, pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers.file_utils import ModelOutput\n",
    "from transformers import AutoConfig, Wav2Vec2Processor\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import (\n",
    "    Wav2Vec2PreTrainedModel,\n",
    "    Wav2Vec2Model\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torchaudio, os, sys, json, pickle, librosa\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb70663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dataclass\n",
    "# class SpeechClassifierOutput(ModelOutput):\n",
    "# #     loss: Optional[torch.FloatTensor] = None\n",
    "# #     logits: torch.FloatTensor = None\n",
    "#     hidden_states: Optional[Tuple[torch.FloatTensor]]\n",
    "# #     attentions: Optional[Tuple[torch.FloatTensor]]\n",
    "# #     h1: Optional[Tuple[torch.FloatTensor]] = None\n",
    "#     h2: Optional[Tuple[torch.FloatTensor]] = None\n",
    "\n",
    "# class Wav2Vec2ClassificationHead(nn.Module):\n",
    "#     \"\"\"Head for wav2vec classification task.\"\"\"\n",
    "\n",
    "#     def __init__(self, config):\n",
    "#         super().__init__()\n",
    "#         self.dense1 = nn.Linear(config.hidden_size, 300)\n",
    "#         self.dense2 = nn.Linear(300, 100)\n",
    "#         self.dropout = nn.Dropout(config.final_dropout)\n",
    "#         self.out_proj = nn.Linear(100, config.num_labels)\n",
    "\n",
    "\n",
    "#     def forward(self, features, **kwargs):\n",
    "#         x = features\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.dense1(x)\n",
    "#         x1 = torch.tanh(x)\n",
    "#         x2 = self.dropout(x1)\n",
    "#         x2 = self.dense2(x2)\n",
    "#         x2 = torch.tanh(x2)\n",
    "#         x3 = self.dropout(x2)        \n",
    "#         x3 = self.out_proj(x3)\n",
    "#         return x1, x2, x3\n",
    "\n",
    "class Wav2Vec2ForSpeechClassification(Wav2Vec2PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        config.pooling_mode = \"mean\"\n",
    "        self.pooling_mode = config.pooling_mode\n",
    "        self.config = config\n",
    "\n",
    "        self.wav2vec2 = Wav2Vec2Model(config)\n",
    "#         self.classifier = Wav2Vec2ClassificationHead(config)\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "    def freeze_feature_extractor(self):\n",
    "        self.wav2vec2.feature_extractor._freeze_parameters()\n",
    "        for module in self.wav2vec2.encoder.layers[:10]:\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def merged_strategy(self, hidden_states, mode=\"mean\"):\n",
    "        if mode == \"mean\":\n",
    "            outputs = torch.mean(hidden_states, dim=1)\n",
    "        elif mode == \"sum\":\n",
    "            outputs = torch.sum(hidden_states, dim=1)\n",
    "        elif mode == \"max\":\n",
    "            outputs = torch.max(hidden_states, dim=1)[0]\n",
    "        else:\n",
    "            raise Exception(\"The pooling method hasn't been defined! Your pooling mode must be one of these ['mean', 'sum', 'max']\")\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_values,\n",
    "            attention_mask=None,\n",
    "            output_attentions=None,\n",
    "            output_hidden_states=None,\n",
    "            return_dict=None,\n",
    "            labels=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        outputs = self.wav2vec2(\n",
    "            input_values,\n",
    "            attention_mask=attention_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        hidden_states = outputs[0]\n",
    "        hidden_states = self.merged_strategy(hidden_states, mode=self.pooling_mode)\n",
    "#         print(\"type of hidden_states is = \", type(hidden_states))\n",
    "        return hidden_states\n",
    "#         hidden_rep, logits = self.classifier(hidden_states)\n",
    "#         h1, h2, logits = self.classifier(hidden_states)\n",
    "\n",
    "#         loss = None\n",
    "#         if labels is not None:\n",
    "#             if self.config.problem_type is None:\n",
    "#                 if self.num_labels == 1:\n",
    "#                     self.config.problem_type = \"regression\"\n",
    "#                 elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "#                     self.config.problem_type = \"single_label_classification\"\n",
    "#                 else:\n",
    "#                     self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "#             if self.config.problem_type == \"regression\":\n",
    "#                 loss_fct = MSELoss()\n",
    "#                 loss = loss_fct(logits.view(-1, self.num_labels), labels)\n",
    "#             elif self.config.problem_type == \"single_label_classification\":\n",
    "#                 loss_fct = CrossEntropyLoss()\n",
    "#                 loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "#             elif self.config.problem_type == \"multi_label_classification\":\n",
    "#                 loss_fct = BCEWithLogitsLoss()\n",
    "#                 loss = loss_fct(logits, labels)\n",
    "\n",
    "#         if not return_dict:\n",
    "#             output = (h1 + h2 + logits,) + outputs[2:]\n",
    "#             return ((loss,) + output) if loss is not None else output\n",
    "        \n",
    "#         return SpeechClassifierOutput(\n",
    "# #             loss=loss,\n",
    "# #             logits=logits,\n",
    "#             hidden_states=outputs.hidden_states,\n",
    "# #             attentions=outputs.attentions,\n",
    "# #             h1=h1,\n",
    "# #             h2=h2\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c07c65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export CUDA_VISIBLE_DEVICES=0\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "346e99b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mswara\u001b[m  Tue May 24 18:02:56 2022\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[31m 36'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 8725\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m8721M\u001b[m)\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[31m 35'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 2117\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m2113M\u001b[m)\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[31m 34'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    1\u001b[m / \u001b[33m11178\u001b[m MB |\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[31m 45'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 6705\u001b[m / \u001b[33m11177\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m6701M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28d935af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bdbea82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at /home/mayank/MTP/begin_again/Error-Driven-ASR-Personalization/w2v2/w2v2_timit/checkpoint-7000/ were not used when initializing Wav2Vec2ForSpeechClassification: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2ForSpeechClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForSpeechClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# model_name_or_path = \"/mnt/data/aman/mayank/MTP/mount_points/jan_19/Error-Driven-ASR-Personalization/MCV_accent/data/dristi_accent-recognition/checkpoint-6400/\"\n",
    "model_name_or_path = \"/home/mayank/MTP/begin_again/Error-Driven-ASR-Personalization/w2v2/w2v2_timit/checkpoint-7000/\"\n",
    "config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name_or_path)\n",
    "sampling_rate = processor.feature_extractor.sampling_rate\n",
    "model = Wav2Vec2ForSpeechClassification.from_pretrained(model_name_or_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2872273c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mswara\u001b[m  Tue May 24 18:03:06 2022\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[31m 36'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 8725\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m8721M\u001b[m)\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[31m 36'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 2117\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m2113M\u001b[m)\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[31m 36'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 1201\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m1197M\u001b[m)\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[31m 45'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 6705\u001b[m / \u001b[33m11177\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m6701M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dbe4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(path, sampling_rate):\n",
    "    speech_array, _sampling_rate = torchaudio.load(path)\n",
    "    resampler = torchaudio.transforms.Resample(_sampling_rate)\n",
    "    speech = resampler(speech_array).squeeze().numpy()\n",
    "    return speech\n",
    "\n",
    "def predict(path, sampling_rate):\n",
    "#     print(path)\n",
    "    speech = speech_file_to_array_fn(path, sampling_rate)\n",
    "    features = processor(speech, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "    input_values = features.input_values.to(device)\n",
    "    attention_mask = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        op = model(input_values, attention_mask=attention_mask)\n",
    "#         logits = op.logits\n",
    "#         h1 = op.h1\n",
    "#         h2 = op.h2\n",
    "#         print(list(op))\n",
    "        pooled_w2v2_features = op\n",
    "        \n",
    "#     scores = F.softmax(logits, dim=1).detach().cpu().numpy()[0]\n",
    "#     outputs = [{\"Accent\": config.id2label[i], \"Score\": f\"{round(score * 100, 3):.1f}%\"} for i, score in enumerate(scores)]\n",
    "#     return outputs, h1, h2, logits\n",
    "    return pooled_w2v2_features\n",
    "\n",
    "def prediction(df_row):\n",
    "    if 'path' in df_row: path = df_row[\"path\"]\n",
    "    else: path = df_row[\"audio_filepath\"]\n",
    "    speech, sr = torchaudio.load(path)\n",
    "    speech = speech[0].numpy().squeeze()\n",
    "    speech = librosa.resample(np.asarray(speech), sr, sampling_rate)\n",
    "#     outputs, h1, h2, h3 = predict(path, sampling_rate)\n",
    "    outputs = predict(path, sampling_rate)\n",
    "    return outputs\n",
    "\n",
    "def extract_features(file_list, file_dir):\n",
    "    with open(file_dir.replace('.json', '_w2v2.file'), 'wb') as f:\n",
    "        for file in tqdm(file_list, position=0, leave=True):\n",
    "            w2v2_features = prediction(file).cpu().detach().numpy()\n",
    "            pickle.dump(w2v2_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa7ddb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________\n",
      "kannada_male_english\n",
      "seed_file_starting\n",
      ".//kannada_male_english/w2v2/seed.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:11<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "seed_file_ending ...\n",
      "\n",
      "selection_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3244/3244 [15:56<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3244\n",
      "selection_file_ending ...\n",
      "\n",
      "\n",
      "test_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1433/1433 [06:26<00:00,  3.71it/s]\n",
      " 14%|█▍        | 1/7 [22:35<2:15:32, 1355.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1433\n",
      "test_file_ending ...\n",
      "\n",
      "\n",
      "____________________\n",
      "manipuri_female_english\n",
      "seed_file_starting\n",
      ".//manipuri_female_english/w2v2/seed.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "seed_file_ending ...\n",
      "\n",
      "selection_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6925/6925 [25:31<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6925\n",
      "selection_file_ending ...\n",
      "\n",
      "\n",
      "test_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 483/3010 [01:22<07:32,  5.58it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 3010/3010 [08:38<00:00,  5.81it/s]\n",
      " 29%|██▊       | 2/7 [56:54<2:27:26, 1769.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3010\n",
      "test_file_ending ...\n",
      "\n",
      "\n",
      "____________________\n",
      "rajasthani_male_english\n",
      "seed_file_starting\n",
      ".//rajasthani_male_english/w2v2/seed.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:15<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "seed_file_ending ...\n",
      "\n",
      "selection_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3267/3267 [16:35<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3267\n",
      "selection_file_ending ...\n",
      "\n",
      "\n",
      "test_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1442/1442 [07:49<00:00,  3.07it/s]\n",
      " 43%|████▎     | 3/7 [1:21:35<1:49:10, 1637.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1442\n",
      "test_file_ending ...\n",
      "\n",
      "\n",
      "____________________\n",
      "hindi_male_english\n",
      "seed_file_starting\n",
      ".//hindi_male_english/w2v2/seed.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:10<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "seed_file_ending ...\n",
      "\n",
      "selection_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3492/3492 [15:24<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3492\n",
      "selection_file_ending ...\n",
      "\n",
      "\n",
      "test_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1539/1539 [06:11<00:00,  4.14it/s]\n",
      " 57%|█████▋    | 4/7 [1:43:21<1:15:20, 1506.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1539\n",
      "test_file_ending ...\n",
      "\n",
      "\n",
      "____________________\n",
      "gujarati_female_english\n",
      "seed_file_starting\n",
      ".//gujarati_female_english/w2v2/seed.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "seed_file_ending ...\n",
      "\n",
      "selection_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3169/3169 [20:37<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3169\n",
      "selection_file_ending ...\n",
      "\n",
      "\n",
      "test_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1401/1401 [08:26<00:00,  2.76it/s]\n",
      " 71%|███████▏  | 5/7 [2:12:42<53:16, 1598.47s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1401\n",
      "test_file_ending ...\n",
      "\n",
      "\n",
      "____________________\n",
      "assamese_female_english\n",
      "seed_file_starting\n",
      ".//assamese_female_english/w2v2/seed.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:15<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "seed_file_ending ...\n",
      "\n",
      "selection_file_starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 4248/5765 [20:49<05:45,  4.39it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 2263/2263 [09:07<00:00,  4.13it/s]\n",
      "100%|██████████| 7/7 [3:27:41<00:00, 1780.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2263\n",
      "test_file_ending ...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = './'\n",
    "\n",
    "# accents = [ 'malayalam_male_english', 'kannada_male_english', 'manipuri_female_english', 'rajasthani_male_english',\n",
    "#         'hindi_male_english', 'gujarati_female_english', 'assamese_female_english', 'tamil_male_english']\n",
    "\n",
    "accents = [ 'kannada_male_english', 'manipuri_female_english', 'rajasthani_male_english',\n",
    "        'hindi_male_english', 'gujarati_female_english', 'assamese_female_english', 'tamil_male_english']\n",
    "\n",
    "\n",
    "for accent in tqdm(accents):\n",
    "    manifests_path = base_dir + f'/{accent}/'\n",
    "    !mkdir -p $manifests_path/w2v2/\n",
    "#     manifests_path = base_dir + accent + '/manifests/'\n",
    "    print('_'*20)\n",
    "    print(accent)\n",
    "\n",
    "    seed_file_dir = manifests_path + 'w2v2/seed.json'\n",
    "    seed_file_path = manifests_path + 'seed.json'\n",
    "    seed_file = open(seed_file_path)\n",
    "    seed_list = [json.loads(line.strip()) for line in seed_file]\n",
    "\n",
    "    print('seed_file_starting')\n",
    "    print(seed_file_dir)\n",
    "    extract_features(seed_list, seed_file_dir)\n",
    "    print(len(seed_list))\n",
    "    print('seed_file_ending ...\\n')\n",
    "    \n",
    "    \n",
    "    selection_file_dir = manifests_path + 'w2v2/selection.json'\n",
    "    selection_file_path = manifests_path + 'selection.json'\n",
    "    selection_file = open(selection_file_path)\n",
    "    selection_list = [json.loads(line.strip()) for line in selection_file]\n",
    "    \n",
    "    print('selection_file_starting')\n",
    "    extract_features(selection_list, selection_file_dir)\n",
    "    print(len(selection_list))\n",
    "    print('selection_file_ending ...\\n\\n')\n",
    "    \n",
    "    \n",
    "    test_file_dir = manifests_path + 'w2v2/test.json'\n",
    "    test_file_path = manifests_path + 'test.json'\n",
    "    test_file = open(test_file_path)\n",
    "    test_list = [json.loads(line.strip()) for line in test_file]\n",
    "\n",
    "    print('test_file_starting')\n",
    "    extract_features(test_list, test_file_dir)\n",
    "    print(len(test_list))\n",
    "    print('test_file_ending ...\\n\\n')\n",
    "    \n",
    "    \n",
    "#     dev_file_dir = manifests_path + 'w2v2/'\n",
    "#     dev_file_path = manifests_path + 'dev.json'\n",
    "#     dev_file = open(dev_file_path)\n",
    "#     dev_list = [json.loads(line.strip()) for line in dev_file]\n",
    "\n",
    "#     print('dev_file_starting')\n",
    "#     print(dev_file_dir)\n",
    "#     extract_features(dev_list, dev_file_dir)\n",
    "#     print(len(dev_list))\n",
    "#     print('dev_file_ending ...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719382b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________\n",
      "Setting: ./malayalam_male_english/all/budget_2000/target_20/FL2MI/39\n",
      "train_file_starting\n",
      "./malayalam_male_english/all/budget_2000/target_20/FL2MI/39/train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1682/1682 [07:31<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n",
      "train_file_ending ...\n",
      "\n",
      "____________________\n",
      "Setting: ./kannada_male_english/all/budget_2000/target_20/FL2MI/39\n",
      "train_file_starting\n",
      "./kannada_male_english/all/budget_2000/target_20/FL2MI/39/train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1672/1672 [07:25<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1672\n",
      "train_file_ending ...\n",
      "\n",
      "____________________\n",
      "Setting: ./manipuri_female_english/all/budget_2000/target_20/FL2MI/39\n",
      "train_file_starting\n",
      "./manipuri_female_english/all/budget_2000/target_20/FL2MI/39/train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 2432/2484 [07:15<00:08,  6.26it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 3050/3050 [12:55<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3050\n",
      "train_file_ending ...\n",
      "\n",
      "____________________\n",
      "Setting: ./kannada_male_english/all/budget_3500/target_20/FL2MI/39\n",
      "train_file_starting\n",
      "./kannada_male_english/all/budget_3500/target_20/FL2MI/39/train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3065/3065 [13:01<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3065\n",
      "train_file_ending ...\n",
      "\n",
      "____________________\n",
      "Setting: ./manipuri_female_english/all/budget_3500/target_20/FL2MI/39\n",
      "train_file_starting\n",
      "./manipuri_female_english/all/budget_3500/target_20/FL2MI/39/train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4447/4447 [13:09<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4447\n",
      "train_file_ending ...\n",
      "\n",
      "____________________\n",
      "Setting: ./rajasthani_male_english/all/budget_3500/target_20/FL2MI/39\n",
      "train_file_starting\n",
      "./rajasthani_male_english/all/budget_3500/target_20/FL2MI/39/train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3202/3202 [13:14<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3202\n",
      "train_file_ending ...\n",
      "\n",
      "____________________\n",
      "Setting: ./hindi_male_english/all/budget_3500/target_20/FL2MI/39\n",
      "train_file_starting\n",
      "./hindi_male_english/all/budget_3500/target_20/FL2MI/39/train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3365/3365 [15:24<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3365\n",
      "train_file_ending ...\n",
      "\n",
      "____________________\n",
      "Setting: ./gujarati_female_english/all/budget_3500/target_20/FL2MI/39\n",
      "train_file_starting\n",
      "./gujarati_female_english/all/budget_3500/target_20/FL2MI/39/train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1647/2269 [10:52<05:06,  2.03it/s]"
     ]
    }
   ],
   "source": [
    "for b1 in [2000, 3500]:\n",
    "    for target in [20]:\n",
    "        for fxn in [\"FL2MI\"]:\n",
    "            for ft in [\"39\"]:\n",
    "                for accent in [ 'malayalam_male_english', 'kannada_male_english', 'manipuri_female_english', 'rajasthani_male_english', \n",
    "                               'hindi_male_english', 'gujarati_female_english', 'assamese_female_english', 'tamil_male_english']:\n",
    "\n",
    "\n",
    "                    base_dir = f'./{accent}/all/budget_{b1}/target_{target}/{fxn}/{ft}'\n",
    "                    manifests_path = base_dir + f'/train.json'\n",
    "                    print('_'*20)\n",
    "                    print(f'Setting: {base_dir}')\n",
    "                    train_file_path = manifests_path\n",
    "                    train_file_dir = train_file_path\n",
    "                    train_file = open(train_file_path)\n",
    "                    train_list = [json.loads(line.strip()) for line in train_file] \n",
    "\n",
    "                    print('train_file_starting')\n",
    "                    print(train_file_dir)\n",
    "                    extract_features(train_list, train_file_dir)\n",
    "                    print(len(train_list))\n",
    "                    print('train_file_ending ...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f931774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mswara\u001b[m  Tue May 24 20:54:00 2022\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 50'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 8725\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m8721M\u001b[m)\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 86'C\u001b[m, \u001b[1m\u001b[32m100 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 7973\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m7969M\u001b[m)\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 64'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 3411\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m3407M\u001b[m)\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 50'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 6705\u001b[m / \u001b[33m11177\u001b[m MB | \u001b[1m\u001b[30mmayank\u001b[m(\u001b[33m6701M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "# !gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde4bb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7fc71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w2v2",
   "language": "python",
   "name": "w2v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
