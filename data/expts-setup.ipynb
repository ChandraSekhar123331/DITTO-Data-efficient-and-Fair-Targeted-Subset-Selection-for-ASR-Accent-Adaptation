{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a22f7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import librosa, glob, sys, json, pickle, os, random, linecache, statistics\n",
    "from tqdm import tqdm\n",
    "import pandas as pd, numpy as np\n",
    "from IPython.core.display import display, HTML\n",
    "from collections import Counter\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "701c46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up random selections\n",
    "accents = ['kannada_male_english', 'malayalam_male_english', 'rajasthani_male_english', 'hindi_male_english', \n",
    "           'tamil_male_english', 'gujarati_female_english', 'manipuri_female_english', 'assamese_female_english']\n",
    "\n",
    "# random.seed(42)\n",
    "\n",
    "def _write(manifests_path, items, file):\n",
    "    with open(manifests_path+file, 'w') as f:\n",
    "        for item in items:\n",
    "            json.dump(item, f)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8343ded3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3244\n",
      "6735\n",
      "10002\n",
      "13494\n",
      "18677\n",
      "21846\n",
      "28771\n",
      "34536\n"
     ]
    }
   ],
   "source": [
    "global_files = []\n",
    "manifests_path = 'random/'\n",
    "\n",
    "for accent in accents:\n",
    "\taccent_json = open(accent+'/selection.json', 'r')\n",
    "\tfiles = accent_json.readlines()\n",
    "\tfiles = [json.loads(file) for file in files]\n",
    "\trandom.shuffle(files)\n",
    "\tglobal_files.extend(files)\n",
    "\tprint(len(global_files))\n",
    "\n",
    "random.shuffle(global_files)\n",
    "_write(manifests_path, global_files, 'all_selection.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8299bb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5765 assamese_female_english/selection.json\n",
      "    3169 gujarati_female_english/selection.json\n",
      "    3492 hindi_male_english/selection.json\n",
      "    3244 kannada_male_english/selection.json\n",
      "    3491 malayalam_male_english/selection.json\n",
      "    6925 manipuri_female_english/selection.json\n",
      "    3267 rajasthani_male_english/selection.json\n",
      "    5183 tamil_male_english/selection.json\n",
      "   34536 total\n",
      "34536 random/all_selection.json\n"
     ]
    }
   ],
   "source": [
    "!wc -l */selection.json\n",
    "!wc -l random/all_selection.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d0b9c24",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-d568b34125cf>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-d568b34125cf>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def random_lines(filename, budget)\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def random_lines(filename, budget)\n",
    "    idxs = random.sample(range(35329), budget)\n",
    "    return [linecache.getline(filename, i) for i in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1855e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def budget(budget_size):\n",
    "    return int(4.92*budget_size)\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "ground_list = [json.loads(line.strip()) for line in open('random/all_selection.json')]\n",
    "\n",
    "for budget_size in [100, 200, 250, 300, 400, 500, 600, 700, 800, 1000, 2000, 3000, 4000]:\n",
    "    output_dir = 'random/{}'.format(budget_size)\n",
    "    list_total_selection, list_total_count, list_total_duration = [], [], []\n",
    "    list_accent_sample_count, list_accent_sample_duration = {}, {}\n",
    "    for accent in accents:\n",
    "        list_accent_sample_count[accent] = []\n",
    "        list_accent_sample_duration[accent] = []\n",
    "    \n",
    "    for i in [1, 2, 3]:\n",
    "        run = f'run_{i}'\n",
    "        run_dir = os.path.join(output_dir, run)\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "        # for folder in ['train', 'output', 'plots']:\n",
    "        #     os.makedirs(os.path.join(run_dir, folder))\n",
    "        all_indices = list(range(len(ground_list)))\n",
    "        random.seed(i)\n",
    "        random.shuffle(all_indices)\n",
    "        total_duration, index = 0, 0\n",
    "        while total_duration + ground_list[all_indices[index]]['duration'] <= budget(budget_size):\n",
    "            total_duration += ground_list[all_indices[index]]['duration']\n",
    "            index += 1\n",
    "        list_total_count.append(index)\n",
    "        list_total_duration.append(total_duration)\n",
    "        selected_indices = all_indices[:index]\n",
    "        selected_list = [ground_list[j] for j in selected_indices]\n",
    "\n",
    "#        train_list = selected_list + query_list\n",
    "        train_list = selected_list\n",
    "        \n",
    "        for accent in accents:\n",
    "            accent_sample_count, accent_sample_duration = 0, 0\n",
    "            for item in selected_list:\n",
    "                if item['audio_filepath'].split('/')[-4] == accent:\n",
    "                    accent_sample_count += 1\n",
    "                    accent_sample_duration += item['duration']\n",
    "            list_accent_sample_count[accent].append(accent_sample_count)\n",
    "            list_accent_sample_duration[accent].append(accent_sample_duration)\n",
    "        list_total_selection.append(Counter([item['audio_filepath'].split('/')[-4] for item in selected_list]))\n",
    "        \n",
    "#        with open(base_dir + query_dir + f'train/error_model/{budget_size}/seed_{i}/train.json', 'w') as f:\n",
    "#            for line in train_list:\n",
    "#                f.write('{}\\n'.format(json.dumps(line)))\n",
    "        with open(f'{run_dir}/train.json', 'w') as f:\n",
    "            for line in train_list:\n",
    "                f.write('{}\\n'.format(json.dumps(line)))\n",
    "                \n",
    "#        plots(dirs, run_dir, ground_features, ground_features_Y, query_features, test_features, selected_indices)\n",
    "    \n",
    "    stats = 'total selection : ' + ' '.join(map(str, list_total_count)) + ' -> {0:.2f}\\n'.format(statistics.mean(list_total_count))\n",
    "    stats += 'total selection duration: ' + ' '.join(map(str, list_total_duration)) + ' -> {0:.2f}\\n'.format(statistics.mean(list_total_duration))\n",
    "    for accent in accents:\n",
    "        stats += '\\naccent: {}\\n'.format(accent)\n",
    "        stats += 'accented selection: ' + ' '.join(map(str, list_accent_sample_count[accent])) + ' -> {0:.2f}\\n'.format(statistics.mean(list_accent_sample_count[accent]))\n",
    "        stats += 'accented duration: ' + ' '.join(map(str, list_accent_sample_duration[accent])) + ' -> {0:.2f}\\n'.format(statistics.mean(list_accent_sample_duration[accent]))\n",
    "    stats += '\\nall selections: ' + str(list_total_selection)\n",
    "    \n",
    "    with open(output_dir + '/stats.txt', 'w') as f:\n",
    "        f.write(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa626e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import json, os, torch, statistics, glob, librosa, pickle, torchaudio\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "mfcc_transform = T.MFCC(\n",
    "    sample_rate=22050,\n",
    "    n_mfcc=39,\n",
    "    melkwargs={\n",
    "      'n_fft': 2048,\n",
    "      'n_mels': 256,\n",
    "      'hop_length': 512,\n",
    "      'mel_scale': 'htk',\n",
    "    }\n",
    ")\n",
    "base_dir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b6d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_list, file_dir):\n",
    "    file_type = file_dir.split('/')[-1].replace('.json', '')\n",
    "    feature_dir = '/'.join(file_dir.split('/')[:-1])+'/39/'\n",
    "    os.makedirs(os.path.dirname(feature_dir), exist_ok=True)\n",
    "    feature_file = feature_dir+file_type+'_39.file'\n",
    "    with open(feature_file, 'wb') as f:\n",
    "        for file in tqdm(file_list):\n",
    "            waveform, sample_rate = torchaudio.load(file['audio_filepath'])\n",
    "            mfcc_features = mfcc_transform(waveform).mean(2).detach().numpy()\n",
    "            pickle.dump(mfcc_features, f)\n",
    "    print(\"completed\", file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6237e788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kannada_male_english\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1433/1433 [00:35<00:00, 40.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed kannada_male_english/test.json\n",
      "selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3244/3244 [01:09<00:00, 46.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed kannada_male_english/selection.json\n",
      "seed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 50.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed kannada_male_english/seed.json\n",
      "\n",
      "\n",
      "\n",
      "malayalam_male_english\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1539/1539 [02:01<00:00, 12.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed malayalam_male_english/test.json\n",
      "selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3491/3491 [03:16<00:00, 17.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed malayalam_male_english/selection.json\n",
      "seed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 51.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed malayalam_male_english/seed.json\n",
      "\n",
      "\n",
      "\n",
      "rajasthani_male_english\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1442/1442 [02:00<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed rajasthani_male_english/test.json\n",
      "selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3267/3267 [03:05<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed rajasthani_male_english/selection.json\n",
      "seed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 46.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed rajasthani_male_english/seed.json\n",
      "\n",
      "\n",
      "\n",
      "hindi_male_english\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1539/1539 [01:59<00:00, 12.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed hindi_male_english/test.json\n",
      "selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3492/3492 [03:00<00:00, 19.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed hindi_male_english/selection.json\n",
      "seed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 50.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed hindi_male_english/seed.json\n",
      "\n",
      "\n",
      "\n",
      "tamil_male_english\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2263/2263 [00:50<00:00, 44.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed tamil_male_english/test.json\n",
      "selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [01:57<00:00, 43.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed tamil_male_english/selection.json\n",
      "seed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed tamil_male_english/seed.json\n",
      "\n",
      "\n",
      "\n",
      "gujarati_female_english\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1401/1401 [00:36<00:00, 38.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed gujarati_female_english/test.json\n",
      "selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3169/3169 [01:15<00:00, 42.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed gujarati_female_english/selection.json\n",
      "seed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 42.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed gujarati_female_english/seed.json\n",
      "\n",
      "\n",
      "\n",
      "manipuri_female_english\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3010/3010 [03:19<00:00, 15.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed manipuri_female_english/test.json\n",
      "selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6925/6925 [05:48<00:00, 19.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed manipuri_female_english/selection.json\n",
      "seed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed manipuri_female_english/seed.json\n",
      "\n",
      "\n",
      "\n",
      "assamese_female_english\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2513/2513 [03:04<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed assamese_female_english/test.json\n",
      "selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5765/5765 [05:25<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed assamese_female_english/selection.json\n",
      "seed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 44.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed assamese_female_english/seed.json\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "speakers = ['kannada_male_english', 'malayalam_male_english', 'rajasthani_male_english', 'hindi_male_english', \n",
    "           'tamil_male_english', 'gujarati_female_english', 'manipuri_female_english', 'assamese_female_english']\n",
    "file_types = [\"test\", \"selection\", \"seed\"]\n",
    "for speaker in speakers:\n",
    "    print(speaker)\n",
    "    for file_type in file_types:\n",
    "#         print(file_type)\n",
    "        file_dir = f'{speaker}/{file_type}.json'\n",
    "        opened_file = open(file_dir)\n",
    "        json_list = [json.loads(line.strip()) for line in opened_file]\n",
    "        extract_features(json_list, file_dir)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77cc1db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:17<00:00,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed assamese_female_english/seed.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seed_file_dir = 'assamese_female_english/seed.json'\n",
    "seed_file = open(seed_file_dir)\n",
    "seed_list = [json.loads(line.strip()) for line in seed_file]\n",
    "extract_features(seed_list, seed_file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92a7757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration(json_file):\n",
    "    dur_list = [json.loads(line.strip())['duration'] for line in open(json_file)]\n",
    "    print(4.92*100, \"requested duration\")\n",
    "    print(int(4.92*len(dur_list)), \"is num_selected x 4.92\", f\"{len(dur_list)} samples\")\n",
    "    print(sum(dur_list), \"selected duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f62c357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492.0 requested duration\n",
      "373 is num_selected x 4.92 76 samples\n",
      "492.232002 selected duration\n"
     ]
    }
   ],
   "source": [
    "duration('kannada_male_english/all/budget_200/target_20/FL2MI/39/budget_100/error_model/run_2/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5322b209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 kannada_male_english/all/budget_200/target_20/FL2MI/39/budget_100/error_model/run_1/train.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l kannada_male_english/all/budget_200/target_20/FL2MI/39/budget_100/error_model/run_1/train.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bf9a6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json(file_type, speaker):\n",
    "    ref = open(f'{speaker}/all.json', 'r')\n",
    "    files = ref.readlines()\n",
    "    files = [json.loads(file) for file in files]\n",
    "    path_dict = [(file[\"audio_filepath\"], file[\"pseudo_text\"]) for file in files]\n",
    "    path_dict = dict(path_dict)\n",
    "    json_file = open(f\"{speaker}/manifests/{file_type}.json\", 'r')\n",
    "    samples = json_file.readlines()\n",
    "    new_json_file = open(f\"{speaker}/{file_type}.json\", 'w')\n",
    "#     new_json_file = open(f\"{speaker}/temp.json\", 'w')\n",
    "    new_json_samples = []\n",
    "    for sample in samples:\n",
    "        new_dict = json.loads(sample)\n",
    "        new_dict['pseudo_text'] = path_dict[new_dict['audio_filepath']]\n",
    "        json.dump(new_dict, new_json_file)\n",
    "        new_json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21206240",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = ['kannada_male_english', 'malayalam_male_english', 'rajasthani_male_english', 'hindi_male_english', \n",
    "           'tamil_male_english', 'gujarati_female_english', 'manipuri_female_english', 'assamese_female_english']\n",
    "file_types = [\"all\", \"test\", \"selection\", \"seed\", \"seed_plus_dev\", \"dev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "749d72f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for speaker in speakers:\n",
    "    for file_type in file_types:\n",
    "        convert_json(file_type, speaker)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w2v2",
   "language": "python",
   "name": "w2v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
